{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gothic-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h2o\n",
      "  Downloading h2o-3.32.1.3.tar.gz (164.8 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from h2o) (2.25.1)\n",
      "Requirement already satisfied: future in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from h2o) (0.18.2)\n",
      "Requirement already satisfied: colorama>=0.3.8 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from h2o) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from requests->h2o) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from requests->h2o) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from requests->h2o) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from requests->h2o) (2.10)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: h2o\n",
      "  Building wheel for h2o (setup.py): started\n",
      "  Building wheel for h2o (setup.py): finished with status 'done'\n",
      "  Created wheel for h2o: filename=h2o-3.32.1.3-py2.py3-none-any.whl size=164854343 sha256=c30f0e02d7113fa321def42b0078fc0e7ec6f8451a5b1dae812bf9964f6d576d\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\72\\00\\18\\d1ed0b56eb5efd5e96b48828c07bd131ff8829a6d16fcef39d\n",
      "Successfully built h2o\n",
      "Installing collected packages: tabulate, h2o\n",
      "Successfully installed h2o-3.32.1.3 tabulate-0.8.9\n"
     ]
    }
   ],
   "source": [
    "!pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polish-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radio-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.291-b10, mixed mode)\n",
      "  Starting server from C:\\Users\\Administrator\\anaconda3\\envs\\mlp\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpchlo62pz\n",
      "  JVM stdout: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpchlo62pz\\h2o_Administrator_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\tmpchlo62pz\\h2o_Administrator_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/London</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.32.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 25 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Administrator_g52e3c</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.427 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.6.12 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         03 secs\n",
       "H2O_cluster_timezone:       Europe/London\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.32.1.3\n",
       "H2O_cluster_version_age:    1 month and 25 days\n",
       "H2O_cluster_name:           H2O_from_python_Administrator_g52e3c\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.427 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.6.12 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "popular-manufacturer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>categ_1_hot_Administrative Services</th>\n",
       "      <th>categ_1_hot_Advertising</th>\n",
       "      <th>categ_1_hot_Agriculture and Farming</th>\n",
       "      <th>categ_1_hot_Apps</th>\n",
       "      <th>categ_1_hot_Artificial Intelligence</th>\n",
       "      <th>categ_1_hot_Biotechnology</th>\n",
       "      <th>categ_1_hot_Clothing and Apparel</th>\n",
       "      <th>categ_1_hot_Commerce and Shopping</th>\n",
       "      <th>categ_1_hot_Community and Lifestyle</th>\n",
       "      <th>...</th>\n",
       "      <th>total_funding_1hot_1000</th>\n",
       "      <th>total_funding_1hot_10000</th>\n",
       "      <th>total_funding_1hot_l_10000</th>\n",
       "      <th>num_founder_1hot_3</th>\n",
       "      <th>num_founder_1hot_6</th>\n",
       "      <th>num_founder_1hot_10</th>\n",
       "      <th>have_seed</th>\n",
       "      <th>have_series_a</th>\n",
       "      <th>have_series_b</th>\n",
       "      <th>have_series_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10724</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10725</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10726</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10729 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       status  categ_1_hot_Administrative Services  categ_1_hot_Advertising  \\\n",
       "0           1                                    0                        0   \n",
       "1           1                                    0                        0   \n",
       "2           1                                    0                        0   \n",
       "3           1                                    0                        0   \n",
       "4           1                                    0                        0   \n",
       "...       ...                                  ...                      ...   \n",
       "10724       1                                    0                        0   \n",
       "10725       1                                    0                        0   \n",
       "10726       1                                    0                        0   \n",
       "10727       1                                    0                        0   \n",
       "10728       1                                    0                        0   \n",
       "\n",
       "       categ_1_hot_Agriculture and Farming  categ_1_hot_Apps  \\\n",
       "0                                        0                 0   \n",
       "1                                        0                 0   \n",
       "2                                        0                 0   \n",
       "3                                        0                 0   \n",
       "4                                        0                 0   \n",
       "...                                    ...               ...   \n",
       "10724                                    0                 0   \n",
       "10725                                    0                 0   \n",
       "10726                                    0                 0   \n",
       "10727                                    0                 0   \n",
       "10728                                    0                 0   \n",
       "\n",
       "       categ_1_hot_Artificial Intelligence  categ_1_hot_Biotechnology  \\\n",
       "0                                        1                          0   \n",
       "1                                        0                          0   \n",
       "2                                        0                          0   \n",
       "3                                        0                          0   \n",
       "4                                        0                          0   \n",
       "...                                    ...                        ...   \n",
       "10724                                    0                          0   \n",
       "10725                                    0                          0   \n",
       "10726                                    0                          0   \n",
       "10727                                    0                          0   \n",
       "10728                                    0                          0   \n",
       "\n",
       "       categ_1_hot_Clothing and Apparel  categ_1_hot_Commerce and Shopping  \\\n",
       "0                                     0                                  0   \n",
       "1                                     0                                  1   \n",
       "2                                     0                                  0   \n",
       "3                                     0                                  0   \n",
       "4                                     0                                  0   \n",
       "...                                 ...                                ...   \n",
       "10724                                 0                                  0   \n",
       "10725                                 0                                  0   \n",
       "10726                                 0                                  0   \n",
       "10727                                 0                                  1   \n",
       "10728                                 1                                  1   \n",
       "\n",
       "       categ_1_hot_Community and Lifestyle  ...  total_funding_1hot_1000  \\\n",
       "0                                        0  ...                        0   \n",
       "1                                        0  ...                        0   \n",
       "2                                        0  ...                        0   \n",
       "3                                        1  ...                        0   \n",
       "4                                        0  ...                        1   \n",
       "...                                    ...  ...                      ...   \n",
       "10724                                    0  ...                        0   \n",
       "10725                                    0  ...                        0   \n",
       "10726                                    0  ...                        0   \n",
       "10727                                    0  ...                        0   \n",
       "10728                                    0  ...                        1   \n",
       "\n",
       "       total_funding_1hot_10000  total_funding_1hot_l_10000  \\\n",
       "0                             0                           0   \n",
       "1                             0                           0   \n",
       "2                             0                           0   \n",
       "3                             0                           0   \n",
       "4                             0                           0   \n",
       "...                         ...                         ...   \n",
       "10724                         0                           0   \n",
       "10725                         0                           0   \n",
       "10726                         1                           0   \n",
       "10727                         0                           0   \n",
       "10728                         0                           0   \n",
       "\n",
       "       num_founder_1hot_3  num_founder_1hot_6  num_founder_1hot_10  have_seed  \\\n",
       "0                       1                   0                    0          1   \n",
       "1                       0                   1                    0          1   \n",
       "2                       1                   0                    0          1   \n",
       "3                       1                   0                    0          1   \n",
       "4                       1                   0                    0          1   \n",
       "...                   ...                 ...                  ...        ...   \n",
       "10724                   1                   0                    0          1   \n",
       "10725                   1                   0                    0          1   \n",
       "10726                   1                   0                    0          0   \n",
       "10727                   1                   0                    0          1   \n",
       "10728                   1                   0                    0          1   \n",
       "\n",
       "       have_series_a  have_series_b  have_series_c  \n",
       "0                  0              0              0  \n",
       "1                  0              0              0  \n",
       "2                  0              0              0  \n",
       "3                  0              0              0  \n",
       "4                  0              0              0  \n",
       "...              ...            ...            ...  \n",
       "10724              0              0              0  \n",
       "10725              0              0              0  \n",
       "10726              1              0              0  \n",
       "10727              0              0              0  \n",
       "10728              0              0              0  \n",
       "\n",
       "[10729 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset_v2.csv')\n",
    "# data = data.drop(columns=['org_uuid'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "polished-outreach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from scikit-learn) (1.0.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distinct-selling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data1 = h2o.H2OFrame(data)\n",
    "train, test = data1.split_frame(ratios=[.8], seed=1234)\n",
    "# X_train, X_test = train_test_split(data, test_size = 0.3)\n",
    "# X_train_hex = h2o.H2OFrame(X_train)\n",
    "# X_test_hex = h2o.H2OFrame(X_test)\n",
    "# X_names =  ['employee_count_1hot_100', 'employee_count_1hot_1000', 'employee_count_1hot_10000', 'total_funding_1hot_100','total_funding_1hot_1000', 'total_funding_1hot_10000', 'total_funding_1hot_l_10000']\n",
    "\n",
    "X_names = ['status',\n",
    " 'categ_1_hot_Administrative Services',\n",
    " 'categ_1_hot_Advertising',\n",
    " 'categ_1_hot_Agriculture and Farming',\n",
    " 'categ_1_hot_Apps',\n",
    " 'categ_1_hot_Artificial Intelligence',\n",
    " 'categ_1_hot_Biotechnology',\n",
    " 'categ_1_hot_Clothing and Apparel',\n",
    " 'categ_1_hot_Commerce and Shopping',\n",
    " 'categ_1_hot_Community and Lifestyle',\n",
    " 'categ_1_hot_Consumer Electronics',\n",
    " 'categ_1_hot_Consumer Goods',\n",
    " 'categ_1_hot_Content and Publishing',\n",
    " 'categ_1_hot_Data and Analytics',\n",
    " 'categ_1_hot_Design',\n",
    " 'categ_1_hot_Education',\n",
    " 'categ_1_hot_Energy',\n",
    " 'categ_1_hot_Events',\n",
    " 'categ_1_hot_Financial Services',\n",
    " 'categ_1_hot_Food and Beverage',\n",
    " 'categ_1_hot_Gaming',\n",
    " 'categ_1_hot_Government and Military',\n",
    " 'categ_1_hot_Hardware',\n",
    " 'categ_1_hot_Health Care',\n",
    " 'categ_1_hot_Information Technology',\n",
    " 'categ_1_hot_Internet Services',\n",
    " 'categ_1_hot_Lending and Investments',\n",
    " 'categ_1_hot_Manufacturing',\n",
    " 'categ_1_hot_Media and Entertainment',\n",
    " 'categ_1_hot_Messaging and Telecommunications',\n",
    " 'categ_1_hot_Mobile',\n",
    " 'categ_1_hot_Music and Audio',\n",
    " 'categ_1_hot_Natural Resources',\n",
    " 'categ_1_hot_Navigation and Mapping',\n",
    " 'categ_1_hot_Other',\n",
    " 'categ_1_hot_Payments',\n",
    " 'categ_1_hot_Platforms',\n",
    " 'categ_1_hot_Privacy and Security',\n",
    " 'categ_1_hot_Professional Services',\n",
    " 'categ_1_hot_Real Estate',\n",
    " 'categ_1_hot_Sales and Marketing',\n",
    " 'categ_1_hot_Science and Engineering',\n",
    " 'categ_1_hot_Software',\n",
    " 'categ_1_hot_Sports',\n",
    " 'categ_1_hot_Sustainability',\n",
    " 'categ_1_hot_Transportation',\n",
    " 'categ_1_hot_Travel and Tourism',\n",
    " 'categ_1_hot_Video',\n",
    " 'total_funding_1hot_100',\n",
    " 'total_funding_1hot_1000',\n",
    " 'total_funding_1hot_10000',\n",
    " 'total_funding_1hot_l_10000',\n",
    " 'num_founder_1hot_3',\n",
    " 'num_founder_1hot_6',\n",
    " 'num_founder_1hot_10',\n",
    " 'have_seed',\n",
    " 'have_series_a',\n",
    " 'have_series_b',\n",
    " 'have_series_c']\n",
    "\n",
    "X_test = test.drop('status').as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "preceding-working",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:8629\n",
      "Cols:59\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>status  </th><th>categ_1_hot_Administrative Services  </th><th>categ_1_hot_Advertising  </th><th>categ_1_hot_Agriculture and Farming  </th><th>categ_1_hot_Apps  </th><th>categ_1_hot_Artificial Intelligence  </th><th>categ_1_hot_Biotechnology  </th><th>categ_1_hot_Clothing and Apparel  </th><th>categ_1_hot_Commerce and Shopping  </th><th>categ_1_hot_Community and Lifestyle  </th><th>categ_1_hot_Consumer Electronics  </th><th>categ_1_hot_Consumer Goods  </th><th>categ_1_hot_Content and Publishing  </th><th>categ_1_hot_Data and Analytics  </th><th>categ_1_hot_Design  </th><th>categ_1_hot_Education  </th><th>categ_1_hot_Energy  </th><th>categ_1_hot_Events  </th><th>categ_1_hot_Financial Services  </th><th>categ_1_hot_Food and Beverage  </th><th>categ_1_hot_Gaming  </th><th>categ_1_hot_Government and Military  </th><th>categ_1_hot_Hardware  </th><th>categ_1_hot_Health Care  </th><th>categ_1_hot_Information Technology  </th><th>categ_1_hot_Internet Services  </th><th>categ_1_hot_Lending and Investments  </th><th>categ_1_hot_Manufacturing  </th><th>categ_1_hot_Media and Entertainment  </th><th>categ_1_hot_Messaging and Telecommunications  </th><th>categ_1_hot_Mobile  </th><th>categ_1_hot_Music and Audio  </th><th>categ_1_hot_Natural Resources  </th><th>categ_1_hot_Navigation and Mapping  </th><th>categ_1_hot_Other  </th><th>categ_1_hot_Payments  </th><th>categ_1_hot_Platforms  </th><th>categ_1_hot_Privacy and Security  </th><th>categ_1_hot_Professional Services  </th><th>categ_1_hot_Real Estate  </th><th>categ_1_hot_Sales and Marketing  </th><th>categ_1_hot_Science and Engineering  </th><th>categ_1_hot_Software  </th><th>categ_1_hot_Sports  </th><th>categ_1_hot_Sustainability  </th><th>categ_1_hot_Transportation  </th><th>categ_1_hot_Travel and Tourism  </th><th>categ_1_hot_Video  </th><th>total_funding_1hot_100  </th><th>total_funding_1hot_1000  </th><th>total_funding_1hot_10000  </th><th>total_funding_1hot_l_10000  </th><th>num_founder_1hot_3  </th><th>num_founder_1hot_6  </th><th>num_founder_1hot_10  </th><th>have_seed  </th><th>have_series_a  </th><th>have_series_b  </th><th>have_series_c  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum    </td><td>enum                                 </td><td>enum                     </td><td>enum                                 </td><td>enum              </td><td>enum                                 </td><td>enum                       </td><td>enum                              </td><td>enum                               </td><td>enum                                 </td><td>enum                              </td><td>enum                        </td><td>enum                                </td><td>enum                            </td><td>enum                </td><td>enum                   </td><td>enum                </td><td>enum                </td><td>enum                            </td><td>enum                           </td><td>enum                </td><td>enum                                 </td><td>enum                  </td><td>enum                     </td><td>enum                                </td><td>enum                           </td><td>enum                                 </td><td>enum                       </td><td>enum                                 </td><td>enum                                          </td><td>enum                </td><td>enum                         </td><td>enum                           </td><td>enum                                </td><td>enum               </td><td>enum                  </td><td>enum                   </td><td>enum                              </td><td>enum                               </td><td>enum                     </td><td>enum                             </td><td>enum                                 </td><td>enum                  </td><td>enum                </td><td>enum                        </td><td>enum                        </td><td>enum                            </td><td>enum               </td><td>enum                    </td><td>enum                     </td><td>enum                      </td><td>enum                        </td><td>enum                </td><td>enum                </td><td>enum                 </td><td>enum       </td><td>enum           </td><td>enum           </td><td>enum           </td></tr>\n",
       "<tr><td>mins   </td><td>        </td><td>                                     </td><td>                         </td><td>                                     </td><td>                  </td><td>                                     </td><td>                           </td><td>                                  </td><td>                                   </td><td>                                     </td><td>                                  </td><td>                            </td><td>                                    </td><td>                                </td><td>                    </td><td>                       </td><td>                    </td><td>                    </td><td>                                </td><td>                               </td><td>                    </td><td>                                     </td><td>                      </td><td>                         </td><td>                                    </td><td>                               </td><td>                                     </td><td>                           </td><td>                                     </td><td>                                              </td><td>                    </td><td>                             </td><td>                               </td><td>                                    </td><td>                   </td><td>                      </td><td>                       </td><td>                                  </td><td>                                   </td><td>                         </td><td>                                 </td><td>                                     </td><td>                      </td><td>                    </td><td>                            </td><td>                            </td><td>                                </td><td>                   </td><td>                        </td><td>                         </td><td>                          </td><td>                            </td><td>                    </td><td>                    </td><td>                     </td><td>           </td><td>               </td><td>               </td><td>               </td></tr>\n",
       "<tr><td>mean   </td><td>        </td><td>                                     </td><td>                         </td><td>                                     </td><td>                  </td><td>                                     </td><td>                           </td><td>                                  </td><td>                                   </td><td>                                     </td><td>                                  </td><td>                            </td><td>                                    </td><td>                                </td><td>                    </td><td>                       </td><td>                    </td><td>                    </td><td>                                </td><td>                               </td><td>                    </td><td>                                     </td><td>                      </td><td>                         </td><td>                                    </td><td>                               </td><td>                                     </td><td>                           </td><td>                                     </td><td>                                              </td><td>                    </td><td>                             </td><td>                               </td><td>                                    </td><td>                   </td><td>                      </td><td>                       </td><td>                                  </td><td>                                   </td><td>                         </td><td>                                 </td><td>                                     </td><td>                      </td><td>                    </td><td>                            </td><td>                            </td><td>                                </td><td>                   </td><td>                        </td><td>                         </td><td>                          </td><td>                            </td><td>                    </td><td>                    </td><td>                     </td><td>           </td><td>               </td><td>               </td><td>               </td></tr>\n",
       "<tr><td>maxs   </td><td>        </td><td>                                     </td><td>                         </td><td>                                     </td><td>                  </td><td>                                     </td><td>                           </td><td>                                  </td><td>                                   </td><td>                                     </td><td>                                  </td><td>                            </td><td>                                    </td><td>                                </td><td>                    </td><td>                       </td><td>                    </td><td>                    </td><td>                                </td><td>                               </td><td>                    </td><td>                                     </td><td>                      </td><td>                         </td><td>                                    </td><td>                               </td><td>                                     </td><td>                           </td><td>                                     </td><td>                                              </td><td>                    </td><td>                             </td><td>                               </td><td>                                    </td><td>                   </td><td>                      </td><td>                       </td><td>                                  </td><td>                                   </td><td>                         </td><td>                                 </td><td>                                     </td><td>                      </td><td>                    </td><td>                            </td><td>                            </td><td>                                </td><td>                   </td><td>                        </td><td>                         </td><td>                          </td><td>                            </td><td>                    </td><td>                    </td><td>                     </td><td>           </td><td>               </td><td>               </td><td>               </td></tr>\n",
       "<tr><td>sigma  </td><td>        </td><td>                                     </td><td>                         </td><td>                                     </td><td>                  </td><td>                                     </td><td>                           </td><td>                                  </td><td>                                   </td><td>                                     </td><td>                                  </td><td>                            </td><td>                                    </td><td>                                </td><td>                    </td><td>                       </td><td>                    </td><td>                    </td><td>                                </td><td>                               </td><td>                    </td><td>                                     </td><td>                      </td><td>                         </td><td>                                    </td><td>                               </td><td>                                     </td><td>                           </td><td>                                     </td><td>                                              </td><td>                    </td><td>                             </td><td>                               </td><td>                                    </td><td>                   </td><td>                      </td><td>                       </td><td>                                  </td><td>                                   </td><td>                         </td><td>                                 </td><td>                                     </td><td>                      </td><td>                    </td><td>                            </td><td>                            </td><td>                                </td><td>                   </td><td>                        </td><td>                         </td><td>                          </td><td>                            </td><td>                    </td><td>                    </td><td>                     </td><td>           </td><td>               </td><td>               </td><td>               </td></tr>\n",
       "<tr><td>zeros  </td><td>        </td><td>                                     </td><td>                         </td><td>                                     </td><td>                  </td><td>                                     </td><td>                           </td><td>                                  </td><td>                                   </td><td>                                     </td><td>                                  </td><td>                            </td><td>                                    </td><td>                                </td><td>                    </td><td>                       </td><td>                    </td><td>                    </td><td>                                </td><td>                               </td><td>                    </td><td>                                     </td><td>                      </td><td>                         </td><td>                                    </td><td>                               </td><td>                                     </td><td>                           </td><td>                                     </td><td>                                              </td><td>                    </td><td>                             </td><td>                               </td><td>                                    </td><td>                   </td><td>                      </td><td>                       </td><td>                                  </td><td>                                   </td><td>                         </td><td>                                 </td><td>                                     </td><td>                      </td><td>                    </td><td>                            </td><td>                            </td><td>                                </td><td>                   </td><td>                        </td><td>                         </td><td>                          </td><td>                            </td><td>                    </td><td>                    </td><td>                     </td><td>           </td><td>               </td><td>               </td><td>               </td></tr>\n",
       "<tr><td>missing</td><td>0       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>0                                    </td><td>0                                 </td><td>0                           </td><td>0                                   </td><td>0                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>0                     </td><td>0                        </td><td>0                                   </td><td>0                              </td><td>0                                    </td><td>0                          </td><td>0                                    </td><td>0                                             </td><td>0                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>0                                </td><td>0                                    </td><td>0                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>0                       </td><td>0                        </td><td>0                         </td><td>0                           </td><td>0                   </td><td>0                   </td><td>0                    </td><td>0          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>0      </td><td>1       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>1                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>0                                    </td><td>0                                 </td><td>0                           </td><td>0                                   </td><td>1                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>0                     </td><td>0                        </td><td>0                                   </td><td>0                              </td><td>0                                    </td><td>0                          </td><td>1                                    </td><td>0                                             </td><td>0                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>0                                </td><td>1                                    </td><td>1                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>1                       </td><td>0                        </td><td>0                         </td><td>0                           </td><td>1                   </td><td>0                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>1      </td><td>1       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>1                                  </td><td>0                                    </td><td>0                                 </td><td>0                           </td><td>0                                   </td><td>0                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>1                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>0                     </td><td>0                        </td><td>0                                   </td><td>1                              </td><td>1                                    </td><td>0                          </td><td>0                                    </td><td>0                                             </td><td>1                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>1                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>0                                </td><td>0                                    </td><td>1                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>1                       </td><td>0                        </td><td>0                         </td><td>0                           </td><td>0                   </td><td>1                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>2      </td><td>1       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>0                                    </td><td>0                                 </td><td>0                           </td><td>0                                   </td><td>0                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>0                     </td><td>0                        </td><td>1                                   </td><td>0                              </td><td>0                                    </td><td>0                          </td><td>0                                    </td><td>0                                             </td><td>0                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>1                                </td><td>0                                    </td><td>1                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>1                       </td><td>0                        </td><td>0                         </td><td>0                           </td><td>1                   </td><td>0                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>3      </td><td>1       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>0                                    </td><td>1                                 </td><td>0                           </td><td>0                                   </td><td>0                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>1                     </td><td>0                        </td><td>0                                   </td><td>1                              </td><td>0                                    </td><td>0                          </td><td>0                                    </td><td>0                                             </td><td>0                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>1                        </td><td>0                                </td><td>0                                    </td><td>0                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>0                       </td><td>1                        </td><td>0                         </td><td>0                           </td><td>1                   </td><td>0                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>4      </td><td>1       </td><td>0                                    </td><td>1                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>0                                    </td><td>0                                 </td><td>0                           </td><td>0                                   </td><td>1                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>0                     </td><td>0                        </td><td>1                                   </td><td>0                              </td><td>0                                    </td><td>0                          </td><td>0                                    </td><td>0                                             </td><td>0                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>1                                </td><td>0                                    </td><td>0                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>1                       </td><td>0                        </td><td>0                         </td><td>0                           </td><td>1                   </td><td>0                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>5      </td><td>1       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>0                                    </td><td>0                                 </td><td>0                           </td><td>1                                   </td><td>1                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>1                     </td><td>0                        </td><td>0                                   </td><td>0                              </td><td>0                                    </td><td>0                          </td><td>1                                    </td><td>0                                             </td><td>0                   </td><td>1                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>0                                </td><td>0                                    </td><td>1                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>1                  </td><td>1                       </td><td>0                        </td><td>0                         </td><td>0                           </td><td>0                   </td><td>1                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>6      </td><td>1       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>0                                    </td><td>0                                 </td><td>0                           </td><td>0                                   </td><td>0                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>0                     </td><td>0                        </td><td>0                                   </td><td>1                              </td><td>0                                    </td><td>0                          </td><td>0                                    </td><td>0                                             </td><td>0                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>0                                </td><td>0                                    </td><td>1                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>1                       </td><td>0                        </td><td>0                         </td><td>0                           </td><td>1                   </td><td>0                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>7      </td><td>1       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>0                                    </td><td>0                                 </td><td>0                           </td><td>0                                   </td><td>1                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>0                     </td><td>0                        </td><td>0                                   </td><td>1                              </td><td>0                                    </td><td>0                          </td><td>0                                    </td><td>0                                             </td><td>1                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>0                                </td><td>0                                    </td><td>1                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>0                       </td><td>1                        </td><td>0                         </td><td>0                           </td><td>1                   </td><td>0                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>8      </td><td>1       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>0                                    </td><td>0                                 </td><td>0                           </td><td>1                                   </td><td>0                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>0                     </td><td>0                        </td><td>0                                   </td><td>0                              </td><td>0                                    </td><td>0                          </td><td>1                                    </td><td>0                                             </td><td>0                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>1                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>0                                </td><td>0                                    </td><td>1                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>1                       </td><td>0                        </td><td>0                         </td><td>0                           </td><td>0                   </td><td>1                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "<tr><td>9      </td><td>1       </td><td>0                                    </td><td>0                        </td><td>0                                    </td><td>0                 </td><td>0                                    </td><td>0                          </td><td>0                                 </td><td>0                                  </td><td>1                                    </td><td>0                                 </td><td>0                           </td><td>0                                   </td><td>0                               </td><td>0                   </td><td>0                      </td><td>0                   </td><td>0                   </td><td>0                               </td><td>0                              </td><td>0                   </td><td>0                                    </td><td>0                     </td><td>0                        </td><td>0                                   </td><td>1                              </td><td>0                                    </td><td>0                          </td><td>1                                    </td><td>0                                             </td><td>1                   </td><td>0                            </td><td>0                              </td><td>0                                   </td><td>0                  </td><td>0                     </td><td>0                      </td><td>0                                 </td><td>0                                  </td><td>0                        </td><td>0                                </td><td>0                                    </td><td>0                     </td><td>0                   </td><td>0                           </td><td>0                           </td><td>0                               </td><td>0                  </td><td>1                       </td><td>0                        </td><td>0                         </td><td>0                           </td><td>1                   </td><td>0                   </td><td>0                    </td><td>1          </td><td>0              </td><td>0              </td><td>0              </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_hex= train.asfactor()\n",
    "X_test_hex = test.asfactor()\n",
    "X_train_hex.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ultimate-pattern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "10:51:50.772: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "# h2o_rf = H2ORandomForestEstimator(ntrees=200, max_depth=20, nfolds=10)\n",
    "# Train model\n",
    "from h2o.automl import H2OAutoML\n",
    "aml = H2OAutoML(\n",
    "    max_runtime_secs=(60 * 10),  # 8 hours\n",
    "    max_models=None,  # no limit\n",
    "    seed=20\n",
    ")\n",
    "aml.train(x=X_names, y='status', training_frame=X_train_hex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dominican-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "lb = aml.leaderboard\n",
    "\n",
    "# model_ids = list(lb['model_id'].as_data_frame().iloc[:,0])\n",
    "# out_path = \".\"\n",
    "\n",
    "# for m_id in model_ids:\n",
    "#     mdl = h2o.get_model(m_id)\n",
    "#     h2o.save_model(model=mdl, path=out_path, force=True)\n",
    "\n",
    "# h2o.export_file(lb, os.path.join(out_path, 'aml_leaderboard2.h2o'), force=True)\n",
    "df = lb.head(rows=lb.nrows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "filled-catch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20210715_105150</td><td style=\"text-align: right;\">0.627242</td><td style=\"text-align: right;\"> 0.244464</td><td style=\"text-align: right;\">0.956651</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.252041</td><td style=\"text-align: right;\">0.0635246</td></tr>\n",
       "<tr><td>GLM_1_AutoML_20210715_105150                       </td><td style=\"text-align: right;\">0.62441 </td><td style=\"text-align: right;\"> 0.24484 </td><td style=\"text-align: right;\">0.95679 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.25215 </td><td style=\"text-align: right;\">0.0635799</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_1         </td><td style=\"text-align: right;\">0.62408 </td><td style=\"text-align: right;\"> 0.247025</td><td style=\"text-align: right;\">0.955722</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.253125</td><td style=\"text-align: right;\">0.0640723</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_12        </td><td style=\"text-align: right;\">0.622804</td><td style=\"text-align: right;\"> 0.246791</td><td style=\"text-align: right;\">0.955868</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.252953</td><td style=\"text-align: right;\">0.063985 </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20210715_105150   </td><td style=\"text-align: right;\">0.622408</td><td style=\"text-align: right;\"> 0.244973</td><td style=\"text-align: right;\">0.955959</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.252173</td><td style=\"text-align: right;\">0.0635912</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_13        </td><td style=\"text-align: right;\">0.621493</td><td style=\"text-align: right;\"> 0.248838</td><td style=\"text-align: right;\">0.954248</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.253519</td><td style=\"text-align: right;\">0.0642719</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20210715_105150                       </td><td style=\"text-align: right;\">0.621305</td><td style=\"text-align: right;\"> 0.248698</td><td style=\"text-align: right;\">0.956423</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.252947</td><td style=\"text-align: right;\">0.0639823</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20210715_105150                       </td><td style=\"text-align: right;\">0.620799</td><td style=\"text-align: right;\"> 0.245998</td><td style=\"text-align: right;\">0.955435</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.25248 </td><td style=\"text-align: right;\">0.0637462</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_11        </td><td style=\"text-align: right;\">0.619254</td><td style=\"text-align: right;\"> 0.245468</td><td style=\"text-align: right;\">0.955545</td><td style=\"text-align: right;\">              0.499161</td><td style=\"text-align: right;\">0.252327</td><td style=\"text-align: right;\">0.063669 </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_15        </td><td style=\"text-align: right;\">0.619172</td><td style=\"text-align: right;\"> 0.246453</td><td style=\"text-align: right;\">0.954883</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.252684</td><td style=\"text-align: right;\">0.063849 </td></tr>\n",
       "<tr><td>GBM_1_AutoML_20210715_105150                       </td><td style=\"text-align: right;\">0.617162</td><td style=\"text-align: right;\"> 0.248706</td><td style=\"text-align: right;\">0.955087</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.254268</td><td style=\"text-align: right;\">0.064652 </td></tr>\n",
       "<tr><td>GBM_2_AutoML_20210715_105150                       </td><td style=\"text-align: right;\">0.61524 </td><td style=\"text-align: right;\"> 0.248135</td><td style=\"text-align: right;\">0.954163</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.253372</td><td style=\"text-align: right;\">0.0641971</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_3         </td><td style=\"text-align: right;\">0.614975</td><td style=\"text-align: right;\"> 0.24651 </td><td style=\"text-align: right;\">0.95469 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.252733</td><td style=\"text-align: right;\">0.0638739</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_7         </td><td style=\"text-align: right;\">0.61429 </td><td style=\"text-align: right;\"> 0.251719</td><td style=\"text-align: right;\">0.954928</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.255775</td><td style=\"text-align: right;\">0.0654207</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_6         </td><td style=\"text-align: right;\">0.613562</td><td style=\"text-align: right;\"> 0.252029</td><td style=\"text-align: right;\">0.953644</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.254611</td><td style=\"text-align: right;\">0.0648266</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20210715_105150                       </td><td style=\"text-align: right;\">0.612019</td><td style=\"text-align: right;\"> 0.249104</td><td style=\"text-align: right;\">0.953314</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.253587</td><td style=\"text-align: right;\">0.0643066</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20210715_105150                       </td><td style=\"text-align: right;\">0.611141</td><td style=\"text-align: right;\"> 0.25066 </td><td style=\"text-align: right;\">0.953453</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.254273</td><td style=\"text-align: right;\">0.0646548</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_4         </td><td style=\"text-align: right;\">0.603423</td><td style=\"text-align: right;\"> 0.251213</td><td style=\"text-align: right;\">0.951985</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.254093</td><td style=\"text-align: right;\">0.064563 </td></tr>\n",
       "<tr><td>DRF_1_AutoML_20210715_105150                       </td><td style=\"text-align: right;\">0.603292</td><td style=\"text-align: right;\"> 0.262907</td><td style=\"text-align: right;\">0.951684</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.255191</td><td style=\"text-align: right;\">0.0651226</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_14        </td><td style=\"text-align: right;\">0.600837</td><td style=\"text-align: right;\"> 0.253058</td><td style=\"text-align: right;\">0.952558</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.255466</td><td style=\"text-align: right;\">0.0652629</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_9         </td><td style=\"text-align: right;\">0.600589</td><td style=\"text-align: right;\"> 0.251782</td><td style=\"text-align: right;\">0.951958</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.254674</td><td style=\"text-align: right;\">0.0648586</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_8         </td><td style=\"text-align: right;\">0.599732</td><td style=\"text-align: right;\"> 0.258645</td><td style=\"text-align: right;\">0.950047</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.256608</td><td style=\"text-align: right;\">0.0658477</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20210715_105150_model_2</td><td style=\"text-align: right;\">0.597459</td><td style=\"text-align: right;\"> 0.360847</td><td style=\"text-align: right;\">0.951776</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.257647</td><td style=\"text-align: right;\">0.0663818</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20210715_105150_model_1</td><td style=\"text-align: right;\">0.596114</td><td style=\"text-align: right;\"> 0.294145</td><td style=\"text-align: right;\">0.947571</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.256164</td><td style=\"text-align: right;\">0.0656201</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_10        </td><td style=\"text-align: right;\">0.593558</td><td style=\"text-align: right;\"> 0.256118</td><td style=\"text-align: right;\">0.951016</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.255822</td><td style=\"text-align: right;\">0.0654448</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20210715_105150              </td><td style=\"text-align: right;\">0.590181</td><td style=\"text-align: right;\"> 0.24997 </td><td style=\"text-align: right;\">0.950074</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.253569</td><td style=\"text-align: right;\">0.0642973</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_5         </td><td style=\"text-align: right;\">0.588807</td><td style=\"text-align: right;\"> 0.258301</td><td style=\"text-align: right;\">0.951281</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.257963</td><td style=\"text-align: right;\">0.066545 </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20210715_105150_model_2         </td><td style=\"text-align: right;\">0.585937</td><td style=\"text-align: right;\"> 0.303753</td><td style=\"text-align: right;\">0.950507</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.274012</td><td style=\"text-align: right;\">0.0750824</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20210715_105150_model_1</td><td style=\"text-align: right;\">0.580616</td><td style=\"text-align: right;\"> 0.305726</td><td style=\"text-align: right;\">0.949504</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.272441</td><td style=\"text-align: right;\">0.0742242</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20210715_105150_model_1</td><td style=\"text-align: right;\">0.580025</td><td style=\"text-align: right;\"> 0.356807</td><td style=\"text-align: right;\">0.947659</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.269767</td><td style=\"text-align: right;\">0.072774 </td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20210715_105150_model_6</td><td style=\"text-align: right;\">0.57944 </td><td style=\"text-align: right;\"> 0.260257</td><td style=\"text-align: right;\">0.948795</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.254205</td><td style=\"text-align: right;\">0.0646204</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20210715_105150_model_4</td><td style=\"text-align: right;\">0.5747  </td><td style=\"text-align: right;\"> 0.253795</td><td style=\"text-align: right;\">0.94938 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.254464</td><td style=\"text-align: right;\">0.0647519</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20210715_105150_model_2</td><td style=\"text-align: right;\">0.572416</td><td style=\"text-align: right;\"> 0.265417</td><td style=\"text-align: right;\">0.949358</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.256586</td><td style=\"text-align: right;\">0.0658365</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20210715_105150_model_2</td><td style=\"text-align: right;\">0.57131 </td><td style=\"text-align: right;\"> 0.256473</td><td style=\"text-align: right;\">0.948523</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.254877</td><td style=\"text-align: right;\">0.0649625</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20210715_105150_model_3</td><td style=\"text-align: right;\">0.564785</td><td style=\"text-align: right;\"> 0.462375</td><td style=\"text-align: right;\">0.945922</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.261855</td><td style=\"text-align: right;\">0.0685678</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20210715_105150_model_5</td><td style=\"text-align: right;\">0.562778</td><td style=\"text-align: right;\"> 0.345732</td><td style=\"text-align: right;\">0.943932</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.257798</td><td style=\"text-align: right;\">0.0664596</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20210715_105150_model_3</td><td style=\"text-align: right;\">0.556324</td><td style=\"text-align: right;\"> 0.288501</td><td style=\"text-align: right;\">0.944048</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.257045</td><td style=\"text-align: right;\">0.0660721</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20210715_105150_model_4</td><td style=\"text-align: right;\">0.552592</td><td style=\"text-align: right;\"> 0.273412</td><td style=\"text-align: right;\">0.94362 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.259145</td><td style=\"text-align: right;\">0.0671564</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20210715_105150_model_4</td><td style=\"text-align: right;\">0.548157</td><td style=\"text-align: right;\"> 0.3171  </td><td style=\"text-align: right;\">0.942814</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.257647</td><td style=\"text-align: right;\">0.0663819</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20210715_105150_model_6</td><td style=\"text-align: right;\">0.541348</td><td style=\"text-align: right;\"> 0.267063</td><td style=\"text-align: right;\">0.943173</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.256512</td><td style=\"text-align: right;\">0.0657987</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20210715_105150_model_3</td><td style=\"text-align: right;\">0.540993</td><td style=\"text-align: right;\"> 0.364334</td><td style=\"text-align: right;\">0.942259</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.259378</td><td style=\"text-align: right;\">0.0672767</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20210715_105150_model_5</td><td style=\"text-align: right;\">0.520577</td><td style=\"text-align: right;\"> 0.521046</td><td style=\"text-align: right;\">0.934687</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.261756</td><td style=\"text-align: right;\">0.068516 </td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20210715_105150_model_5</td><td style=\"text-align: right;\">0.511128</td><td style=\"text-align: right;\"> 0.553265</td><td style=\"text-align: right;\">0.932502</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.262864</td><td style=\"text-align: right;\">0.0690973</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "driving-shaft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.06134264141048438\n",
      "RMSE: 0.24767446660987155\n",
      "LogLoss: 0.23658833575959692\n",
      "Mean Per-Class Error: 0.3756543974407419\n",
      "AUC: 0.6402859354535749\n",
      "AUCPR: 0.9621229976348808\n",
      "Gini: 0.28057187090714986\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6885243129584632: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(139.0/139.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/1961.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>(139.0/2100.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1   Error             Rate\n",
       "0      0  0.0   139.0     1.0    (139.0/139.0)\n",
       "1      1  0.0  1961.0     0.0     (0.0/1961.0)\n",
       "2  Total  0.0  2100.0  0.0662   (139.0/2100.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.688524</td>\n",
       "      <td>0.965772</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.688524</td>\n",
       "      <td>0.986022</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.760955</td>\n",
       "      <td>0.946482</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.688524</td>\n",
       "      <td>0.933810</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.992503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.688524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.992503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.945049</td>\n",
       "      <td>0.125103</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.926523</td>\n",
       "      <td>0.585926</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.931540</td>\n",
       "      <td>0.624346</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.992503</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.992503</td>\n",
       "      <td>1959.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.747969</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.688524</td>\n",
       "      <td>1961.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.992503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.992503</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.747969</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.688524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.688524     0.965772  399.0\n",
       "1                        max f2   0.688524     0.986022  399.0\n",
       "2                  max f0point5   0.760955     0.946482  393.0\n",
       "3                  max accuracy   0.688524     0.933810  399.0\n",
       "4                 max precision   0.992503     1.000000    0.0\n",
       "5                    max recall   0.688524     1.000000  399.0\n",
       "6               max specificity   0.992503     1.000000    0.0\n",
       "7              max absolute_mcc   0.945049     0.125103  125.0\n",
       "8    max min_per_class_accuracy   0.926523     0.585926  182.0\n",
       "9   max mean_per_class_accuracy   0.931540     0.624346  167.0\n",
       "10                      max tns   0.992503   139.000000    0.0\n",
       "11                      max fns   0.992503  1959.000000    0.0\n",
       "12                      max fps   0.747969   139.000000  395.0\n",
       "13                      max tps   0.688524  1961.000000  399.0\n",
       "14                      max tnr   0.992503     1.000000    0.0\n",
       "15                      max fnr   0.992503     0.998980    0.0\n",
       "16                      max fpr   0.747969     1.000000  395.0\n",
       "17                      max tpr   0.688524     1.000000  399.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 93.38 %, avg score: 92.95 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.989216</td>\n",
       "      <td>1.070882</td>\n",
       "      <td>1.070882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990506</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>7.088220</td>\n",
       "      <td>7.088220</td>\n",
       "      <td>0.010709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.987398</td>\n",
       "      <td>1.070882</td>\n",
       "      <td>1.070882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989425</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.021418</td>\n",
       "      <td>7.088220</td>\n",
       "      <td>7.088220</td>\n",
       "      <td>0.021418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.986336</td>\n",
       "      <td>1.019888</td>\n",
       "      <td>1.053884</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.986905</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.988585</td>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.031617</td>\n",
       "      <td>1.988781</td>\n",
       "      <td>5.388407</td>\n",
       "      <td>0.024422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.985562</td>\n",
       "      <td>1.070882</td>\n",
       "      <td>1.058134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985868</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.987906</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>7.088220</td>\n",
       "      <td>5.813361</td>\n",
       "      <td>0.035131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.984467</td>\n",
       "      <td>1.019888</td>\n",
       "      <td>1.050484</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.984997</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.987324</td>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>1.988781</td>\n",
       "      <td>5.048445</td>\n",
       "      <td>0.038136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.978584</td>\n",
       "      <td>1.060683</td>\n",
       "      <td>1.055584</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.981921</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.984623</td>\n",
       "      <td>0.053034</td>\n",
       "      <td>0.105558</td>\n",
       "      <td>6.068332</td>\n",
       "      <td>5.558389</td>\n",
       "      <td>0.083976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.973054</td>\n",
       "      <td>1.050484</td>\n",
       "      <td>1.053884</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.975965</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.981737</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>0.158083</td>\n",
       "      <td>5.048445</td>\n",
       "      <td>5.388407</td>\n",
       "      <td>0.122111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.965838</td>\n",
       "      <td>1.050484</td>\n",
       "      <td>1.053034</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.969610</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.978705</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>0.210607</td>\n",
       "      <td>5.048445</td>\n",
       "      <td>5.303417</td>\n",
       "      <td>0.160247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.953612</td>\n",
       "      <td>1.024987</td>\n",
       "      <td>1.043685</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.959021</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.972144</td>\n",
       "      <td>0.102499</td>\n",
       "      <td>0.313106</td>\n",
       "      <td>2.498725</td>\n",
       "      <td>4.368519</td>\n",
       "      <td>0.197998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.942711</td>\n",
       "      <td>1.019888</td>\n",
       "      <td>1.037736</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.948066</td>\n",
       "      <td>0.969048</td>\n",
       "      <td>0.966124</td>\n",
       "      <td>0.101989</td>\n",
       "      <td>0.415094</td>\n",
       "      <td>1.988781</td>\n",
       "      <td>3.773585</td>\n",
       "      <td>0.228044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.933181</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>1.030087</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.937949</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.960489</td>\n",
       "      <td>0.099949</td>\n",
       "      <td>0.515043</td>\n",
       "      <td>-0.050994</td>\n",
       "      <td>3.008669</td>\n",
       "      <td>0.227274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.924023</td>\n",
       "      <td>0.958695</td>\n",
       "      <td>1.018188</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.928632</td>\n",
       "      <td>0.950794</td>\n",
       "      <td>0.955180</td>\n",
       "      <td>0.095869</td>\n",
       "      <td>0.610913</td>\n",
       "      <td>-4.130546</td>\n",
       "      <td>1.818800</td>\n",
       "      <td>0.164870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.915519</td>\n",
       "      <td>0.989291</td>\n",
       "      <td>1.014060</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.920239</td>\n",
       "      <td>0.946939</td>\n",
       "      <td>0.950188</td>\n",
       "      <td>0.098929</td>\n",
       "      <td>0.709842</td>\n",
       "      <td>-1.070882</td>\n",
       "      <td>1.405988</td>\n",
       "      <td>0.148691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.899934</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>1.009689</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.908689</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.945001</td>\n",
       "      <td>0.097909</td>\n",
       "      <td>0.807751</td>\n",
       "      <td>-2.090770</td>\n",
       "      <td>0.968893</td>\n",
       "      <td>0.117104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.877103</td>\n",
       "      <td>0.958695</td>\n",
       "      <td>1.004023</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.890937</td>\n",
       "      <td>0.937566</td>\n",
       "      <td>0.938994</td>\n",
       "      <td>0.095869</td>\n",
       "      <td>0.903621</td>\n",
       "      <td>-4.130546</td>\n",
       "      <td>0.402289</td>\n",
       "      <td>0.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.688524</td>\n",
       "      <td>0.963794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.844275</td>\n",
       "      <td>0.933810</td>\n",
       "      <td>0.929522</td>\n",
       "      <td>0.096379</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.620602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                      0.01         0.989216  1.070882   \n",
       "1       2                      0.02         0.987398  1.070882   \n",
       "2       3                      0.03         0.986336  1.019888   \n",
       "3       4                      0.04         0.985562  1.070882   \n",
       "4       5                      0.05         0.984467  1.019888   \n",
       "5       6                      0.10         0.978584  1.060683   \n",
       "6       7                      0.15         0.973054  1.050484   \n",
       "7       8                      0.20         0.965838  1.050484   \n",
       "8       9                      0.30         0.953612  1.024987   \n",
       "9      10                      0.40         0.942711  1.019888   \n",
       "10     11                      0.50         0.933181  0.999490   \n",
       "11     12                      0.60         0.924023  0.958695   \n",
       "12     13                      0.70         0.915519  0.989291   \n",
       "13     14                      0.80         0.899934  0.979092   \n",
       "14     15                      0.90         0.877103  0.958695   \n",
       "15     16                      1.00         0.688524  0.963794   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.070882       1.000000  0.990506                  1.000000   \n",
       "1          1.070882       1.000000  0.988345                  1.000000   \n",
       "2          1.053884       0.952381  0.986905                  0.984127   \n",
       "3          1.058134       1.000000  0.985868                  0.988095   \n",
       "4          1.050484       0.952381  0.984997                  0.980952   \n",
       "5          1.055584       0.990476  0.981921                  0.985714   \n",
       "6          1.053884       0.980952  0.975965                  0.984127   \n",
       "7          1.053034       0.980952  0.969610                  0.983333   \n",
       "8          1.043685       0.957143  0.959021                  0.974603   \n",
       "9          1.037736       0.952381  0.948066                  0.969048   \n",
       "10         1.030087       0.933333  0.937949                  0.961905   \n",
       "11         1.018188       0.895238  0.928632                  0.950794   \n",
       "12         1.014060       0.923810  0.920239                  0.946939   \n",
       "13         1.009689       0.914286  0.908689                  0.942857   \n",
       "14         1.004023       0.895238  0.890937                  0.937566   \n",
       "15         1.000000       0.900000  0.844275                  0.933810   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate      gain  \\\n",
       "0           0.990506      0.010709                 0.010709  7.088220   \n",
       "1           0.989425      0.010709                 0.021418  7.088220   \n",
       "2           0.988585      0.010199                 0.031617  1.988781   \n",
       "3           0.987906      0.010709                 0.042325  7.088220   \n",
       "4           0.987324      0.010199                 0.052524  1.988781   \n",
       "5           0.984623      0.053034                 0.105558  6.068332   \n",
       "6           0.981737      0.052524                 0.158083  5.048445   \n",
       "7           0.978705      0.052524                 0.210607  5.048445   \n",
       "8           0.972144      0.102499                 0.313106  2.498725   \n",
       "9           0.966124      0.101989                 0.415094  1.988781   \n",
       "10          0.960489      0.099949                 0.515043 -0.050994   \n",
       "11          0.955180      0.095869                 0.610913 -4.130546   \n",
       "12          0.950188      0.098929                 0.709842 -1.070882   \n",
       "13          0.945001      0.097909                 0.807751 -2.090770   \n",
       "14          0.938994      0.095869                 0.903621 -4.130546   \n",
       "15          0.929522      0.096379                 1.000000 -3.620602   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0          7.088220            0.010709  \n",
       "1          7.088220            0.021418  \n",
       "2          5.388407            0.024422  \n",
       "3          5.813361            0.035131  \n",
       "4          5.048445            0.038136  \n",
       "5          5.558389            0.083976  \n",
       "6          5.388407            0.122111  \n",
       "7          5.303417            0.160247  \n",
       "8          4.368519            0.197998  \n",
       "9          3.773585            0.228044  \n",
       "10         3.008669            0.227274  \n",
       "11         1.818800            0.164870  \n",
       "12         1.405988            0.148691  \n",
       "13         0.968893            0.117104  \n",
       "14         0.402289            0.054700  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = h2o.get_model('GBM_grid__1_AutoML_20210715_105150_model_1')\n",
    "perf = model.model_performance(X_test_hex)\n",
    "# model.model_performance()\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exclusive-beijing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The `auc_type` parameter is set but it is not used because the `test_data` parameter is None.\n",
      "\n",
      "ModelMetricsBinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.06557889248033012\n",
      "RMSE: 0.25608376067281213\n",
      "LogLoss: 0.27430738322607606\n",
      "Mean Per-Class Error: 0.42157549353881685\n",
      "AUC: 0.5984002023532125\n",
      "AUCPR: 0.9525863266546644\n",
      "Gini: 0.1968004047064249\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4804755846659342: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>(595.0/596.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8033.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/8033.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8628.0</td>\n",
       "      <td>0.069</td>\n",
       "      <td>(595.0/8629.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1   Error             Rate\n",
       "0      0  1.0   595.0  0.9983    (595.0/596.0)\n",
       "1      1  0.0  8033.0     0.0     (0.0/8033.0)\n",
       "2  Total  1.0  8628.0   0.069   (595.0/8629.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>0.964288</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>0.985402</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>0.944059</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>0.931046</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.998359</td>\n",
       "      <td>0.982507</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991611</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.951004</td>\n",
       "      <td>0.080783</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.933521</td>\n",
       "      <td>0.562305</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.951004</td>\n",
       "      <td>0.578425</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7771.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.441797</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>8033.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991611</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967385</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.441797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.480476     0.964288  398.0\n",
       "1                        max f2   0.480476     0.985402  398.0\n",
       "2                  max f0point5   0.480476     0.944059  398.0\n",
       "3                  max accuracy   0.480476     0.931046  398.0\n",
       "4                 max precision   0.998359     0.982507    3.0\n",
       "5                    max recall   0.480476     1.000000  398.0\n",
       "6               max specificity   1.000000     0.991611    0.0\n",
       "7              max absolute_mcc   0.951004     0.080783   99.0\n",
       "8    max min_per_class_accuracy   0.933521     0.562305  135.0\n",
       "9   max mean_per_class_accuracy   0.951004     0.578425   99.0\n",
       "10                      max tns   1.000000   591.000000    0.0\n",
       "11                      max fns   1.000000  7771.000000    0.0\n",
       "12                      max fps   0.441797   596.000000  399.0\n",
       "13                      max tps   0.480476  8033.000000  398.0\n",
       "14                      max tnr   1.000000     0.991611    0.0\n",
       "15                      max fnr   1.000000     0.967385    0.0\n",
       "16                      max fpr   0.441797     1.000000  399.0\n",
       "17                      max tpr   0.480476     1.000000  398.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 93.09 %, avg score: 92.91 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.054078</td>\n",
       "      <td>1.054078</td>\n",
       "      <td>0.981273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032615</td>\n",
       "      <td>0.032615</td>\n",
       "      <td>5.407796</td>\n",
       "      <td>5.407796</td>\n",
       "      <td>0.024226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>0.998050</td>\n",
       "      <td>1.060597</td>\n",
       "      <td>1.055566</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.999698</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>6.059656</td>\n",
       "      <td>5.556631</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.050180</td>\n",
       "      <td>0.997024</td>\n",
       "      <td>1.037153</td>\n",
       "      <td>1.051867</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.997521</td>\n",
       "      <td>0.979215</td>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>0.052782</td>\n",
       "      <td>3.715278</td>\n",
       "      <td>5.186659</td>\n",
       "      <td>0.037682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.991765</td>\n",
       "      <td>1.044216</td>\n",
       "      <td>1.048055</td>\n",
       "      <td>0.972093</td>\n",
       "      <td>0.994438</td>\n",
       "      <td>0.975666</td>\n",
       "      <td>0.996858</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.104818</td>\n",
       "      <td>4.421644</td>\n",
       "      <td>4.805482</td>\n",
       "      <td>0.069583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.150075</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>1.034409</td>\n",
       "      <td>1.043503</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.988555</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.994088</td>\n",
       "      <td>0.051786</td>\n",
       "      <td>0.156604</td>\n",
       "      <td>3.440899</td>\n",
       "      <td>4.350269</td>\n",
       "      <td>0.094523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>1.031824</td>\n",
       "      <td>1.040586</td>\n",
       "      <td>0.960557</td>\n",
       "      <td>0.982019</td>\n",
       "      <td>0.968714</td>\n",
       "      <td>0.991074</td>\n",
       "      <td>0.051537</td>\n",
       "      <td>0.208141</td>\n",
       "      <td>3.182435</td>\n",
       "      <td>4.058649</td>\n",
       "      <td>0.117537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.300035</td>\n",
       "      <td>0.965411</td>\n",
       "      <td>1.016937</td>\n",
       "      <td>1.032703</td>\n",
       "      <td>0.946698</td>\n",
       "      <td>0.971883</td>\n",
       "      <td>0.961375</td>\n",
       "      <td>0.984677</td>\n",
       "      <td>0.101705</td>\n",
       "      <td>0.309847</td>\n",
       "      <td>1.693680</td>\n",
       "      <td>3.270326</td>\n",
       "      <td>0.142062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.400046</td>\n",
       "      <td>0.952166</td>\n",
       "      <td>1.008224</td>\n",
       "      <td>1.026583</td>\n",
       "      <td>0.938586</td>\n",
       "      <td>0.958708</td>\n",
       "      <td>0.955678</td>\n",
       "      <td>0.978185</td>\n",
       "      <td>0.100834</td>\n",
       "      <td>0.410681</td>\n",
       "      <td>0.822375</td>\n",
       "      <td>2.658338</td>\n",
       "      <td>0.153970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.500058</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.995777</td>\n",
       "      <td>1.020422</td>\n",
       "      <td>0.926999</td>\n",
       "      <td>0.945808</td>\n",
       "      <td>0.949942</td>\n",
       "      <td>0.971709</td>\n",
       "      <td>0.099589</td>\n",
       "      <td>0.510270</td>\n",
       "      <td>-0.422345</td>\n",
       "      <td>2.042202</td>\n",
       "      <td>0.147854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.599954</td>\n",
       "      <td>0.927406</td>\n",
       "      <td>0.985716</td>\n",
       "      <td>1.014643</td>\n",
       "      <td>0.917633</td>\n",
       "      <td>0.933615</td>\n",
       "      <td>0.944562</td>\n",
       "      <td>0.965366</td>\n",
       "      <td>0.098469</td>\n",
       "      <td>0.608739</td>\n",
       "      <td>-1.428374</td>\n",
       "      <td>1.464331</td>\n",
       "      <td>0.127195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.699965</td>\n",
       "      <td>0.913057</td>\n",
       "      <td>0.984574</td>\n",
       "      <td>1.010347</td>\n",
       "      <td>0.916570</td>\n",
       "      <td>0.920876</td>\n",
       "      <td>0.940563</td>\n",
       "      <td>0.959010</td>\n",
       "      <td>0.098469</td>\n",
       "      <td>0.707208</td>\n",
       "      <td>-1.542594</td>\n",
       "      <td>1.034699</td>\n",
       "      <td>0.104859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.799977</td>\n",
       "      <td>0.893867</td>\n",
       "      <td>0.989553</td>\n",
       "      <td>1.007747</td>\n",
       "      <td>0.921205</td>\n",
       "      <td>0.904092</td>\n",
       "      <td>0.938143</td>\n",
       "      <td>0.952144</td>\n",
       "      <td>0.098967</td>\n",
       "      <td>0.806175</td>\n",
       "      <td>-1.044706</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.089732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.899988</td>\n",
       "      <td>0.856892</td>\n",
       "      <td>0.969637</td>\n",
       "      <td>1.003512</td>\n",
       "      <td>0.902665</td>\n",
       "      <td>0.878678</td>\n",
       "      <td>0.934200</td>\n",
       "      <td>0.943980</td>\n",
       "      <td>0.096975</td>\n",
       "      <td>0.903150</td>\n",
       "      <td>-3.036259</td>\n",
       "      <td>0.351238</td>\n",
       "      <td>0.045767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.441797</td>\n",
       "      <td>0.968393</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901506</td>\n",
       "      <td>0.795682</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>0.929148</td>\n",
       "      <td>0.096850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.160731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.030942         1.000000  1.054078   \n",
       "1       2                  0.040097         0.998050  1.060597   \n",
       "2       3                  0.050180         0.997024  1.037153   \n",
       "3       4                  0.100012         0.991765  1.044216   \n",
       "4       5                  0.150075         0.985249  1.034409   \n",
       "5       6                  0.200023         0.978410  1.031824   \n",
       "6       7                  0.300035         0.965411  1.016937   \n",
       "7       8                  0.400046         0.952166  1.008224   \n",
       "8       9                  0.500058         0.939850  0.995777   \n",
       "9      10                  0.599954         0.927406  0.985716   \n",
       "10     11                  0.699965         0.913057  0.984574   \n",
       "11     12                  0.799977         0.893867  0.989553   \n",
       "12     13                  0.899988         0.856892  0.969637   \n",
       "13     14                  1.000000         0.441797  0.968393   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.054078       0.981273  1.000000                  0.981273   \n",
       "1          1.055566       0.987342  0.998678                  0.982659   \n",
       "2          1.051867       0.965517  0.997521                  0.979215   \n",
       "3          1.048055       0.972093  0.994438                  0.975666   \n",
       "4          1.043503       0.962963  0.988555                  0.971429   \n",
       "5          1.040586       0.960557  0.982019                  0.968714   \n",
       "6          1.032703       0.946698  0.971883                  0.961375   \n",
       "7          1.026583       0.938586  0.958708                  0.955678   \n",
       "8          1.020422       0.926999  0.945808                  0.949942   \n",
       "9          1.014643       0.917633  0.933615                  0.944562   \n",
       "10         1.010347       0.916570  0.920876                  0.940563   \n",
       "11         1.007747       0.921205  0.904092                  0.938143   \n",
       "12         1.003512       0.902665  0.878678                  0.934200   \n",
       "13         1.000000       0.901506  0.795682                  0.930931   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate      gain  \\\n",
       "0           1.000000      0.032615                 0.032615  5.407796   \n",
       "1           0.999698      0.009710                 0.042325  6.059656   \n",
       "2           0.999261      0.010457                 0.052782  3.715278   \n",
       "3           0.996858      0.052035                 0.104818  4.421644   \n",
       "4           0.994088      0.051786                 0.156604  3.440899   \n",
       "5           0.991074      0.051537                 0.208141  3.182435   \n",
       "6           0.984677      0.101705                 0.309847  1.693680   \n",
       "7           0.978185      0.100834                 0.410681  0.822375   \n",
       "8           0.971709      0.099589                 0.510270 -0.422345   \n",
       "9           0.965366      0.098469                 0.608739 -1.428374   \n",
       "10          0.959010      0.098469                 0.707208 -1.542594   \n",
       "11          0.952144      0.098967                 0.806175 -1.044706   \n",
       "12          0.943980      0.096975                 0.903150 -3.036259   \n",
       "13          0.929148      0.096850                 1.000000 -3.160731   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0          5.407796            0.024226  \n",
       "1          5.556631            0.032258  \n",
       "2          5.186659            0.037682  \n",
       "3          4.805482            0.069583  \n",
       "4          4.350269            0.094523  \n",
       "5          4.058649            0.117537  \n",
       "6          3.270326            0.142062  \n",
       "7          2.658338            0.153970  \n",
       "8          2.042202            0.147854  \n",
       "9          1.464331            0.127195  \n",
       "10         1.034699            0.104859  \n",
       "11         0.774736            0.089732  \n",
       "12         0.351238            0.045767  \n",
       "13         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = h2o.get_model('DRF_1_AutoML_20210715_105150')\n",
    "# perf = model.model_performance(X_test_hex)\n",
    "model.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "perfect-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The `auc_type` parameter is set but it is not used because the `test_data` parameter is None.\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.07755676675178935\n",
      "RMSE: 0.2784901555742848\n",
      "LogLoss: 0.3000466973600749\n",
      "Mean Per-Class Error: 0.3967426312768554\n",
      "AUC: 0.6385034425945992\n",
      "AUCPR: 0.9590462396821524\n",
      "Gini: 0.27700688518919847\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6421055610570181: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(596.0/596.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8033.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/8033.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8629.0</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>(596.0/8629.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1   Error             Rate\n",
       "0      0  0.0   596.0     1.0    (596.0/596.0)\n",
       "1      1  0.0  8033.0     0.0     (0.0/8033.0)\n",
       "2  Total  0.0  8629.0  0.0691   (596.0/8629.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>0.964230</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>0.985378</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.673029</td>\n",
       "      <td>0.944093</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.650834</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.775494</td>\n",
       "      <td>0.110888</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.795998</td>\n",
       "      <td>0.592282</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.785277</td>\n",
       "      <td>0.603257</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>8030.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>8033.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.975334</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.642106     0.964230  399.0\n",
       "1                        max f2   0.642106     0.985378  399.0\n",
       "2                  max f0point5   0.673029     0.944093  393.0\n",
       "3                  max accuracy   0.650834     0.930931  398.0\n",
       "4                 max precision   0.975334     1.000000    0.0\n",
       "5                    max recall   0.642106     1.000000  399.0\n",
       "6               max specificity   0.975334     1.000000    0.0\n",
       "7              max absolute_mcc   0.775494     0.110888  277.0\n",
       "8    max min_per_class_accuracy   0.795998     0.592282  239.0\n",
       "9   max mean_per_class_accuracy   0.785277     0.603257  259.0\n",
       "10                      max tns   0.975334   596.000000    0.0\n",
       "11                      max fns   0.975334  8030.000000    0.0\n",
       "12                      max fps   0.642106   596.000000  399.0\n",
       "13                      max tps   0.642106  8033.000000  399.0\n",
       "14                      max tnr   0.975334     1.000000    0.0\n",
       "15                      max fnr   0.975334     0.999627    0.0\n",
       "16                      max fpr   0.642106     1.000000  399.0\n",
       "17                      max tpr   0.642106     1.000000  399.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 93.09 %, avg score: 81.53 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010082</td>\n",
       "      <td>0.952548</td>\n",
       "      <td>1.061847</td>\n",
       "      <td>1.061847</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.959110</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>6.184689</td>\n",
       "      <td>6.184689</td>\n",
       "      <td>0.009028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>0.942285</td>\n",
       "      <td>1.061703</td>\n",
       "      <td>1.061776</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.946734</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.952958</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.021287</td>\n",
       "      <td>6.170332</td>\n",
       "      <td>6.177552</td>\n",
       "      <td>0.017931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030015</td>\n",
       "      <td>0.936173</td>\n",
       "      <td>1.061703</td>\n",
       "      <td>1.061752</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.939977</td>\n",
       "      <td>0.988417</td>\n",
       "      <td>0.948648</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>6.170332</td>\n",
       "      <td>6.175155</td>\n",
       "      <td>0.026835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>0.929962</td>\n",
       "      <td>1.049500</td>\n",
       "      <td>1.058671</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.932843</td>\n",
       "      <td>0.985549</td>\n",
       "      <td>0.944674</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.042450</td>\n",
       "      <td>4.949984</td>\n",
       "      <td>5.867092</td>\n",
       "      <td>0.034061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050064</td>\n",
       "      <td>0.923785</td>\n",
       "      <td>1.061703</td>\n",
       "      <td>1.059275</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.926734</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.941103</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.053031</td>\n",
       "      <td>6.170332</td>\n",
       "      <td>5.927459</td>\n",
       "      <td>0.042964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.900621</td>\n",
       "      <td>1.056748</td>\n",
       "      <td>1.058013</td>\n",
       "      <td>0.983759</td>\n",
       "      <td>0.912040</td>\n",
       "      <td>0.984936</td>\n",
       "      <td>0.926588</td>\n",
       "      <td>0.052782</td>\n",
       "      <td>0.105814</td>\n",
       "      <td>5.674764</td>\n",
       "      <td>5.801258</td>\n",
       "      <td>0.084001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150075</td>\n",
       "      <td>0.881964</td>\n",
       "      <td>1.036896</td>\n",
       "      <td>1.050968</td>\n",
       "      <td>0.965278</td>\n",
       "      <td>0.890936</td>\n",
       "      <td>0.978378</td>\n",
       "      <td>0.914695</td>\n",
       "      <td>0.051911</td>\n",
       "      <td>0.157724</td>\n",
       "      <td>3.689555</td>\n",
       "      <td>5.096813</td>\n",
       "      <td>0.110745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>0.867952</td>\n",
       "      <td>1.034317</td>\n",
       "      <td>1.046810</td>\n",
       "      <td>0.962877</td>\n",
       "      <td>0.874651</td>\n",
       "      <td>0.974508</td>\n",
       "      <td>0.904696</td>\n",
       "      <td>0.051662</td>\n",
       "      <td>0.209386</td>\n",
       "      <td>3.431668</td>\n",
       "      <td>4.681009</td>\n",
       "      <td>0.135561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300035</td>\n",
       "      <td>0.846716</td>\n",
       "      <td>1.030629</td>\n",
       "      <td>1.041416</td>\n",
       "      <td>0.959444</td>\n",
       "      <td>0.856551</td>\n",
       "      <td>0.969486</td>\n",
       "      <td>0.888647</td>\n",
       "      <td>0.103075</td>\n",
       "      <td>0.312461</td>\n",
       "      <td>3.062873</td>\n",
       "      <td>4.141631</td>\n",
       "      <td>0.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400046</td>\n",
       "      <td>0.828625</td>\n",
       "      <td>0.997021</td>\n",
       "      <td>1.030318</td>\n",
       "      <td>0.928158</td>\n",
       "      <td>0.837695</td>\n",
       "      <td>0.959154</td>\n",
       "      <td>0.875909</td>\n",
       "      <td>0.099714</td>\n",
       "      <td>0.412175</td>\n",
       "      <td>-0.297873</td>\n",
       "      <td>3.031755</td>\n",
       "      <td>0.175598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500058</td>\n",
       "      <td>0.810195</td>\n",
       "      <td>1.009468</td>\n",
       "      <td>1.026148</td>\n",
       "      <td>0.939745</td>\n",
       "      <td>0.819247</td>\n",
       "      <td>0.955272</td>\n",
       "      <td>0.864577</td>\n",
       "      <td>0.100959</td>\n",
       "      <td>0.513133</td>\n",
       "      <td>0.946847</td>\n",
       "      <td>2.614773</td>\n",
       "      <td>0.189308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.599954</td>\n",
       "      <td>0.791661</td>\n",
       "      <td>1.001916</td>\n",
       "      <td>1.022113</td>\n",
       "      <td>0.932715</td>\n",
       "      <td>0.800863</td>\n",
       "      <td>0.951516</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.100087</td>\n",
       "      <td>0.613220</td>\n",
       "      <td>0.191640</td>\n",
       "      <td>2.211308</td>\n",
       "      <td>0.192080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699965</td>\n",
       "      <td>0.776510</td>\n",
       "      <td>1.000755</td>\n",
       "      <td>1.019061</td>\n",
       "      <td>0.931634</td>\n",
       "      <td>0.784389</td>\n",
       "      <td>0.948675</td>\n",
       "      <td>0.844027</td>\n",
       "      <td>0.100087</td>\n",
       "      <td>0.713308</td>\n",
       "      <td>0.075543</td>\n",
       "      <td>1.906148</td>\n",
       "      <td>0.193173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799977</td>\n",
       "      <td>0.761303</td>\n",
       "      <td>0.959680</td>\n",
       "      <td>1.011638</td>\n",
       "      <td>0.893395</td>\n",
       "      <td>0.769621</td>\n",
       "      <td>0.941764</td>\n",
       "      <td>0.834725</td>\n",
       "      <td>0.095979</td>\n",
       "      <td>0.809287</td>\n",
       "      <td>-4.032035</td>\n",
       "      <td>1.163767</td>\n",
       "      <td>0.134790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899988</td>\n",
       "      <td>0.740448</td>\n",
       "      <td>0.952211</td>\n",
       "      <td>1.005034</td>\n",
       "      <td>0.886443</td>\n",
       "      <td>0.751584</td>\n",
       "      <td>0.935617</td>\n",
       "      <td>0.825486</td>\n",
       "      <td>0.095232</td>\n",
       "      <td>0.904519</td>\n",
       "      <td>-4.778868</td>\n",
       "      <td>0.503390</td>\n",
       "      <td>0.065593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641929</td>\n",
       "      <td>0.954701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888760</td>\n",
       "      <td>0.723873</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>0.815323</td>\n",
       "      <td>0.095481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.529924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010082         0.952548  1.061847   \n",
       "1       2                  0.020049         0.942285  1.061703   \n",
       "2       3                  0.030015         0.936173  1.061703   \n",
       "3       4                  0.040097         0.929962  1.049500   \n",
       "4       5                  0.050064         0.923785  1.061703   \n",
       "5       6                  0.100012         0.900621  1.056748   \n",
       "6       7                  0.150075         0.881964  1.036896   \n",
       "7       8                  0.200023         0.867952  1.034317   \n",
       "8       9                  0.300035         0.846716  1.030629   \n",
       "9      10                  0.400046         0.828625  0.997021   \n",
       "10     11                  0.500058         0.810195  1.009468   \n",
       "11     12                  0.599954         0.791661  1.001916   \n",
       "12     13                  0.699965         0.776510  1.000755   \n",
       "13     14                  0.799977         0.761303  0.959680   \n",
       "14     15                  0.899988         0.740448  0.952211   \n",
       "15     16                  1.000000         0.641929  0.954701   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.061847       0.988506  0.959110                  0.988506   \n",
       "1          1.061776       0.988372  0.946734                  0.988439   \n",
       "2          1.061752       0.988372  0.939977                  0.988417   \n",
       "3          1.058671       0.977011  0.932843                  0.985549   \n",
       "4          1.059275       0.988372  0.926734                  0.986111   \n",
       "5          1.058013       0.983759  0.912040                  0.984936   \n",
       "6          1.050968       0.965278  0.890936                  0.978378   \n",
       "7          1.046810       0.962877  0.874651                  0.974508   \n",
       "8          1.041416       0.959444  0.856551                  0.969486   \n",
       "9          1.030318       0.928158  0.837695                  0.959154   \n",
       "10         1.026148       0.939745  0.819247                  0.955272   \n",
       "11         1.022113       0.932715  0.800863                  0.951516   \n",
       "12         1.019061       0.931634  0.784389                  0.948675   \n",
       "13         1.011638       0.893395  0.769621                  0.941764   \n",
       "14         1.005034       0.886443  0.751584                  0.935617   \n",
       "15         1.000000       0.888760  0.723873                  0.930931   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate      gain  \\\n",
       "0           0.959110      0.010706                 0.010706  6.184689   \n",
       "1           0.952958      0.010581                 0.021287  6.170332   \n",
       "2           0.948648      0.010581                 0.031869  6.170332   \n",
       "3           0.944674      0.010581                 0.042450  4.949984   \n",
       "4           0.941103      0.010581                 0.053031  6.170332   \n",
       "5           0.926588      0.052782                 0.105814  5.674764   \n",
       "6           0.914695      0.051911                 0.157724  3.689555   \n",
       "7           0.904696      0.051662                 0.209386  3.431668   \n",
       "8           0.888647      0.103075                 0.312461  3.062873   \n",
       "9           0.875909      0.099714                 0.412175 -0.297873   \n",
       "10          0.864577      0.100959                 0.513133  0.946847   \n",
       "11          0.853968      0.100087                 0.613220  0.191640   \n",
       "12          0.844027      0.100087                 0.713308  0.075543   \n",
       "13          0.834725      0.095979                 0.809287 -4.032035   \n",
       "14          0.825486      0.095232                 0.904519 -4.778868   \n",
       "15          0.815323      0.095481                 1.000000 -4.529924   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0          6.184689            0.009028  \n",
       "1          6.177552            0.017931  \n",
       "2          6.175155            0.026835  \n",
       "3          5.867092            0.034061  \n",
       "4          5.927459            0.042964  \n",
       "5          5.801258            0.084001  \n",
       "6          5.096813            0.110745  \n",
       "7          4.681009            0.135561  \n",
       "8          4.141631            0.179911  \n",
       "9          3.031755            0.175598  \n",
       "10         2.614773            0.189308  \n",
       "11         2.211308            0.192080  \n",
       "12         1.906148            0.193173  \n",
       "13         1.163767            0.134790  \n",
       "14         0.503390            0.065593  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = h2o.get_model('DeepLearning_1_AutoML_20210715_105150')\n",
    "# perf = model.model_performance(X_test_hex)\n",
    "model.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "parliamentary-rouge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The `auc_type` parameter is set but it is not used because the `test_data` parameter is None.\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.06314625649140404\n",
      "RMSE: 0.25128918896642577\n",
      "LogLoss: 0.24171345286601462\n",
      "Null degrees of freedom: 8628\n",
      "Residual degrees of freedom: 8514\n",
      "Null deviance: 4335.643455378077\n",
      "Residual deviance: 4171.49076956168\n",
      "AIC: 4401.49076956168\n",
      "AUC: 0.6570337583976166\n",
      "AUCPR: 0.9614293349883738\n",
      "Gini: 0.31406751679523315\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8395718159346054: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(596.0/596.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8033.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(0.0/8033.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8629.0</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>(596.0/8629.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1   Error             Rate\n",
       "0      0  0.0   596.0     1.0    (596.0/596.0)\n",
       "1      1  0.0  8033.0     0.0     (0.0/8033.0)\n",
       "2  Total  0.0  8629.0  0.0691   (596.0/8629.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.964230</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.985378</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.850332</td>\n",
       "      <td>0.944002</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.987140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.987140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.921979</td>\n",
       "      <td>0.123242</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.921790</td>\n",
       "      <td>0.615212</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.922247</td>\n",
       "      <td>0.619370</td>\n",
       "      <td>205.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.987140</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.987140</td>\n",
       "      <td>8030.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.847731</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>8033.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.987140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.987140</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.847731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.839572     0.964230  399.0\n",
       "1                        max f2   0.839572     0.985378  399.0\n",
       "2                  max f0point5   0.850332     0.944002  396.0\n",
       "3                  max accuracy   0.839572     0.930931  399.0\n",
       "4                 max precision   0.987140     1.000000    0.0\n",
       "5                    max recall   0.839572     1.000000  399.0\n",
       "6               max specificity   0.987140     1.000000    0.0\n",
       "7              max absolute_mcc   0.921979     0.123242  206.0\n",
       "8    max min_per_class_accuracy   0.921790     0.615212  207.0\n",
       "9   max mean_per_class_accuracy   0.922247     0.619370  205.0\n",
       "10                      max tns   0.987140   596.000000    0.0\n",
       "11                      max fns   0.987140  8030.000000    0.0\n",
       "12                      max fps   0.847731   596.000000  397.0\n",
       "13                      max tps   0.839572  8033.000000  399.0\n",
       "14                      max tnr   0.987140     1.000000    0.0\n",
       "15                      max fnr   0.987140     0.999627    0.0\n",
       "16                      max fpr   0.847731     1.000000  397.0\n",
       "17                      max tpr   0.839572     1.000000  399.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 93.09 %, avg score: 93.09 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.980417</td>\n",
       "      <td>1.050585</td>\n",
       "      <td>1.050585</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.982086</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.982086</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>5.058529</td>\n",
       "      <td>5.058529</td>\n",
       "      <td>0.007724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>0.979302</td>\n",
       "      <td>1.061094</td>\n",
       "      <td>1.055566</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.979791</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.980998</td>\n",
       "      <td>0.010083</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>6.109402</td>\n",
       "      <td>5.556631</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030015</td>\n",
       "      <td>0.976101</td>\n",
       "      <td>1.074194</td>\n",
       "      <td>1.061752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977463</td>\n",
       "      <td>0.988417</td>\n",
       "      <td>0.979824</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>7.419395</td>\n",
       "      <td>6.175155</td>\n",
       "      <td>0.026835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>0.974295</td>\n",
       "      <td>1.074194</td>\n",
       "      <td>1.064880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975209</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>0.978664</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.042699</td>\n",
       "      <td>7.419395</td>\n",
       "      <td>6.488013</td>\n",
       "      <td>0.037665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050064</td>\n",
       "      <td>0.972883</td>\n",
       "      <td>1.036722</td>\n",
       "      <td>1.059275</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.973685</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.977673</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.053031</td>\n",
       "      <td>3.672207</td>\n",
       "      <td>5.927459</td>\n",
       "      <td>0.042964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.967524</td>\n",
       "      <td>1.049271</td>\n",
       "      <td>1.054278</td>\n",
       "      <td>0.976798</td>\n",
       "      <td>0.969892</td>\n",
       "      <td>0.981460</td>\n",
       "      <td>0.973787</td>\n",
       "      <td>0.052409</td>\n",
       "      <td>0.105440</td>\n",
       "      <td>4.927066</td>\n",
       "      <td>5.427842</td>\n",
       "      <td>0.078594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150075</td>\n",
       "      <td>0.962859</td>\n",
       "      <td>1.061761</td>\n",
       "      <td>1.056775</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>0.965277</td>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.053156</td>\n",
       "      <td>0.158596</td>\n",
       "      <td>6.176115</td>\n",
       "      <td>5.677459</td>\n",
       "      <td>0.123361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>0.958641</td>\n",
       "      <td>1.041794</td>\n",
       "      <td>1.053034</td>\n",
       "      <td>0.969838</td>\n",
       "      <td>0.960889</td>\n",
       "      <td>0.980301</td>\n",
       "      <td>0.968436</td>\n",
       "      <td>0.052035</td>\n",
       "      <td>0.210631</td>\n",
       "      <td>4.179367</td>\n",
       "      <td>5.303370</td>\n",
       "      <td>0.153584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300498</td>\n",
       "      <td>0.949890</td>\n",
       "      <td>1.030830</td>\n",
       "      <td>1.045610</td>\n",
       "      <td>0.959631</td>\n",
       "      <td>0.954084</td>\n",
       "      <td>0.973390</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.103573</td>\n",
       "      <td>0.314204</td>\n",
       "      <td>3.082972</td>\n",
       "      <td>4.560954</td>\n",
       "      <td>0.198432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400046</td>\n",
       "      <td>0.940783</td>\n",
       "      <td>1.007917</td>\n",
       "      <td>1.036230</td>\n",
       "      <td>0.938300</td>\n",
       "      <td>0.945184</td>\n",
       "      <td>0.964658</td>\n",
       "      <td>0.959045</td>\n",
       "      <td>0.100336</td>\n",
       "      <td>0.414540</td>\n",
       "      <td>0.791656</td>\n",
       "      <td>3.622997</td>\n",
       "      <td>0.209842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500174</td>\n",
       "      <td>0.930267</td>\n",
       "      <td>1.007057</td>\n",
       "      <td>1.030390</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.935209</td>\n",
       "      <td>0.959222</td>\n",
       "      <td>0.954274</td>\n",
       "      <td>0.100834</td>\n",
       "      <td>0.515374</td>\n",
       "      <td>0.705683</td>\n",
       "      <td>3.038993</td>\n",
       "      <td>0.220072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.599954</td>\n",
       "      <td>0.921500</td>\n",
       "      <td>1.009318</td>\n",
       "      <td>1.026885</td>\n",
       "      <td>0.939605</td>\n",
       "      <td>0.925730</td>\n",
       "      <td>0.955959</td>\n",
       "      <td>0.949527</td>\n",
       "      <td>0.100710</td>\n",
       "      <td>0.616084</td>\n",
       "      <td>0.931812</td>\n",
       "      <td>2.688543</td>\n",
       "      <td>0.233533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.700313</td>\n",
       "      <td>0.913863</td>\n",
       "      <td>0.983644</td>\n",
       "      <td>1.020689</td>\n",
       "      <td>0.915704</td>\n",
       "      <td>0.917456</td>\n",
       "      <td>0.950190</td>\n",
       "      <td>0.944931</td>\n",
       "      <td>0.098718</td>\n",
       "      <td>0.714801</td>\n",
       "      <td>-1.635589</td>\n",
       "      <td>2.068867</td>\n",
       "      <td>0.209768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.800093</td>\n",
       "      <td>0.906000</td>\n",
       "      <td>0.960661</td>\n",
       "      <td>1.013203</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.909903</td>\n",
       "      <td>0.943221</td>\n",
       "      <td>0.940562</td>\n",
       "      <td>0.095855</td>\n",
       "      <td>0.810656</td>\n",
       "      <td>-3.933874</td>\n",
       "      <td>1.320264</td>\n",
       "      <td>0.152938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899988</td>\n",
       "      <td>0.895355</td>\n",
       "      <td>0.954562</td>\n",
       "      <td>1.006694</td>\n",
       "      <td>0.888631</td>\n",
       "      <td>0.900763</td>\n",
       "      <td>0.937162</td>\n",
       "      <td>0.936145</td>\n",
       "      <td>0.095357</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>-4.543786</td>\n",
       "      <td>0.669374</td>\n",
       "      <td>0.087221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.939764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874855</td>\n",
       "      <td>0.884008</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>0.930931</td>\n",
       "      <td>0.093987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-6.023588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold      lift  \\\n",
       "0       1                  0.010546         0.980417  1.050585   \n",
       "1       2                  0.020049         0.979302  1.061094   \n",
       "2       3                  0.030015         0.976101  1.074194   \n",
       "3       4                  0.040097         0.974295  1.074194   \n",
       "4       5                  0.050064         0.972883  1.036722   \n",
       "5       6                  0.100012         0.967524  1.049271   \n",
       "6       7                  0.150075         0.962859  1.061761   \n",
       "7       8                  0.200023         0.958641  1.041794   \n",
       "8       9                  0.300498         0.949890  1.030830   \n",
       "9      10                  0.400046         0.940783  1.007917   \n",
       "10     11                  0.500174         0.930267  1.007057   \n",
       "11     12                  0.599954         0.921500  1.009318   \n",
       "12     13                  0.700313         0.913863  0.983644   \n",
       "13     14                  0.800093         0.906000  0.960661   \n",
       "14     15                  0.899988         0.895355  0.954562   \n",
       "15     16                  1.000000         0.839572  0.939764   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0          1.050585       0.978022  0.982086                  0.978022   \n",
       "1          1.055566       0.987805  0.979791                  0.982659   \n",
       "2          1.061752       1.000000  0.977463                  0.988417   \n",
       "3          1.064880       1.000000  0.975209                  0.991329   \n",
       "4          1.059275       0.965116  0.973685                  0.986111   \n",
       "5          1.054278       0.976798  0.969892                  0.981460   \n",
       "6          1.056775       0.988426  0.965277                  0.983784   \n",
       "7          1.053034       0.969838  0.960889                  0.980301   \n",
       "8          1.045610       0.959631  0.954084                  0.973390   \n",
       "9          1.036230       0.938300  0.945184                  0.964658   \n",
       "10         1.030390       0.937500  0.935209                  0.959222   \n",
       "11         1.026885       0.939605  0.925730                  0.955959   \n",
       "12         1.020689       0.915704  0.917456                  0.950190   \n",
       "13         1.013203       0.894309  0.909903                  0.943221   \n",
       "14         1.006694       0.888631  0.900763                  0.937162   \n",
       "15         1.000000       0.874855  0.884008                  0.930931   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate      gain  \\\n",
       "0           0.982086      0.011079                 0.011079  5.058529   \n",
       "1           0.980998      0.010083                 0.021163  6.109402   \n",
       "2           0.979824      0.010706                 0.031869  7.419395   \n",
       "3           0.978664      0.010830                 0.042699  7.419395   \n",
       "4           0.977673      0.010332                 0.053031  3.672207   \n",
       "5           0.973787      0.052409                 0.105440  4.927066   \n",
       "6           0.970948      0.053156                 0.158596  6.176115   \n",
       "7           0.968436      0.052035                 0.210631  4.179367   \n",
       "8           0.963638      0.103573                 0.314204  3.082972   \n",
       "9           0.959045      0.100336                 0.414540  0.791656   \n",
       "10          0.954274      0.100834                 0.515374  0.705683   \n",
       "11          0.949527      0.100710                 0.616084  0.931812   \n",
       "12          0.944931      0.098718                 0.714801 -1.635589   \n",
       "13          0.940562      0.095855                 0.810656 -3.933874   \n",
       "14          0.936145      0.095357                 0.906013 -4.543786   \n",
       "15          0.930931      0.093987                 1.000000 -6.023588   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0          5.058529            0.007724  \n",
       "1          5.556631            0.016129  \n",
       "2          6.175155            0.026835  \n",
       "3          6.488013            0.037665  \n",
       "4          5.927459            0.042964  \n",
       "5          5.427842            0.078594  \n",
       "6          5.677459            0.123361  \n",
       "7          5.303370            0.153584  \n",
       "8          4.560954            0.198432  \n",
       "9          3.622997            0.209842  \n",
       "10         3.038993            0.220072  \n",
       "11         2.688543            0.233533  \n",
       "12         2.068867            0.209768  \n",
       "13         1.320264            0.152938  \n",
       "14         0.669374            0.087221  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = h2o.get_model('GLM_1_AutoML_20210715_105150')\n",
    "# perf = model.model_performance(X_test_hex)\n",
    "model.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "closing-european",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\mlp\\lib\\site-packages\\h2o\\estimators\\estimator_base.py:200: RuntimeWarning: Dropping bad and constant columns: [have_series_c]\n",
      "  warnings.warn(mesg[\"message\"], RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "WARNING: The `auc_type` parameter is set but it is not used because the `test_data` parameter is None.\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "pros_gbm = H2OGradientBoostingEstimator(nfolds=5,\n",
    "                                        seed=1234,\n",
    "                                        keep_cross_validation_predictions = True)\n",
    "pros_gbm.train(x=X_names, y='status', training_frame=X_train_hex)\n",
    "\n",
    "# Eval performance:\n",
    "perf = pros_gbm.model_performance(X_test_hex)\n",
    "# Generate predictions on a test set (if necessary):\n",
    "# pred = pros_gbm.predict()\n",
    "\n",
    "# Extract feature interactions:\n",
    "# feature_interactions = pros_gbm.feature_interaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "continent-active",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  C1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pros_gbm.predict(X_test_hex)\n",
    "# pred['predict'].unique()\n",
    "\n",
    "# print(train.loc[train['status']==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "south-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H2OProbWrapper:\n",
    "    def __init__(self, h2o_model, feature_names):\n",
    "        self.h2o_model = h2o_model\n",
    "        self.feature_names = feature_names\n",
    "    def predict_binary_prob(self, X):\n",
    "        if isinstance(X, pd.Series):\n",
    "            X = X.values.reshape(1,-1)\n",
    "        self.dataframe= pd.DataFrame(X, columns=self.feature_names)\n",
    "        self.predictions = self.h2o_model.predict(h2o.H2OFrame(self.dataframe)).as_data_frame().values\n",
    "        return self.predictions.astype('float64')[:,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "frequent-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_wrapper = H2OProbWrapper(model,X_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "worldwide-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.39.0-cp36-cp36m-win_amd64.whl (414 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from shap) (1.1.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from shap) (1.19.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from shap) (4.56.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from shap) (0.24.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from shap) (1.5.2)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting numba\n",
      "  Downloading numba-0.53.1-cp36-cp36m-win_amd64.whl (2.3 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from numba->shap) (52.0.0.post20210125)\n",
      "Collecting llvmlite<0.37,>=0.36.0rc1\n",
      "  Downloading llvmlite-0.36.0-cp36-cp36m-win_amd64.whl (16.0 MB)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from pandas->shap) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from pandas->shap) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from scikit-learn->shap) (1.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\administrator\\anaconda3\\envs\\mlp\\lib\\site-packages (from scikit-learn->shap) (2.1.0)\n",
      "Installing collected packages: llvmlite, slicer, numba, shap\n",
      "Successfully installed llvmlite-0.36.0 numba-0.53.1 shap-0.39.0 slicer-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "touched-reply",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Unknown type passed as data object: <class 'h2o.frame.H2OFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-d4b152eda47f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKernelExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2o_wrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_binary_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_hex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mxgboost_shap_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlp\\lib\\site-packages\\shap\\explainers\\_kernel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, data, link, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"keep_index\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_index_ordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"keep_index_ordered\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[0mmodel_null\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch_model_to_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlp\\lib\\site-packages\\shap\\utils\\_legacy.py\u001b[0m in \u001b[0;36mconvert_to_data\u001b[1;34m(val, keep_index)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mSparseData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Unknown type passed as data object: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mLink\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Unknown type passed as data object: <class 'h2o.frame.H2OFrame'>"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "explainer = shap.KernelExplainer(h2o_wrapper.predict_binary_prob, X_test_hex)\n",
    "xgboost_shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-advertising",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(xgboost_shap_values, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
