{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d96b8ed6bbfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_sts_dataset(filename):\n",
    "    # Loads a subset of the STS dataset into a DataFrame. In particular both\n",
    "    # sentences and their human rated similarity score.\n",
    "    sent_pairs = []\n",
    "    with tf.gfile.GFile(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            ts = line.strip().split(\"\\t\")\n",
    "            sent_pairs.append((ts[5], ts[6], float(ts[4])))\n",
    "    return pd.DataFrame(sent_pairs, columns=[\"sent_1\", \"sent_2\", \"sim\"])\n",
    "\n",
    "\n",
    "def download_and_load_sts_data():\n",
    "    sts_dataset = tf.keras.utils.get_file(\n",
    "        fname=\"Stsbenchmark.tar.gz\",\n",
    "        origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n",
    "        extract=True)\n",
    "\n",
    "    sts_dev = load_sts_dataset(os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"))\n",
    "    sts_test = load_sts_dataset(os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"))\n",
    "\n",
    "    return sts_dev, sts_test\n",
    "\n",
    "sts_dev, sts_test = download_and_load_sts_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-macosx_10_11_x86_64.whl (195.7 MB)\n",
      "\u001b[K     |▎                               | 1.8 MB 85 kB/s eta 0:37:587^C\n",
      "\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 61]\n",
      "[nltk_data]     Connection refused>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 61] Connection\n",
      "[nltk_data]     refused>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "STOP = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "class Sentence:\n",
    "    \n",
    "    def __init__(self, sentence):\n",
    "        self.raw = sentence\n",
    "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\").replace(\",\",\"\").replace(\".\",\"\").replace(\"'\",\"\")\n",
    "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]\n",
    "        self.tokens_without_stop = [t for t in self.tokens if t not in STOP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = Sentence(\"Wetpaint is a technology platform company that uses its proprietary state-of-the-art technology and expertise in social media to build and monetize audiences for digital publishers. Wetpaint’s own online property, Wetpaint Entertainment, an entertainment news site that attracts more than 12 million unique visitors monthly and has over 2 million Facebook fans, is a proof point to the company’s success in building and engaging audiences. Media companies can license Wetpaint’s platform which includes a dynamic playbook tailored to their individual needs and comprehensive training. Founded by Internet pioneer Ben Elowitz, and with offices in New York and Seattle, Wetpaint is backed by Accel Partners, the investors behind Facebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wetpaint',\n",
       " 'technology',\n",
       " 'platform',\n",
       " 'company',\n",
       " 'uses',\n",
       " 'proprietary',\n",
       " 'state-of-the-art',\n",
       " 'technology',\n",
       " 'expertise',\n",
       " 'social',\n",
       " 'media',\n",
       " 'build',\n",
       " 'monetize',\n",
       " 'audiences',\n",
       " 'digital',\n",
       " 'publishers',\n",
       " 'wetpaints',\n",
       " 'online',\n",
       " 'property',\n",
       " 'wetpaint',\n",
       " 'entertainment',\n",
       " 'entertainment',\n",
       " 'news',\n",
       " 'site',\n",
       " 'attracts',\n",
       " '12',\n",
       " 'million',\n",
       " 'unique',\n",
       " 'visitors',\n",
       " 'monthly',\n",
       " '2',\n",
       " 'million',\n",
       " 'facebook',\n",
       " 'fans',\n",
       " 'proof',\n",
       " 'point',\n",
       " 'companys',\n",
       " 'success',\n",
       " 'building',\n",
       " 'engaging',\n",
       " 'audiences',\n",
       " 'media',\n",
       " 'companies',\n",
       " 'license',\n",
       " 'wetpaints',\n",
       " 'platform',\n",
       " 'includes',\n",
       " 'dynamic',\n",
       " 'playbook',\n",
       " 'tailored',\n",
       " 'individual',\n",
       " 'needs',\n",
       " 'comprehensive',\n",
       " 'training',\n",
       " 'founded',\n",
       " 'internet',\n",
       " 'pioneer',\n",
       " 'ben',\n",
       " 'elowitz',\n",
       " 'offices',\n",
       " 'new',\n",
       " 'york',\n",
       " 'seattle',\n",
       " 'wetpaint',\n",
       " 'backed',\n",
       " 'accel',\n",
       " 'partners',\n",
       " 'investors',\n",
       " 'behind',\n",
       " 'facebook']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.tokens_without_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH_TO_WORD2VEC = os.path.expanduser(\"data/GoogleNews-vectors-negative300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(PATH_TO_WORD2VEC, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "PATH_TO_FREQUENCIES_FILE = \"data/frequencies.tsv\"\n",
    "PATH_TO_DOC_FREQUENCIES_FILE = \"data/doc_frequencies.tsv\"\n",
    "\n",
    "def read_tsv(f):\n",
    "    frequencies = {}\n",
    "    with open(f) as tsv:\n",
    "        tsv_reader = csv.reader(tsv, delimiter=\"\\t\")\n",
    "        for row in tsv_reader: \n",
    "            frequencies[row[0]] = int(row[1])\n",
    "        \n",
    "    return frequencies\n",
    "        \n",
    "frequencies = read_tsv(PATH_TO_FREQUENCIES_FILE)\n",
    "doc_frequencies = read_tsv(PATH_TO_DOC_FREQUENCIES_FILE)\n",
    "doc_frequencies[\"NUM_DOCS\"] = 1288431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def run_avg_benchmark(sentences1, sentences2, model=None, use_stoplist=False, doc_freqs=None): \n",
    "\n",
    "    if doc_freqs is not None:\n",
    "        N = doc_freqs[\"NUM_DOCS\"]\n",
    "    \n",
    "    tokens1 = sentences1.tokens_without_stop if use_stoplist else sentences1.tokens\n",
    "    tokens2 = sentences2.tokens_without_stop if use_stoplist else sentences2.tokens\n",
    "\n",
    "    tokens1 = [token for token in tokens1 if token in model]\n",
    "    tokens2 = [token for token in tokens2 if token in model]\n",
    "\n",
    "#     if len(tokens1) == 0 or len(tokens2) == 0:\n",
    "#         sims.append(0)\n",
    "#         continue\n",
    "\n",
    "    tokfreqs1 = Counter(tokens1)\n",
    "    tokfreqs2 = Counter(tokens2)\n",
    "\n",
    "    weights1 = [tokfreqs1[token] * math.log(N/(doc_freqs.get(token, 0)+1)) \n",
    "                for token in tokfreqs1] if doc_freqs else None\n",
    "    weights2 = [tokfreqs2[token] * math.log(N/(doc_freqs.get(token, 0)+1)) \n",
    "                for token in tokfreqs2] if doc_freqs else None\n",
    "\n",
    "    embedding1 = np.average([model[token] for token in tokfreqs1], axis=0, weights=weights1).reshape(1, -1)\n",
    "    embedding2 = np.average([model[token] for token in tokfreqs2], axis=0, weights=weights2).reshape(1, -1)\n",
    "    sim = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "\n",
    "    return sim\n",
    "\n",
    "def run_wmd_benchmark(sent1, sent2, model, use_stoplist=False):\n",
    "\n",
    "    tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n",
    "    tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
    "\n",
    "    tokens1 = [token for token in tokens1 if token in model]\n",
    "    tokens2 = [token for token in tokens2 if token in model]\n",
    "\n",
    "    if len(tokens1) == 0 or len(tokens2) == 0:\n",
    "        tokens1 = [token for token in sent1.tokens if token in model]\n",
    "        tokens2 = [token for token in sent2.tokens if token in model]\n",
    "\n",
    "    sim = -model.wmdistance(tokens1, tokens2)\n",
    "        \n",
    "    return sim\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def remove_first_principal_component(X):\n",
    "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n",
    "    svd.fit(X)\n",
    "    pc = svd.components_\n",
    "    XX = X - X.dot(pc.transpose()) * pc\n",
    "    return XX\n",
    "\n",
    "\n",
    "def run_sif_benchmark(sent1, sent2, model, freqs={}, use_stoplist=False, a=0.001): \n",
    "    total_freq = sum(freqs.values())\n",
    "    embeddings = []\n",
    "    # SIF requires us to first collect all sentence embeddings and then perform \n",
    "    # common component analysis.\n",
    "    tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n",
    "    tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
    "\n",
    "    tokens1 = [token for token in tokens1 if token in model]\n",
    "    tokens2 = [token for token in tokens2 if token in model]\n",
    "\n",
    "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
    "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
    "\n",
    "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
    "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
    "\n",
    "    embeddings.append(embedding1)\n",
    "    embeddings.append(embedding2)\n",
    "        \n",
    "    embeddings = remove_first_principal_component(np.array(embeddings))\n",
    "    sim = [cosine_similarity(embeddings[idx*2].reshape(1, -1), \n",
    "                              embeddings[idx*2+1].reshape(1, -1))[0][0] \n",
    "            for idx in range(int(len(embeddings)/2))][0]\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                                               \n",
    "data = pd.read_csv(\"data/organization_descriptions.csv\")                               \n",
    "facebook = data[data[\"name\"] == \"Facebook\"][\"description\"]                        \n",
    "google = data[data[\"name\"] == \"Google\"][\"description\"]                            \n",
    "amazon = data[data[\"name\"] == \"Amazon\"][\"description\"]                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook = data[data[\"name\"] == \"Facebook\"][\"description\"]                        \n",
    "google = data[data[\"name\"] == \"Google\"][\"description\"]                            \n",
    "amazon = data[data[\"name\"] == \"Amazon\"][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148    Mark Zuckerberg is the founder and CEO of Face...\n",
       "Name: p_description, dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"name\"] == \"Facebook\"][\"p_description\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuxing/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (1,2,3,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "final_data = pd.read_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates([\"uuid\",\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>roles</th>\n",
       "      <th>status</th>\n",
       "      <th>short_description</th>\n",
       "      <th>category_list</th>\n",
       "      <th>category_groups_list</th>\n",
       "      <th>num_funding_rounds</th>\n",
       "      <th>employee_count</th>\n",
       "      <th>...</th>\n",
       "      <th>p_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>featured_job_title</th>\n",
       "      <th>p_description</th>\n",
       "      <th>d_uuid</th>\n",
       "      <th>d_name</th>\n",
       "      <th>ins_uuid</th>\n",
       "      <th>ins_name</th>\n",
       "      <th>degree_type</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1393508-30ea-8a36-3f96-dd3226033abd</td>\n",
       "      <td>Wetpaint</td>\n",
       "      <td>131437.0</td>\n",
       "      <td>company</td>\n",
       "      <td>acquired</td>\n",
       "      <td>Wetpaint offers an online social publishing pl...</td>\n",
       "      <td>Publishing,Social Media,Social Media Management</td>\n",
       "      <td>Content and Publishing,Internet Services,Media...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51-100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bf4d7b0e-b34d-2fd8-d292-6049c4f7efc7</td>\n",
       "      <td>Zoho</td>\n",
       "      <td>7682.0</td>\n",
       "      <td>investor,company</td>\n",
       "      <td>operating</td>\n",
       "      <td>Zoho offers a suite of business, collaboration...</td>\n",
       "      <td>Cloud Computing,Collaboration,CRM,Developer To...</td>\n",
       "      <td>Administrative Services,Information Technology...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-5000</td>\n",
       "      <td>...</td>\n",
       "      <td>Raju Vegesna</td>\n",
       "      <td>male</td>\n",
       "      <td>Chief Evangelist</td>\n",
       "      <td>Raju is an evangelist for Zoho and is one of t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5f2b40b8-d1b3-d323-d81a-b7a8e89553d0</td>\n",
       "      <td>Digg</td>\n",
       "      <td>13152.0</td>\n",
       "      <td>company</td>\n",
       "      <td>acquired</td>\n",
       "      <td>Digg Inc. operates a website that enables its ...</td>\n",
       "      <td>Internet,Social Media,Social Network</td>\n",
       "      <td>Internet Services,Media and Entertainment</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51-100</td>\n",
       "      <td>...</td>\n",
       "      <td>Joshua Auerbach</td>\n",
       "      <td>male</td>\n",
       "      <td>Board Member</td>\n",
       "      <td>Venture Partner at Betaworks Studio.   Formerl...</td>\n",
       "      <td>967b2ae6-5842-ca27-59b9-acd60b7b4c42</td>\n",
       "      <td>BA  Economics @ Harvard University</td>\n",
       "      <td>d8b57c0e-9f0f-4dcb-d207-a12a90c64a2d</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>BA</td>\n",
       "      <td>Economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>f4d5ab44-058b-298b-ea81-380e6e9a8eec</td>\n",
       "      <td>Omidyar Network</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>investor</td>\n",
       "      <td>operating</td>\n",
       "      <td>Omidyar Network is an investment firm.</td>\n",
       "      <td>Enterprise Software,Financial Services,Venture...</td>\n",
       "      <td>Financial Services,Lending and Investments,Sof...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101-250</td>\n",
       "      <td>...</td>\n",
       "      <td>Salvatore Giambanco</td>\n",
       "      <td>male</td>\n",
       "      <td>Partner of Human Capital &amp; Operations Functions</td>\n",
       "      <td>Sal leads the human capital and operations fun...</td>\n",
       "      <td>49ae5af2-25fe-b1d1-e19e-11f45a04a4c4</td>\n",
       "      <td>B.A.  Economics &amp; Political Science @ Columbia...</td>\n",
       "      <td>8d297d1e-3e3d-fadd-2963-57e0a40bff2a</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>B.A.</td>\n",
       "      <td>Economics &amp; Political Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>df662812-7f97-0b43-9d3e-12f64f504fbb</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>5.0</td>\n",
       "      <td>investor,company</td>\n",
       "      <td>ipo</td>\n",
       "      <td>Facebook is an online social networking servic...</td>\n",
       "      <td>Mobile Apps,Social,Social Media,Social Network...</td>\n",
       "      <td>Apps,Community and Lifestyle,Content and Publi...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10000+</td>\n",
       "      <td>...</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>male</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>Mark Zuckerberg is the founder and CEO of Face...</td>\n",
       "      <td>e75e1434-2ace-9255-2da8-3943f5bbae7c</td>\n",
       "      <td>Dropped Out  Computer Science @ Harvard Univer...</td>\n",
       "      <td>d8b57c0e-9f0f-4dcb-d207-a12a90c64a2d</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>Dropped Out</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718514</th>\n",
       "      <td>09c8e895-e62e-46f0-93f9-45e088ede007</td>\n",
       "      <td>AngelNV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>investor</td>\n",
       "      <td>operating</td>\n",
       "      <td>Early stage investor school and investment fun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718515</th>\n",
       "      <td>9b7c50d5-8d96-4af4-9b0e-af72705184e9</td>\n",
       "      <td>Science Delivered</td>\n",
       "      <td>NaN</td>\n",
       "      <td>company</td>\n",
       "      <td>operating</td>\n",
       "      <td>Science Delivered promote quality science educ...</td>\n",
       "      <td>Education</td>\n",
       "      <td>Education</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718516</th>\n",
       "      <td>98589112-e90c-434b-a4e7-ffaa12eee602</td>\n",
       "      <td>OmniPanel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>company</td>\n",
       "      <td>operating</td>\n",
       "      <td>OmniPanel is an analytics platform that surfac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718517</th>\n",
       "      <td>90418618-ce0c-49b2-8c0b-1f741a3d313e</td>\n",
       "      <td>Schafer Logistics Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>company</td>\n",
       "      <td>operating</td>\n",
       "      <td>Schafer Logistics Inc provides integrate exper...</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51-100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718518</th>\n",
       "      <td>8418f326-1ac2-4cb0-8ddf-2bee51e23546</td>\n",
       "      <td>True Footage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>company</td>\n",
       "      <td>operating</td>\n",
       "      <td>A real estate data authentication platform tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1216445 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         uuid                   name  \\\n",
       "0        e1393508-30ea-8a36-3f96-dd3226033abd               Wetpaint   \n",
       "1        bf4d7b0e-b34d-2fd8-d292-6049c4f7efc7                   Zoho   \n",
       "35       5f2b40b8-d1b3-d323-d81a-b7a8e89553d0                   Digg   \n",
       "38       f4d5ab44-058b-298b-ea81-380e6e9a8eec        Omidyar Network   \n",
       "148      df662812-7f97-0b43-9d3e-12f64f504fbb               Facebook   \n",
       "...                                       ...                    ...   \n",
       "1718514  09c8e895-e62e-46f0-93f9-45e088ede007                AngelNV   \n",
       "1718515  9b7c50d5-8d96-4af4-9b0e-af72705184e9      Science Delivered   \n",
       "1718516  98589112-e90c-434b-a4e7-ffaa12eee602              OmniPanel   \n",
       "1718517  90418618-ce0c-49b2-8c0b-1f741a3d313e  Schafer Logistics Inc   \n",
       "1718518  8418f326-1ac2-4cb0-8ddf-2bee51e23546           True Footage   \n",
       "\n",
       "             rank             roles     status  \\\n",
       "0        131437.0           company   acquired   \n",
       "1          7682.0  investor,company  operating   \n",
       "35        13152.0           company   acquired   \n",
       "38         1757.0          investor  operating   \n",
       "148           5.0  investor,company        ipo   \n",
       "...           ...               ...        ...   \n",
       "1718514       NaN          investor  operating   \n",
       "1718515       NaN           company  operating   \n",
       "1718516       NaN           company  operating   \n",
       "1718517       NaN           company  operating   \n",
       "1718518       NaN           company  operating   \n",
       "\n",
       "                                         short_description  \\\n",
       "0        Wetpaint offers an online social publishing pl...   \n",
       "1        Zoho offers a suite of business, collaboration...   \n",
       "35       Digg Inc. operates a website that enables its ...   \n",
       "38                  Omidyar Network is an investment firm.   \n",
       "148      Facebook is an online social networking servic...   \n",
       "...                                                    ...   \n",
       "1718514  Early stage investor school and investment fun...   \n",
       "1718515  Science Delivered promote quality science educ...   \n",
       "1718516  OmniPanel is an analytics platform that surfac...   \n",
       "1718517  Schafer Logistics Inc provides integrate exper...   \n",
       "1718518  A real estate data authentication platform tha...   \n",
       "\n",
       "                                             category_list  \\\n",
       "0          Publishing,Social Media,Social Media Management   \n",
       "1        Cloud Computing,Collaboration,CRM,Developer To...   \n",
       "35                    Internet,Social Media,Social Network   \n",
       "38       Enterprise Software,Financial Services,Venture...   \n",
       "148      Mobile Apps,Social,Social Media,Social Network...   \n",
       "...                                                    ...   \n",
       "1718514                                                NaN   \n",
       "1718515                                          Education   \n",
       "1718516                                                NaN   \n",
       "1718517                                     Transportation   \n",
       "1718518                                                NaN   \n",
       "\n",
       "                                      category_groups_list  \\\n",
       "0        Content and Publishing,Internet Services,Media...   \n",
       "1        Administrative Services,Information Technology...   \n",
       "35               Internet Services,Media and Entertainment   \n",
       "38       Financial Services,Lending and Investments,Sof...   \n",
       "148      Apps,Community and Lifestyle,Content and Publi...   \n",
       "...                                                    ...   \n",
       "1718514                                                NaN   \n",
       "1718515                                          Education   \n",
       "1718516                                                NaN   \n",
       "1718517                                     Transportation   \n",
       "1718518                                                NaN   \n",
       "\n",
       "         num_funding_rounds employee_count  ...               p_name gender  \\\n",
       "0                       3.0         51-100  ...                  NaN    NaN   \n",
       "1                       NaN      1001-5000  ...         Raju Vegesna   male   \n",
       "35                      6.0         51-100  ...      Joshua Auerbach   male   \n",
       "38                      NaN        101-250  ...  Salvatore Giambanco   male   \n",
       "148                    17.0         10000+  ...      Mark Zuckerberg   male   \n",
       "...                     ...            ...  ...                  ...    ...   \n",
       "1718514                 NaN        unknown  ...                  NaN    NaN   \n",
       "1718515                 NaN           1-10  ...                  NaN    NaN   \n",
       "1718516                 1.0        unknown  ...                  NaN    NaN   \n",
       "1718517                 NaN         51-100  ...                  NaN    NaN   \n",
       "1718518                 1.0        unknown  ...                  NaN    NaN   \n",
       "\n",
       "                                      featured_job_title  \\\n",
       "0                                                    NaN   \n",
       "1                                       Chief Evangelist   \n",
       "35                                          Board Member   \n",
       "38       Partner of Human Capital & Operations Functions   \n",
       "148                                        Founder & CEO   \n",
       "...                                                  ...   \n",
       "1718514                                              NaN   \n",
       "1718515                                              NaN   \n",
       "1718516                                              NaN   \n",
       "1718517                                              NaN   \n",
       "1718518                                              NaN   \n",
       "\n",
       "                                             p_description  \\\n",
       "0                                                      NaN   \n",
       "1        Raju is an evangelist for Zoho and is one of t...   \n",
       "35       Venture Partner at Betaworks Studio.   Formerl...   \n",
       "38       Sal leads the human capital and operations fun...   \n",
       "148      Mark Zuckerberg is the founder and CEO of Face...   \n",
       "...                                                    ...   \n",
       "1718514                                                NaN   \n",
       "1718515                                                NaN   \n",
       "1718516                                                NaN   \n",
       "1718517                                                NaN   \n",
       "1718518                                                NaN   \n",
       "\n",
       "                                       d_uuid  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "35       967b2ae6-5842-ca27-59b9-acd60b7b4c42   \n",
       "38       49ae5af2-25fe-b1d1-e19e-11f45a04a4c4   \n",
       "148      e75e1434-2ace-9255-2da8-3943f5bbae7c   \n",
       "...                                       ...   \n",
       "1718514                                   NaN   \n",
       "1718515                                   NaN   \n",
       "1718516                                   NaN   \n",
       "1718517                                   NaN   \n",
       "1718518                                   NaN   \n",
       "\n",
       "                                                    d_name  \\\n",
       "0                                                      NaN   \n",
       "1                                                      NaN   \n",
       "35                      BA  Economics @ Harvard University   \n",
       "38       B.A.  Economics & Political Science @ Columbia...   \n",
       "148      Dropped Out  Computer Science @ Harvard Univer...   \n",
       "...                                                    ...   \n",
       "1718514                                                NaN   \n",
       "1718515                                                NaN   \n",
       "1718516                                                NaN   \n",
       "1718517                                                NaN   \n",
       "1718518                                                NaN   \n",
       "\n",
       "                                     ins_uuid             ins_name  \\\n",
       "0                                         NaN                  NaN   \n",
       "1                                         NaN                  NaN   \n",
       "35       d8b57c0e-9f0f-4dcb-d207-a12a90c64a2d   Harvard University   \n",
       "38       8d297d1e-3e3d-fadd-2963-57e0a40bff2a  Columbia University   \n",
       "148      d8b57c0e-9f0f-4dcb-d207-a12a90c64a2d   Harvard University   \n",
       "...                                       ...                  ...   \n",
       "1718514                                   NaN                  NaN   \n",
       "1718515                                   NaN                  NaN   \n",
       "1718516                                   NaN                  NaN   \n",
       "1718517                                   NaN                  NaN   \n",
       "1718518                                   NaN                  NaN   \n",
       "\n",
       "         degree_type                        subject  \n",
       "0                NaN                            NaN  \n",
       "1                NaN                            NaN  \n",
       "35                BA                      Economics  \n",
       "38              B.A.  Economics & Political Science  \n",
       "148      Dropped Out               Computer Science  \n",
       "...              ...                            ...  \n",
       "1718514          NaN                            NaN  \n",
       "1718515          NaN                            NaN  \n",
       "1718516          NaN                            NaN  \n",
       "1718517          NaN                            NaN  \n",
       "1718518          NaN                            NaN  \n",
       "\n",
       "[1216445 rows x 22 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "say = data[data[\"name\"] == \"Say\"][\"p_description\"].values[0]\n",
    "wetpaint = data[data[\"name\"] == \"Wetpaint\"][\"p_description\"].values[0]\n",
    "google = data[data[\"name\"] == \"Google\"][\"p_description\"].values[0]\n",
    "facebook = data[data[\"name\"] == \"Facebook\"][\"p_description\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"foo.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb = data[data[\"name\"] == \"Airbnb\"][\"p_description\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aristotle â€œAriâ€\\x9d Balogh is currently the VP of Storage Infrastructure Products at Google.   Prior to Google, Balogh was Chief Technology Officer at Yahoo. He was responsible for company-wide product development which includes optimizing resources, speeding innovation, and ensuring the quality of Yahooâ€™s products and services. He was focused on establishing a common architecture and building blocks to drive development aligned with corporate strategy and on improving the overall effectiveness of Yahooâ€™s engineering efforts. All of Yahooâ€™s engineering functions, including technical operations, infrastructure, and internal IT support groups, reported into Balogh.   Prior to Yahoo, Balogh was Executive Vice President, Chief Technology Officer and Head of Global Product Design for VeriSign, Inc., where he led all internal and external technology functions. During his nearly ten years at VeriSign, he held numerous technology leadership positions that focused on aligning technical execution with business priorities; driving product strategy; and improving the speed of innovation and quality across the entire lifecycle of service creation and delivery. In 2007, he was recognized by Infoworld Magazine as one of the top 25 CTOs in the industry. Prior to joining Verisign, Balogh held leadership positions at SRA Corporation and Roadnet Technologies.  Balogh holds an M.S.E. in Electrical and Computer Engineering and a B.S. in Electrical and Computer Science from John Hopkins University.'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"name\"] == \"Airbnb\"][\"p_description\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jonathan L. Dolgen has been a director of Expedia since completion of the IAC/Expedia Spin-Off. From July 2004 until April 2010, Dolgen was a Senior Advisor to Viacom, Inc. (“Old Viacom”), a worldwide entertainment and media company, where he provided advisory services to the chief executive officer of Old Viacom, or others designated by him, on an as-requested basis.  Effective December 31, 2005, Old Viacom was separated into two publicly traded companies, Viacom Inc. (“New Viacom”) and CBS Corporation. From the separation of Old Viacom, Dolgen provided advisory services to the chief executive officer of New Viacom, or others designated by him, on an as-requested basis. Since July 2004, Dolgen has been a private investor, and since September 2004, Dolgen has been the principal of Wood River Ventures, LLC, a private entity that seeks investment and other opportunities and provides consulting services, primarily in the media sector. From April 2005 until April 2013, Dolgen, through Wood River, had an arrangement with Madison Dearborn Partners, LLC to seek investment opportunities and consult, primarily in the media sector. From October 2006 through March 2008, Dolgen served as senior consultant for ArtistDirect, Inc. From April 1994 to July 2004, Dolgen served as Chairman and Chief Executive Officer of the Viacom Entertainment Group, a unit of Old Viacom, where he oversaw various operations of Old Viacom’s businesses, which during 2003 and 2004 primarily included the operations engaged in motion picture production and distribution, television production and distribution, regional theme parks, theatrical exhibition and publishing. As a result of the separation of Old Viacom, Old Viacom’s motion picture production and distribution and theatrical exhibition business became part of New Viacom’s businesses, and substantially all of the remaining businesses of Old Viacom overseen by Dolgen remained with CBS Corporation.  Dolgen began his career in the entertainment industry in 1976 and, until joining the Viacom Entertainment Group, served in executive positions at Columbia Pictures Industries, Inc., Twentieth Century Fox and Fox, Inc., and Sony Pictures Entertainment. Dolgen has also been a director of Live Nation Entertainment, Inc. since its formation following the merger of Live Nation, Inc. and Ticketmaster in January 2010. Prior to the merger, Dolgen was a director of Ticketmaster from August 2008. From October 2004 until September 2008, Dolgen was a Director of Charter Communications, Inc. He is also a member of the Board of Trustees of the Claremont Graduate School and a director of the Simon Wiesenthal Center.'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"name\"] == \"Expedia\"][\"p_description\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking = data[data[\"name\"] == \"Booking.com\"][\"description\"].values[0]\n",
    "expedia = data[data[\"name\"] == \"Expedia\"][\"p_description\"].values[0]\n",
    "kayak = data[data[\"name\"] == \"KAYAK\"][\"p_description\"].values[0]\n",
    "Agoda = data[data[\"name\"] == \"Trip.com\"][\"p_description\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "na=np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(data[data[\"name\"] == \"Booking.com\"][\"p_description\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agoda = \"\"\"Trip.com is a Chinese travel agency offering comprehensive services including hotel reservations, air ticketing, packaged tours, high-speed rail ticket booking, and corporate travel management.Trip.com offers over 1,000 packaged tours to both domestic Chinese and overseas destinations, departing from six major Chinese cities (Beijing, Shanghai,Guangzhou, Shenzhen, Hangzhou, and Chengdu) and serving over 10,000 individual travelers monthly. Trip.com Group is a provider of travel services including accommodation reservation, transportation ticketing, packaged tours, and corporate travel management.\n",
    "The company owns and operates the Trip.com, Skyscanner, and Ctrip.com, all of which are online travel agencies. It enables local partners and travelers to make informed and cost-effective bookings for travel products and services, through the aggregation of comprehensive travel-related information and resources, and an advanced transaction platform consisting of mobile apps, internet websites, and 24/7 customer service centers. Founded in 1999 and listed on Nasdaq in 2003, Trip.com Group was established in Shanghai, China by co-founders Neil Shen, Min Fan, Qi Ji, and James Liang.\n",
    "\n",
    "Founded in 1999, Ctrip was listed on NASDAQ in December 2003. It has successfully integrated high-tech industries and traditional travel industry to serve over 40 million registered members. The Ctrip group includes members like lvping, Xingcheng ezTravel, csshotel, and sozhen.com. Its major competitors are elong, aoyou.com, and mangocity.com.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85570425"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_avg_benchmark(Sentence(google),Sentence(airbnb),model = word2vec, use_stoplist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1296013761334525"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_wmd_benchmark(Sentence(airbnb),Sentence(expedia),model = word2vec, use_stoplist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Sentence at 0x7fbce786fbe0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentence(say)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_sif_benchmark(Sentence(airbnb),Sentence(booking),model = word2vec, freqs=frequencies, use_stoplist=False, a=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uuid', 'name', 'rank', 'roles', 'status', 'short_description',\n",
       "       'category_list', 'category_groups_list', 'num_funding_rounds',\n",
       "       'employee_count', 'description', 'p_uuid', 'p_name', 'gender',\n",
       "       'featured_job_title', 'p_description', 'd_uuid', 'd_name', 'ins_uuid',\n",
       "       'ins_name', 'degree_type', 'subject'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_similarity(data,company_one,company_two,text_type, webm_model,stop_flag):\n",
    "    com_des_one =  data[data[\"name\"] == company_one][\"description\"].values[0]\n",
    "    com_peo_des_one =  data[data[\"name\"] == company_one][\"p_description\"].values[0]\n",
    "    com_sh_des_one =  data[data[\"name\"] == company_one][\"short_description\"].values[0]\n",
    "    com_des_two =  data[data[\"name\"] == company_two][\"description\"].values[0]\n",
    "    com_peo_des_two =  data[data[\"name\"] == company_two][\"p_description\"].values[0]\n",
    "    com_sh_des_two =  data[data[\"name\"] == company_two][\"short_description\"].values[0]\n",
    "    com_des_one = com_des_one + str(com_sh_des_one)\n",
    "#     print(str(com_des_two))\n",
    "    com_des_two = str(com_des_two) + str(com_sh_des_two)\n",
    "\n",
    "    if text_type == \"only_des\":\n",
    "        similarity = run_avg_benchmark(Sentence(com_des_one),Sentence(com_des_two),model = webm_model, use_stoplist=stop_flag)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_ls_finance = data[data.apply(lambda x: \"Cloud Computing\" in x[\"category_list\"],axis = 1)][\"name\"]\n",
    "name_ls_travel = data[data.apply(lambda x: \"Travel\" in x[\"category_list\"],axis = 1)][\"name\"]\n",
    "name_ls_cloud = data[data.apply(lambda x: \"Cloud Computing\" in x[\"category_list\"],axis = 1)][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_companies_ls = list(name_ls_finance)\n",
    "travel_companies_ls = list(name_ls_travel)\n",
    "cloud_companies_ls = list(name_ls_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omidyar Network 0.77989084\n",
      "Meritech Capital Partners 0.7644329\n",
      "Centennial Ventures 0.69306344\n",
      "Austin Ventures 0.6186713\n",
      "Acadia Woods Partners 0.65494436\n",
      "Foundation Capital 0.78947747\n",
      "Mobius Venture Capital 0.7800758\n",
      "Inflexion Partners 0.4088419\n",
      "Village Ventures 0.61379933\n",
      "First Round Capital 0.81887305\n"
     ]
    }
   ],
   "source": [
    "for name in finance_companies_ls[:10]:\n",
    "    sim_ls = []\n",
    "#     print(name)\n",
    "    sim = return_similarity(data,\"Airbnb\",name,\"only_des\", word2vec,False)\n",
    "    sim_ls.append(sim)\n",
    "    print(name,sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zoho 0.76162076\n",
      "PBworks 0.82654047\n",
      "Box 0.8388816\n",
      "Oracle-NetSuite 0.749099\n",
      "Big Bang Ventures 0.5666262\n",
      "LongJump 0.82523376\n",
      "Brightcove 0.7676357\n",
      "Limelight Networks 0.78022057\n",
      "Nirvanix 0.78128\n",
      "INgage Networks 0.7725506\n"
     ]
    }
   ],
   "source": [
    "for name in cloud_companies_ls[:10]:\n",
    "    sim_ls = []\n",
    "#     print(name)\n",
    "    sim = return_similarity(data,\"Airbnb\",name,\"only_des\", word2vec,False)\n",
    "    sim_ls.append(sim)\n",
    "    print(name,sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booking.com 0.90176183\n",
      "TripUp 0.8351637\n",
      "SideStep 0.854903\n",
      "Farecast 0.846826\n",
      "KAYAK 0.8667915\n",
      "PAR Capital Management 0.5284684\n",
      "Yapta 0.8116853\n",
      "TripHub 0.824854\n",
      "TVtrip 0.8520464\n",
      "Hotelicopter 0.8523342\n"
     ]
    }
   ],
   "source": [
    "for name in travel_companies_ls[:10]:\n",
    "    sim_ls = []\n",
    "#     print(name)\n",
    "    sim = return_similarity(data,\"Airbnb\",name,\"only_des\", word2vec,False)\n",
    "    sim_ls.append(sim)\n",
    "    print(name,sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1216445, 22)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
