{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 2] No such\n",
      "[nltk_data]     file or directory>\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\70473\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "STOP = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, sentence):\n",
    "        self.raw = sentence\n",
    "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\").replace(\",\",\"\").replace(\".\",\"\").replace(\"'\",\"\")\n",
    "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]\n",
    "        self.tokens_without_stop = [t for t in self.tokens if t not in STOP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "PATH_TO_GLOVE = os.path.expanduser(\"data/glove.42B.300d.txt\")\n",
    "tmp_file = \"data/glove.42B.300d.w2v.txt\"\n",
    "glove2word2vec(PATH_TO_GLOVE, tmp_file)\n",
    "glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Freqency(word weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "PATH_TO_FREQUENCIES_FILE = \"data/frequencies.tsv\"\n",
    "PATH_TO_DOC_FREQUENCIES_FILE = \"data/doc_frequencies.tsv\"\n",
    "\n",
    "def read_tsv(f):\n",
    "    frequencies = {}\n",
    "    with open(f) as tsv:\n",
    "        tsv_reader = csv.reader(tsv, delimiter=\"\\t\")\n",
    "        for row in tsv_reader: \n",
    "            frequencies[row[0]] = int(row[1])\n",
    "        \n",
    "    return frequencies\n",
    "        \n",
    "frequencies = read_tsv(PATH_TO_FREQUENCIES_FILE)\n",
    "doc_frequencies = read_tsv(PATH_TO_DOC_FREQUENCIES_FILE)\n",
    "doc_frequencies[\"NUM_DOCS\"] = 1288431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity measurement-weighted cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def run_avg_benchmark(sentences1, sentences2, model=None, use_stoplist=False, doc_freqs=None): \n",
    "\n",
    "    if doc_freqs is not None:\n",
    "        N = doc_freqs[\"NUM_DOCS\"]\n",
    "    \n",
    "    tokens1 = sentences1.tokens_without_stop if use_stoplist else sentences1.tokens\n",
    "    tokens2 = sentences2.tokens_without_stop if use_stoplist else sentences2.tokens\n",
    "\n",
    "    tokens1 = [token for token in tokens1 if token in model]\n",
    "    tokens2 = [token for token in tokens2 if token in model]\n",
    "\n",
    "#     if len(tokens1) == 0 or len(tokens2) == 0:\n",
    "#         sims.append(0)\n",
    "#         continue\n",
    "\n",
    "    tokfreqs1 = Counter(tokens1)\n",
    "    tokfreqs2 = Counter(tokens2)\n",
    "\n",
    "    weights1 = [tokfreqs1[token] * math.log(N/(doc_freqs.get(token, 0)+1)) \n",
    "                for token in tokfreqs1] if doc_freqs else None\n",
    "    weights2 = [tokfreqs2[token] * math.log(N/(doc_freqs.get(token, 0)+1)) \n",
    "                for token in tokfreqs2] if doc_freqs else None\n",
    "\n",
    "    embedding1 = np.average([model[token] for token in tokfreqs1], axis=0, weights=weights1).reshape(1, -1)\n",
    "    embedding2 = np.average([model[token] for token in tokfreqs2], axis=0, weights=weights2).reshape(1, -1)\n",
    "    sim = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "\n",
    "    return sim\n",
    "\n",
    "def run_wmd_benchmark(sent1, sent2, model, use_stoplist=False):\n",
    "\n",
    "    tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n",
    "    tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
    "\n",
    "    tokens1 = [token for token in tokens1 if token in model]\n",
    "    tokens2 = [token for token in tokens2 if token in model]\n",
    "\n",
    "    if len(tokens1) == 0 or len(tokens2) == 0:\n",
    "        tokens1 = [token for token in sent1.tokens if token in model]\n",
    "        tokens2 = [token for token in sent2.tokens if token in model]\n",
    "\n",
    "    sim = model.wmdistance(tokens1, tokens2)\n",
    "        \n",
    "    return sim\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def remove_first_principal_component(X):\n",
    "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0)\n",
    "    svd.fit(X)\n",
    "    pc = svd.components_\n",
    "    XX = X - X.dot(pc.transpose()) * pc\n",
    "    return XX\n",
    "\n",
    "\n",
    "def run_sif_benchmark(sent1, sent2, model, freqs={}, use_stoplist=False, a=0.001): \n",
    "    total_freq = sum(freqs.values())\n",
    "    embeddings = []\n",
    "    # SIF requires us to first collect all sentence embeddings and then perform \n",
    "    # common component analysis.\n",
    "    tokens1 = sent1.tokens_without_stop if use_stoplist else sent1.tokens\n",
    "    tokens2 = sent2.tokens_without_stop if use_stoplist else sent2.tokens\n",
    "\n",
    "    tokens1 = [token for token in tokens1 if token in model]\n",
    "    tokens2 = [token for token in tokens2 if token in model]\n",
    "\n",
    "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
    "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
    "\n",
    "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
    "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
    "\n",
    "    embeddings.append(embedding1)\n",
    "    embeddings.append(embedding2)\n",
    "        \n",
    "    embeddings = remove_first_principal_component(np.array(embeddings))\n",
    "    sim = [cosine_similarity(embeddings[idx*2].reshape(1, -1), \n",
    "                              embeddings[idx*2+1].reshape(1, -1))[0][0] \n",
    "            for idx in range(int(len(embeddings)/2))][0]\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_pickle(\"baseline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "class my_mongodb:\n",
    "    import pandas as pd\n",
    "    def __init__(self, hostname='localhost', db_port=27017):\n",
    "\n",
    "        self.hostname = hostname\n",
    "        self.db_port = db_port\n",
    "        self.my_mongo_client = MongoClient(self.hostname, self.db_port)\n",
    "        \n",
    "    def df2mongo(self, df_data, db_name, form_name):\n",
    "\n",
    "\n",
    "        def df2bson(df):\n",
    "\n",
    "            data = json.loads(df.T.to_json()).values()\n",
    "            return data\n",
    "\n",
    "        my_db = self.my_mongo_client[db_name]\n",
    "        bson_data = df2bson(df_data)\n",
    "        my_posts = my_db[form_name]\n",
    "        result = my_posts.insert_many(bson_data)\n",
    "        return result\n",
    "\n",
    "    def collection2df(self, db_name, collection_name, query={}, no_id=True):\n",
    "\n",
    "        \"\"\"查询数据库，导出DataFrame类型数据\n",
    "        （db_name：数据库名 collection_name：集合名 \n",
    "         query：查询条件式 no_id：不显示ID,默认为不显示ID）\"\"\"\n",
    "\n",
    "        db = self.my_mongo_client[db_name]\n",
    "        collection = self.my_mongo_client[db_name][collection_name]\n",
    "        cursor = collection.find(query)\n",
    "        df = pd.DataFrame(list(cursor))\n",
    "        if no_id:\n",
    "            del df['_id']\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uuid', 'name', 'rank', 'roles', 'status', 'short_description',\n",
       "       'category_list', 'category_groups_list', 'num_funding_rounds',\n",
       "       'employee_count', 'founded_on', 'description', 'p_uuid', 'p_name',\n",
       "       'gender', 'featured_job_title', 'p_description', 'd_uuid', 'd_name',\n",
       "       'ins_uuid', 'ins_name', 'degree_type', 'subject', 'category_coding',\n",
       "       'acquired', 'closed', 'ipo', 'operating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embedding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_data(data,company):\n",
    "    data[\"p_description\"].fillna(\"No people description\",inplace=True)\n",
    "    data[\"short_description\"].fillna(\"No short description\",inplace=True)\n",
    "    com_des =  data[data[\"name\"] == company][\"description\"].values[0]\n",
    "    com_sh_des =  data[data[\"name\"] == company][\"short_description\"].values[0]\n",
    "    com_p_des = data[data[\"name\"] == company][\"p_description\"].values[0]\n",
    "    com_des = com_des + com_sh_des\n",
    "    com_all_des = com_des + com_p_des\n",
    "    return com_des,com_p_des,com_all_des"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Text Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_similarity(data,company_one,company_two,webm_model,stop_flag,sim_type):\n",
    "\n",
    "    com_des_one,com_p_des_one,com_all_des_one = basic_data(data,company_one)\n",
    "    com_des_two,com_p_des_two,com_all_des_two = basic_data(data,company_two)\n",
    "    if sim_type == \"cos\":\n",
    "        similarity = run_avg_benchmark(Sentence(com_des_one),Sentence(com_des_two),model = webm_model, use_stoplist=stop_flag)\n",
    "    elif sim_type == \"wmd\":\n",
    "        similarity = run_wmd_benchmark(Sentence(com_des_one),Sentence(com_des_two),model = webm_model, use_stoplist=stop_flag)\n",
    "    return similarity,com_des_one,com_des_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9833626,\n",
       " 'Airbnb is a community marketplace for people to list, discover, and book unique spaces around the world through mobile phones or the internet. The company connects travelers seeking authentic experiences with hosts offering unique, inspiring spaces around the world. Whether the available space is a castle for a night, a sailboat for a week, or an apartment for a month, Airbnb is the easiest way for people to showcase these distinctive spaces to an audience of millions. By facilitating bookings and financial transactions, Airbnb makes the process of listing or booking a space effortless and efficient. With 4,500,000 listings in over 65,000 cities in 191 countries, the company offers the widest variety of unique spaces for everyone, at any price point around the globe.  The company was co-founded in August 2008 by Brian Chesky and Joe Gebbia, and is currently headquartered in San Francisco, California.Airbnb is an online community marketplace for people to list, discover, and book accommodations.',\n",
       " \"Founded in 1996 in Amsterdam, Booking.com has grown from a small Dutch startup to one of the world’s leading digital travel companies. Part of Booking Holdings Inc. (NASDAQ: BKNG), Booking.com’s mission is to make it easier for everyone to experience the world. By investing in the technology that helps take the friction out of travel, Booking.com seamlessly connects millions of travellers with memorable experiences, a range of transport options and incredible places to stay - from homes to hotels and much more. As one of the world’s largest travel marketplaces for both established brands and entrepreneurs of all sizes, Booking.com enables properties all over the world to reach a global audience and grow their businesses. Booking.com is available in 43 languages and offers more than 28 million total reported accommodation listings, including over 6.2 million listings alone of homes, apartments and other unique places to stay. No matter where you want to go or what you want to do, Booking.com makes it easy and backs it all up with 24/7 customer support.Founded in 1996, Booking.com is one of the world's leading digital travel companies, available in 40+ languages and 155,000+ destinations.\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_similarity(data,\"Airbnb\",\"Booking.com\",glove,False,\"cos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Category similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, paired_distances\n",
    "def return_cat_sim(data,company_one,company_two):\n",
    "    cat_code_one = data[data[\"name\"] == company_one][\"category_coding\"].values[0]\n",
    "    cat_code_two = data[data[\"name\"] == company_two][\"category_coding\"].values[0]\n",
    "    a = set(cat_code_one)\n",
    "    b = set(cat_code_two)\n",
    "    sim = len(a.intersection(b))/(np.sqrt(len(a))*np.sqrt(len(b)))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[data[\"name\"] == \"eBay\"][\"category_coding\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_cat_sim(data,\"Airbnb\",\"Crosslink Capital\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_unique = [i for i in data[\"status\"].unique()]\n",
    "def status_trans(status, one_hot_set):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    le.fit(one_hot_set)\n",
    "    a = le.transform(status.split())\n",
    "    return a[0]\n",
    "data[\"status_coding\"] = data[\"status\"].apply(lambda x:status_trans(x,status_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_trans(\"ipo\",status_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"status_coding\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [0,-1,1,2,-2,3,-3]\n",
    "rule = {0:0,-1:1,1:1,-2:2,2:2,3:3,-3:3}\n",
    "newList = sorted(ls, key=lambda x:rule[x])\n",
    "print(newList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result storage and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_com_ls = [\"Airbnb\",\"Coinbase\",\"Deliveroo\",\"Revolut\",\"Darktrace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"name\"] == \"Deliveroo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## narrow search range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Search_coms(x,set_be_seached_com):\n",
    "    flag = any(i in set_be_seached_com for i in x)\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_a = data[data[\"name\"] == \"Deliveroo\"][\"category_coding\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_data = data[data[\"category_coding\"].apply(lambda x:Search_coms(x,set_a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_data[\"name\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = my_mongodb().my_mongo_client\n",
    "database = client[\"dissertation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'database' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2ac4c4c47dd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcollection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Airbnb\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'database' is not defined"
     ]
    }
   ],
   "source": [
    "collection = database[\"Airbnb\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 283\n"
     ]
    }
   ],
   "source": [
    "def first_return_searh_result(query_company,database,data,wem_model):\n",
    "    set_a = data[data[\"name\"] == query_company][\"category_coding\"].values[0]\n",
    "    search_data = data[data[\"category_coding\"].apply(lambda x:Search_coms(x,set_a))]\n",
    "    collection = database[query_company]\n",
    "    print(\"Please wait for generating all the competitors\")\n",
    "    for search_company in search_data[\"name\"].values[:10]:\n",
    "        pair = {}\n",
    "        try:\n",
    "            sim, com_des_one,com_des_two = return_similarity(data,query_company,search_company,wem_model,False,\"cos\")\n",
    "#             print(query_company,search_company)\n",
    "            cat_sim = return_cat_sim(data,query_company,search_company)\n",
    "            size_diff = data[data[\"name\"] == query_company][\"status_coding\"].values[0] - data[data[\"name\"] == search_company][\"status_coding\"].values[0]\n",
    "        except:\n",
    "            pass\n",
    "        pair[\"name_query\"] = query_company\n",
    "        pair[\"name_result\"] = search_company\n",
    "        pair[\"query_description\"] = com_des_one\n",
    "        pair[\"result_description\"] = com_des_two\n",
    "        pair[\"text_similarity\"] = float(sim)\n",
    "        pair[\"cat_similarity\"] = float(cat_sim)\n",
    "        pair[\"size_difference\"] = int(size_diff)\n",
    "        collection.insert_one(pair)\n",
    "    print(\"************Data is prepared**************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is the count 0\n",
      "Airbnb eBay\n",
      "here is the count 1\n",
      "Airbnb Spark Capital\n",
      "here is the count 2\n",
      "Airbnb Bessemer Venture Partners\n",
      "here is the count 3\n",
      "Airbnb TripUp\n",
      "here is the count 4\n",
      "Airbnb SideStep\n",
      "here is the count 5\n",
      "Airbnb Farecast\n",
      "here is the count 6\n",
      "Airbnb Yapta\n",
      "here is the count 7\n",
      "Airbnb TripHub\n",
      "here is the count 8\n",
      "Airbnb TVtrip\n",
      "here is the count 9\n",
      "Airbnb Crosslink Capital\n",
      "Data is prepared\n"
     ]
    }
   ],
   "source": [
    "for query_company in evaluation_com_ls[:1]:\n",
    "    count = 0\n",
    "    set_a = data[data[\"name\"] == query_company][\"category_coding\"].values[0]\n",
    "    search_data = data[data[\"category_coding\"].apply(lambda x:Search_coms(x,set_a))]\n",
    "    collection = database[query_company]\n",
    "    for search_company in search_data[\"name\"].values[:10]:\n",
    "        print(\"here is the count {}\".format(count))\n",
    "        pair = {}\n",
    "        try:\n",
    "            sim, com_des_one,com_des_two = return_similarity(data,query_company,search_company,glove,False,\"cos\")\n",
    "            print(query_company,search_company)\n",
    "            cat_sim = return_cat_sim(data,query_company,search_company)\n",
    "            size_diff = data[data[\"name\"] == query_company][\"status_coding\"].values[0] - data[data[\"name\"] == search_company][\"status_coding\"].values[0]\n",
    "        except:\n",
    "            print(query_company,search_company,\"errorxxxxxxxxxxxx\")\n",
    "            pass\n",
    "        pair[\"name_query\"] = query_company\n",
    "        pair[\"name_result\"] = search_company\n",
    "        pair[\"query_description\"] = com_des_one\n",
    "        pair[\"result_description\"] = com_des_two\n",
    "        pair[\"text_similarity\"] = float(sim)\n",
    "        pair[\"cat_similarity\"] = float(cat_sim)\n",
    "        pair[\"size_difference\"] = int(size_diff)\n",
    "        collection.insert_one(pair)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集合已存在！\n"
     ]
    }
   ],
   "source": [
    "collist = database.list_collection_names()\n",
    "# collist = mydb.collection_names()\n",
    "if \"Airbnb\" in collist: \n",
    "    print(\"集合已存在！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name_query', 'name_result', 'query_description', 'result_description',\n",
       "       'text_similarity', 'cat_similarity', 'size_difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search engine back-end algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startup_competitor_search_engine(db_name,data,word2vec):\n",
    "    query_company = input(\"please input query company name in the Crunchdatabase.e.g. Airbnb, Coinbase\"+\"\\n\" +\"You are searching for competitors of \")\n",
    "    query_company = query_company.lower().capitalize()\n",
    "    mango = my_mongodb()\n",
    "    client = mango.my_mongo_client\n",
    "    database = client[db_name]\n",
    "    collist = database.list_collection_names()\n",
    "    collection = database[query_company]\n",
    "    if query_company in collist: \n",
    "        print(\"This is not the first query for this company, results come out soon......\"+\"\\n\")\n",
    "        result_df = mango.collection2df( \"dissertation\", query_company, query={}, no_id=True)\n",
    "        final_result = pd.DataFrame(sorted(result_df.values, key=lambda x: 0.8*x[4]+0.2*x[5], reverse = True),columns=['name_query', 'name_result', 'query_description', 'result_description',\n",
    "       'text_similarity', 'cat_similarity', 'size_difference'])\n",
    "        return final_result\n",
    "    else:\n",
    "        print(\"This is the first query for this company......\"+\"\\n\")\n",
    "        first_return_searh_result(query_company,database,data,word2vec)\n",
    "        result_df = mango.collection2df( \"dissertation\", query_company, query={}, no_id=True)\n",
    "        final_result = pd.DataFrame(sorted(result_df.values, key=lambda x: 0.8*x[4]+0.2*x[5], reverse = True),columns=['name_query', 'name_result', 'query_description', 'result_description',\n",
    "       'text_similarity', 'cat_similarity', 'size_difference'])\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please input query company name in the Crunchdatabase.e.g. Airbnb, Coinbase\n",
      "You are searching for competitors of  Airbnb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first query for this company......\n",
      "\n",
      "Please wait for generating all the competitors\n",
      "************Data is prepared**************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_query</th>\n",
       "      <th>name_result</th>\n",
       "      <th>query_description</th>\n",
       "      <th>result_description</th>\n",
       "      <th>text_similarity</th>\n",
       "      <th>cat_similarity</th>\n",
       "      <th>size_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>TVtrip</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>TVtrip  is [a video guide for hotels](http://w...</td>\n",
       "      <td>0.852046</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Farecast</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>Farecast offers a unique service by providing ...</td>\n",
       "      <td>0.846826</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>SideStep</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>SideStep is a metasearch engine for travel whi...</td>\n",
       "      <td>0.854903</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>TripHub</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>Noting the growing trends in group travel, [Ex...</td>\n",
       "      <td>0.824854</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>TripUp</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>TripUp is an interactive travel community that...</td>\n",
       "      <td>0.835164</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>eBay</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>eBay is an online marketplace.  The platform c...</td>\n",
       "      <td>0.852066</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Yapta</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>Yapta is a travel Website and browser add-on t...</td>\n",
       "      <td>0.811685</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Crosslink Capital</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>Crosslink, founded in 1989, is a premier early...</td>\n",
       "      <td>0.763316</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Spark Capital</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>We are Spark Capital, investors in products we...</td>\n",
       "      <td>0.743787</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>Bessemer Venture Partners</td>\n",
       "      <td>Airbnb is a community marketplace for people t...</td>\n",
       "      <td>Bessemer Venture Partners is a $4B venture cap...</td>\n",
       "      <td>0.748651</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name_query                name_result  \\\n",
       "0     Airbnb                     TVtrip   \n",
       "1     Airbnb                   Farecast   \n",
       "2     Airbnb                   SideStep   \n",
       "3     Airbnb                    TripHub   \n",
       "4     Airbnb                     TripUp   \n",
       "5     Airbnb                       eBay   \n",
       "6     Airbnb                      Yapta   \n",
       "7     Airbnb          Crosslink Capital   \n",
       "8     Airbnb              Spark Capital   \n",
       "9     Airbnb  Bessemer Venture Partners   \n",
       "\n",
       "                                   query_description  \\\n",
       "0  Airbnb is a community marketplace for people t...   \n",
       "1  Airbnb is a community marketplace for people t...   \n",
       "2  Airbnb is a community marketplace for people t...   \n",
       "3  Airbnb is a community marketplace for people t...   \n",
       "4  Airbnb is a community marketplace for people t...   \n",
       "5  Airbnb is a community marketplace for people t...   \n",
       "6  Airbnb is a community marketplace for people t...   \n",
       "7  Airbnb is a community marketplace for people t...   \n",
       "8  Airbnb is a community marketplace for people t...   \n",
       "9  Airbnb is a community marketplace for people t...   \n",
       "\n",
       "                                  result_description  text_similarity  \\\n",
       "0  TVtrip  is [a video guide for hotels](http://w...         0.852046   \n",
       "1  Farecast offers a unique service by providing ...         0.846826   \n",
       "2  SideStep is a metasearch engine for travel whi...         0.854903   \n",
       "3  Noting the growing trends in group travel, [Ex...         0.824854   \n",
       "4  TripUp is an interactive travel community that...         0.835164   \n",
       "5  eBay is an online marketplace.  The platform c...         0.852066   \n",
       "6  Yapta is a travel Website and browser add-on t...         0.811685   \n",
       "7  Crosslink, founded in 1989, is a premier early...         0.763316   \n",
       "8  We are Spark Capital, investors in products we...         0.743787   \n",
       "9  Bessemer Venture Partners is a $4B venture cap...         0.748651   \n",
       "\n",
       "   cat_similarity  size_difference  \n",
       "0        0.288675               -1  \n",
       "1        0.288675                2  \n",
       "2        0.250000                2  \n",
       "3        0.353553                1  \n",
       "4        0.288675                1  \n",
       "5        0.204124                0  \n",
       "6        0.288675                2  \n",
       "7        0.158114               -1  \n",
       "8        0.223607               -1  \n",
       "9        0.158114               -1  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startup_competitor_search_engine(\"Baseline\",data,word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
