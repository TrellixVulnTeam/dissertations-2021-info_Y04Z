{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b544fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e6fa5",
   "metadata": {
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1627644473189,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "584e6fa5"
   },
   "outputs": [],
   "source": [
    "# #Import libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import model_selection, metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "data = pd.read_csv(r'D:\\msc-project\\from-github\\dissertations-2021-info\\rahim_ghani_predict\\data\\features_with_outcome.csv',encoding='utf=8')\n",
    "target = 'outcome'\n",
    "IDcol = 'org_uuid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17cfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83957ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_data = data['outcome']\n",
    "X_data = data.drop(columns=['outcome'])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefdb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train,y_train],axis=1)\n",
    "test = pd.concat([X_test,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-particular",
   "metadata": {
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1627644474795,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "comfortable-particular"
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, dtest, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['outcome'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtest_predictions = alg.predict(dtest[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    dtest_predprob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Training Accuracy : %.4g\" % metrics.accuracy_score(dtrain['outcome'].values, dtrain_predictions))\n",
    "    print (\"Test Accuracy : %.4g\" % metrics.accuracy_score(dtest['outcome'].values, dtest_predictions))\n",
    "    print (\"Training Precision : %.4g\" % metrics.precision_score(dtrain['outcome'].values, dtrain_predictions))\n",
    "    print (\"Test Precision : %.4g\" % metrics.precision_score(dtest['outcome'].values, dtest_predictions))\n",
    "    print (\"Training Recall : %.4g\" % metrics.recall_score(dtrain['outcome'].values, dtrain_predictions))\n",
    "    print (\"Test Recall : %.4g\" % metrics.recall_score(dtest['outcome'].values, dtest_predictions))\n",
    "    print (\"Training f1 : %.4g\" % metrics.f1_score(dtrain['outcome'].values, dtrain_predictions))\n",
    "    print (\"Test f1 : %.4g\" % metrics.f1_score(dtest['outcome'].values, dtest_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['outcome'], dtrain_predprob))\n",
    "    print (\"AUC Score (Test): %f\" % metrics.roc_auc_score(dtest['outcome'], dtest_predprob))\n",
    "    print (\"Training Set Confusion Matrix\\n\")\n",
    "    print (metrics.confusion_matrix(dtrain['outcome'],dtrain_predictions))\n",
    "    print (\"Test Set Confusion Matrix\\n\")\n",
    "    print (metrics.confusion_matrix(dtest['outcome'],dtest_predictions))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.feature_importances_,index=predictors).sort_values(ascending=False).nlargest(n=20)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-radar",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627644474799,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "located-radar"
   },
   "outputs": [],
   "source": [
    "y_data = data['outcome']\n",
    "X_data = data.drop(columns = ['outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-hampton",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627644474799,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "worse-hampton"
   },
   "outputs": [],
   "source": [
    "#splitting data into test and full training set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X_data,y_data, \n",
    "                                                              test_size = 0.2,\n",
    "                                                              stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd6df6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1627644474800,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "e3bd6df6",
    "outputId": "35269cea-412a-4043-a614-4584021a1659"
   },
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "\n",
    "modelfit(xgb1, train, test, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cf5a1",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1627644474800,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "ec5cf5a1"
   },
   "outputs": [],
   "source": [
    "#Tune max_depth and min_child_weight\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                                    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                 objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                                                 param_grid = param_test1, scoring='f1',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch1.cv_results_))\n",
    "print(gsearch1.best_params_)\n",
    "print(gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f678a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[8,9,10],\n",
    " 'min_child_weight':[2,3,4]\n",
    "}\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                                  min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                  objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                                                    param_grid = param_test2, scoring='f1',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch2.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch2.cv_results_))\n",
    "print(gsearch2.best_params_)\n",
    "print(gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590d63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2b = {\n",
    " 'min_child_weight':[1,2,3,4]\n",
    "}\n",
    "\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=10,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2b, scoring='f1',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch2b.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch2b.cv_results_))\n",
    "print(gsearch2b.best_params_)\n",
    "print(gsearch2b.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301f1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=10,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='f1',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch3.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch3.cv_results_))\n",
    "print(gsearch3.best_params_)\n",
    "print(gsearch3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = XGBClassifier(learning_rate =0.1,\n",
    "                     n_estimators=1000,\n",
    "                     max_depth=10,\n",
    "                     min_child_weight=2,\n",
    "                     gamma=0,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     objective= 'binary:logistic',\n",
    "                     nthread=4,\n",
    "                     scale_pos_weight=1,\n",
    "                     seed=27)\n",
    "\n",
    "modelfit(xgb2, train, test, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e615d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'scale_pos_weight':range (1,10,2)\n",
    "}\n",
    "\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=10,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='f1',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch4.cv_results_))\n",
    "print(gsearch4.best_params_)\n",
    "print(gsearch4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4a = {\n",
    " 'scale_pos_weight':[4,5,6]\n",
    "}\n",
    "\n",
    "gsearch4a = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=10,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4a, scoring='f1',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch4a.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch4a.cv_results_))\n",
    "print(gsearch4a.best_params_)\n",
    "print(gsearch4a.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4b = {\n",
    " 'scale_pos_weight':[4.0,4.2,4.4,4.6,4.8,5.0]\n",
    "}\n",
    "\n",
    "gsearch4b = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=10,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4b, scoring='f1',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch4b.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch4b.cv_results_))\n",
    "print(gsearch4b.best_params_)\n",
    "print(gsearch4b.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a9badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(learning_rate =0.1,\n",
    "                     n_estimators=1000,\n",
    "                     max_depth=10,\n",
    "                     min_child_weight=2,\n",
    "                     gamma=0,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     objective= 'binary:logistic',\n",
    "                     nthread=4,\n",
    "                     scale_pos_weight=5,\n",
    "                     seed=27)\n",
    "\n",
    "modelfit(xgb3, train, test, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=10,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=5,seed=27), \n",
    " param_grid = param_test5, scoring='f1',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch5.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch5.cv_results_))\n",
    "print(gsearch5.best_params_)\n",
    "print(gsearch5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91859cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5a = {\n",
    " 'subsample':[i/100.0 for i in range(90,100)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(90,100)]\n",
    "}\n",
    "\n",
    "gsearch5a = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=10,\n",
    " min_child_weight=2, gamma=0, subsample=0.9, colsample_bytree=0.9,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=5,seed=27), \n",
    " param_grid = param_test5a, scoring='f1',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch5a.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch5a.cv_results_))\n",
    "print(gsearch5a.best_params_)\n",
    "print(gsearch5a.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=10,\n",
    " min_child_weight=2, gamma=0, subsample=0.9, colsample_bytree=0.68,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=5,seed=27), \n",
    " param_grid = param_test6, scoring='recall',n_jobs=4, cv=5)\n",
    "\n",
    "gsearch6.fit(train[predictors],train[target])\n",
    "\n",
    "print(pd.DataFrame(gsearch6.cv_results_))\n",
    "print(gsearch6.best_params_)\n",
    "print(gsearch6.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e059df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_normal.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
