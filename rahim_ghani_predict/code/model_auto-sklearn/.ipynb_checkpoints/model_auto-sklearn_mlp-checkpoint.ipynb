{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1627823919707,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "ZHsPkICZ5ybv"
   },
   "outputs": [],
   "source": [
    "!pip3 install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1627816541292,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "5yHG_EuS5psd"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1627826081364,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "NCv5Mc_95psi"
   },
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from autosklearn.metrics import accuracy, balanced_accuracy, precision, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "705RzKmaAwYl"
   },
   "source": [
    "# Define Score Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1627826083587,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "LAzX2dZYAsc-"
   },
   "outputs": [],
   "source": [
    "def error(solution, prediction):\n",
    "    # custom function defining error\n",
    "    return np.mean(solution != prediction)\n",
    "\n",
    "def get_metric_result(cv_results):\n",
    "    results = pd.DataFrame.from_dict(cv_results)\n",
    "    results = results[results['status'] == \"Success\"]\n",
    "    cols = ['rank_test_scores', 'param_classifier:__choice__', 'mean_test_score']\n",
    "    cols.extend([key for key in cv_results.keys() if key.startswith('metric_')])\n",
    "    return results[cols]\n",
    "\n",
    "error_rate = autosklearn.metrics.make_scorer(\n",
    "    name='custom_error',\n",
    "    score_func=error,\n",
    "    optimum=0,\n",
    "    greater_is_better=False,\n",
    "    needs_proba=False,\n",
    "    needs_threshold=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1627826085768,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "5xzYk1UDLRxA"
   },
   "outputs": [],
   "source": [
    "#define show result function\n",
    "def evaluate_model(model):\n",
    "\n",
    "  y_test_predict = model.predict(X_test)\n",
    "  y_test_predict_proba = model.predict_proba(X_test)\n",
    "  print(\"Accuracy score: \", sklearn.metrics.accuracy_score(y_test, y_test_predict))\n",
    "  print('Balanced Accuracy Score: ', sklearn.metrics.balanced_accuracy_score(y_test,y_test_predict))\n",
    "  print (\"Log Loss: \", sklearn.metrics.log_loss(y_test, y_test_predict_proba))\n",
    "  print(\"Precision Score: \", sklearn.metrics.precision_score(y_test, y_test_predict))\n",
    "  print(\"Recall Score: : \", sklearn.metrics.recall_score(y_test, y_test_predict))\n",
    "  print(\"F1 Score: \", sklearn.metrics.f1_score(y_test, y_test_predict))\n",
    "  print(\"F1 (beta=2) Score: \", sklearn.metrics.fbeta_score(y_test, y_test_predict,beta=2))\n",
    "  print(\"ROC Auc Score: \", sklearn.metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))\n",
    "  print ('Confusion Matrix: \\n', sklearn.metrics.confusion_matrix (y_test,y_test_predict))\n",
    "\n",
    "  print(\"#\" * 80)\n",
    "  print(\"Metric results\")\n",
    "  print(get_metric_result(model.cv_results_).to_string(index=False))\n",
    "\n",
    "  model.leaderboard()\n",
    "  model.sprint_statistics()\n",
    "  print(model.show_models())\n",
    "  model.get_models_with_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYqqLR6P5psi"
   },
   "source": [
    "## Data Loading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1453,
     "status": "ok",
     "timestamp": 1627826089426,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "o3gFC7pr5psj",
    "outputId": "2d42dc70-20f9-4623-f482-5fe4e405e3c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "#import all data\n",
    "data = pd.read_csv(r'/content/drive/MyDrive/msc-project-data/features_with_outcome.csv',encoding='utf=8')\n",
    "\n",
    "y_data = data['outcome']\n",
    "X_data = data.drop(columns = ['org_uuid','outcome'])\n",
    "\n",
    "#splitting data into test and full training set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data,y_data, test_size = 0.2,stratify=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6GgCJ2gfYJW"
   },
   "source": [
    "# Print a list of available Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1627816600343,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "Yzj3YToIfb8G",
    "outputId": "1ecb2766-a108-455e-a550-c7eaeae02658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaboost\n",
      "bernoulli_nb\n",
      "decision_tree\n",
      "extra_trees\n",
      "gaussian_nb\n",
      "gradient_boosting\n",
      "k_nearest_neighbors\n",
      "lda\n",
      "liblinear_svc\n",
      "libsvm_svc\n",
      "mlp\n",
      "multinomial_nb\n",
      "passive_aggressive\n",
      "qda\n",
      "random_forest\n",
      "sgd\n"
     ]
    }
   ],
   "source": [
    "import autosklearn.pipeline.components.classification\n",
    "for name in autosklearn.pipeline.components.classification.ClassifierChoice.get_components():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOhovElQAe0y"
   },
   "source": [
    "## Print a list of available metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1627765099259,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "sbx0xtTfAePX",
    "outputId": "c4b4b2d2-6bca-4c8a-e18c-f3489262502e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CLASSIFICATION metrics autosklearn.metrics.*:\n",
      "\t*accuracy\n",
      "\t*balanced_accuracy\n",
      "\t*roc_auc\n",
      "\t*average_precision\n",
      "\t*log_loss\n",
      "\t*precision\n",
      "\t*precision_macro\n",
      "\t*precision_micro\n",
      "\t*precision_samples\n",
      "\t*precision_weighted\n",
      "\t*recall\n",
      "\t*recall_macro\n",
      "\t*recall_micro\n",
      "\t*recall_samples\n",
      "\t*recall_weighted\n",
      "\t*f1\n",
      "\t*f1_macro\n",
      "\t*f1_micro\n",
      "\t*f1_samples\n",
      "\t*f1_weighted\n"
     ]
    }
   ],
   "source": [
    "print(\"Available CLASSIFICATION metrics autosklearn.metrics.*:\")\n",
    "print(\"\\t*\" + \"\\n\\t*\".join(autosklearn.metrics.CLASSIFICATION_METRICS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bo49XYIy5psk"
   },
   "source": [
    "## Build and fit a classifier (mlp) with default target metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1627826118961,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "YUeV_mLqAdRn"
   },
   "outputs": [],
   "source": [
    "#set up classifier, set no target metric\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=3600,\n",
    "    #per_run_time_limit=720,\n",
    "    include_estimators =['mlp'],\n",
    "    resampling_strategy ='cv',\n",
    "    resampling_strategy_arguments={'folds': 5},\n",
    "    ensemble_size=1,\n",
    "    include_preprocessors = ['no_preprocessing'],\n",
    "    scoring_functions=[accuracy, balanced_accuracy, precision, recall, f1, error_rate, roc_auc],\n",
    "    #metric=autosklearn.metrics.recall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9FHkxJPAZpY"
   },
   "outputs": [],
   "source": [
    "#fit classifier\n",
    "automl.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWeHxiyv5psl"
   },
   "source": [
    "## Get the Score of the final ensemble\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1195,
     "status": "ok",
     "timestamp": 1627829717182,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "3-VziovT5psl",
    "outputId": "edee5f03-8ab8-4d84-f573-d44b88d67412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7852419074138531\n",
      "Balanced Accuracy Score:  0.5808194918978788\n",
      "Log Loss:  0.4745093289016461\n",
      "Precision Score:  0.6129032258064516\n",
      "Recall Score: :  0.1996996996996997\n",
      "F1 Score:  0.3012457531143828\n",
      "F1 (beta=2) Score:  0.23082263103089204\n",
      "ROC Auc Score:  0.7366267207397701\n",
      "Confusion Matrix: \n",
      " [[4246  168]\n",
      " [1066  266]]\n",
      "################################################################################\n",
      "Metric results\n",
      " rank_test_scores param_classifier:__choice__  mean_test_score  metric_accuracy  metric_balanced_accuracy  metric_precision  metric_recall  metric_f1  metric_custom_error  metric_roc_auc\n",
      "               11                         mlp         0.775771         0.775771                  0.599044          0.533180       0.269468   0.357177             0.224229        0.729602\n",
      "               15                         mlp         0.768113         0.768113                  0.500000          0.000000       0.000000   0.000000             0.231887        0.500312\n",
      "                4                         mlp         0.780775         0.780775                  0.579906          0.584581       0.205302   0.300446             0.219225        0.732516\n",
      "                8                         mlp         0.778730         0.778730                  0.586887          0.557192       0.229123   0.324320             0.221270        0.730353\n",
      "               30                         mlp         0.583569         0.583569                  0.524870          0.200450       0.415423   0.267944             0.416431        0.535589\n",
      "               15                         mlp         0.768113         0.768113                  0.500000          0.000000       0.000000   0.000000             0.231887        0.500000\n",
      "               24                         mlp         0.709499         0.709499                  0.564163          0.361037       0.293121   0.298762             0.290501        0.653456\n",
      "               10                         mlp         0.776032         0.776032                  0.578256          0.545200       0.209423   0.302236             0.223968        0.713796\n",
      "               27                         mlp         0.660850         0.660850                  0.500000          0.046386       0.200035   0.075309             0.339150        0.592011\n",
      "               19                         mlp         0.767982         0.767982                  0.543472          0.457970       0.124788   0.179950             0.232018        0.694010\n",
      "               22                         mlp         0.742657         0.742657                  0.544785          0.300817       0.175797   0.210816             0.257343        0.645510\n",
      "               12                         mlp         0.770332         0.770332                  0.601990          0.508474       0.288050   0.367535             0.229668        0.712582\n",
      "                1                         mlp         0.783343         0.783343                  0.575611          0.608727       0.188216   0.287094             0.216657        0.733961\n",
      "               15                         mlp         0.768113         0.768113                  0.500000          0.000000       0.000000   0.000000             0.231887        0.500000\n",
      "                3                         mlp         0.781254         0.781254                  0.583684          0.576227       0.215238   0.313212             0.218746        0.735553\n",
      "               21                         mlp         0.763109         0.763109                  0.595716          0.485770       0.283546   0.355926             0.236891        0.703011\n",
      "               14                         mlp         0.768156         0.768156                  0.500094          0.199991       0.000188   0.000375             0.231844        0.567609\n",
      "               26                         mlp         0.660894         0.660894                  0.500000          0.046386       0.199991   0.075306             0.339106        0.500000\n",
      "               13                         mlp         0.769201         0.769201                  0.507256          0.114281       0.018761   0.032231             0.230799        0.544869\n",
      "               20                         mlp         0.766938         0.766938                  0.507815          0.451953       0.024582   0.046553             0.233062        0.676443\n",
      "                2                         mlp         0.782472         0.782472                  0.584934          0.584507       0.216549   0.315770             0.217528        0.738383\n",
      "               15                         mlp         0.768113         0.768113                  0.500000          0.000000       0.000000   0.000000             0.231887        0.532412\n",
      "               28                         mlp         0.656020         0.656020                  0.498129          0.072023       0.203557   0.081510             0.343980        0.498129\n",
      "               25                         mlp         0.705539         0.705539                  0.578219          0.357455       0.340779   0.348750             0.294461        0.625087\n",
      "                7                         mlp         0.779035         0.779035                  0.592725          0.553080       0.245272   0.338683             0.220965        0.725247\n",
      "                6                         mlp         0.779992         0.779992                  0.572385          0.472936       0.185219   0.262077             0.220008        0.683926\n",
      "                5                         mlp         0.780645         0.780645                  0.585383          0.571411       0.221242   0.318514             0.219355        0.737880\n",
      "               23                         mlp         0.736260         0.736260                  0.590865          0.418663       0.319735   0.354773             0.263740        0.669164\n",
      "               29                         mlp         0.639789         0.639789                  0.576689          0.301661       0.459014   0.301155             0.360211        0.681253\n",
      "                9                         mlp         0.777555         0.777555                  0.595492          0.550395       0.255963   0.345502             0.222445        0.731301\n",
      "[(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'mlp', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:mlp:activation': 'tanh', 'classifier:mlp:alpha': 0.00015449319712477246, 'classifier:mlp:batch_size': 'auto', 'classifier:mlp:beta_1': 0.9, 'classifier:mlp:beta_2': 0.999, 'classifier:mlp:early_stopping': 'valid', 'classifier:mlp:epsilon': 1e-08, 'classifier:mlp:hidden_layer_depth': 1, 'classifier:mlp:learning_rate_init': 0.00012619863932697268, 'classifier:mlp:n_iter_no_change': 32, 'classifier:mlp:num_nodes_per_layer': 121, 'classifier:mlp:shuffle': 'True', 'classifier:mlp:solver': 'adam', 'classifier:mlp:tol': 0.0001, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004357811688882498, 'classifier:mlp:validation_fraction': 0.1},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(automl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXkSkKTqK22f"
   },
   "source": [
    "# Build and fit classifier (mlp) with f1 as target metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZ1qSZtMib9D"
   },
   "outputs": [],
   "source": [
    "#set up classifier, set no target metric\n",
    "automl1 = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=3600,\n",
    "    #per_run_time_limit=720,\n",
    "    include_estimators =['mlp'],\n",
    "    resampling_strategy ='cv',\n",
    "    resampling_strategy_arguments={'folds': 5},\n",
    "    ensemble_size=1,\n",
    "    include_preprocessors = ['no_preprocessing'],\n",
    "    scoring_functions=[accuracy, balanced_accuracy, precision, recall, f1, error_rate, roc_auc],\n",
    "    metric=autosklearn.metrics.f1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bN6lWYwcLDRN"
   },
   "outputs": [],
   "source": [
    "automl1.fit(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1627833314445,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "JxRZNI8nLJka",
    "outputId": "c0cf6f69-c89b-4688-b4aa-9b0f72dffdc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.7399930386355725\n",
      "Balanced Accuracy Score:  0.6200377994668888\n",
      "Log Loss:  0.5589776003877271\n",
      "Precision Score:  0.43349753694581283\n",
      "Recall Score: :  0.3963963963963964\n",
      "F1 Score:  0.41411764705882353\n",
      "F1 (beta=2) Score:  0.4032997250229147\n",
      "ROC Auc Score:  0.6947280595049058\n",
      "Confusion Matrix: \n",
      " [[3724  690]\n",
      " [ 804  528]]\n",
      "################################################################################\n",
      "Metric results\n",
      " rank_test_scores param_classifier:__choice__  mean_test_score  metric_accuracy  metric_balanced_accuracy  metric_precision  metric_recall  metric_f1  metric_custom_error  metric_roc_auc\n",
      "                8                         mlp         0.357177         0.775771                  0.599044          0.533180       0.269468   0.357177             0.224229        0.729602\n",
      "               18                         mlp         0.284950         0.769636                  0.583309          0.595118       0.235849   0.284950             0.230364        0.740527\n",
      "               16                         mlp         0.300446         0.780775                  0.579906          0.584581       0.205302   0.300446             0.219225        0.732516\n",
      "               13                         mlp         0.324320         0.778730                  0.586887          0.557192       0.229123   0.324320             0.221270        0.730353\n",
      "               19                         mlp         0.267944         0.583569                  0.524870          0.200450       0.415423   0.267944             0.416431        0.535589\n",
      "               24                         mlp         0.000000         0.768113                  0.500000          0.000000       0.000000   0.000000             0.231887        0.500000\n",
      "               17                         mlp         0.298762         0.709499                  0.564163          0.361037       0.293121   0.298762             0.290501        0.653456\n",
      "                7                         mlp         0.359354         0.705670                  0.583944          0.366503       0.356927   0.359354             0.294330        0.632214\n",
      "               21                         mlp         0.173080         0.701014                  0.546023          0.234799       0.257025   0.173080             0.298986        0.591410\n",
      "               22                         mlp         0.082343         0.768243                  0.524442          0.100400       0.069791   0.082343             0.231757        0.561962\n",
      "                3                         mlp         0.372906         0.751055                  0.602274          0.468906       0.324819   0.372906             0.248945        0.697498\n",
      "                4                         mlp         0.367822         0.721379                  0.591608          0.388387       0.349601   0.367822             0.278621        0.638961\n",
      "                6                         mlp         0.359977         0.730517                  0.597759          0.430533       0.350171   0.359977             0.269483        0.669689\n",
      "               15                         mlp         0.300889         0.782603                  0.580304          0.589858       0.203040   0.300889             0.217397        0.737910\n",
      "               20                         mlp         0.205436         0.557417                  0.514553          0.223077       0.434698   0.205436             0.442583        0.546640\n",
      "               10                         mlp         0.355853         0.742962                  0.590592          0.424676       0.306439   0.355853             0.257038        0.675051\n",
      "                5                         mlp         0.361578         0.755189                  0.596842          0.466988       0.301549   0.361578             0.244811        0.681082\n",
      "               12                         mlp         0.339926         0.758148                  0.587637          0.466406       0.269654   0.339926             0.241852        0.686860\n",
      "               14                         mlp         0.322814         0.765545                  0.584142          0.500906       0.245837   0.322814             0.234455        0.704995\n",
      "                9                         mlp         0.356361         0.721335                  0.586470          0.385581       0.334959   0.356361             0.278665        0.633881\n",
      "                1                         mlp         0.393751         0.706671                  0.605292          0.385229       0.416223   0.393751             0.293329        0.656381\n",
      "               23                         mlp         0.004448         0.768200                  0.500842          0.223800       0.002251   0.004448             0.231800        0.499258\n",
      "               11                         mlp         0.348439         0.746095                  0.590463          0.441793       0.300235   0.348439             0.253905        0.669707\n",
      "                2                         mlp         0.376523         0.749967                  0.601899          0.447078       0.325768   0.376523             0.250033        0.665347\n",
      "[(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'mlp', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:mlp:activation': 'relu', 'classifier:mlp:alpha': 0.013284534092105787, 'classifier:mlp:batch_size': 'auto', 'classifier:mlp:beta_1': 0.9, 'classifier:mlp:beta_2': 0.999, 'classifier:mlp:early_stopping': 'train', 'classifier:mlp:epsilon': 1e-08, 'classifier:mlp:hidden_layer_depth': 2, 'classifier:mlp:learning_rate_init': 0.0010281896956218979, 'classifier:mlp:n_iter_no_change': 32, 'classifier:mlp:num_nodes_per_layer': 85, 'classifier:mlp:shuffle': 'True', 'classifier:mlp:solver': 'adam', 'classifier:mlp:tol': 0.0001},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(automl1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--hzcjMPbDG8"
   },
   "source": [
    "# Build and fit classifier (mlp) with recall as target metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1627833314446,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "iximzObwbF7b"
   },
   "outputs": [],
   "source": [
    "#set up classifier, set recall as target metric\n",
    "automl2 = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=3600,\n",
    "    #per_run_time_limit=720,\n",
    "    include_estimators =['mlp'],\n",
    "    resampling_strategy ='cv',\n",
    "    resampling_strategy_arguments={'folds': 5},\n",
    "    ensemble_size=1,\n",
    "    include_preprocessors = ['no_preprocessing'],\n",
    "    scoring_functions=[accuracy, balanced_accuracy, precision, recall, f1, error_rate, roc_auc],\n",
    "    metric=autosklearn.metrics.recall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0oKHMYrbLno"
   },
   "outputs": [],
   "source": [
    "automl2.fit(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1436,
     "status": "ok",
     "timestamp": 1627836910495,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "vW7k3kn_bOpl",
    "outputId": "06fb9d46-5c04-4daa-94fa-4988cc69722e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.755134006265228\n",
      "Balanced Accuracy Score:  0.6511228605134359\n",
      "Log Loss:  0.5186550964606867\n",
      "Precision Score:  0.4709976798143852\n",
      "Recall Score: :  0.4572072072072072\n",
      "F1 Score:  0.464\n",
      "F1 (beta=2) Score:  0.4599003171726325\n",
      "ROC Auc Score:  0.7208713300976555\n",
      "Confusion Matrix: \n",
      " [[3730  684]\n",
      " [ 723  609]]\n",
      "################################################################################\n",
      "Metric results\n",
      " rank_test_scores param_classifier:__choice__  mean_test_score  metric_accuracy  metric_balanced_accuracy  metric_precision  metric_recall  metric_f1  metric_custom_error  metric_roc_auc\n",
      "               10                         mlp         0.269468         0.775771                  0.599044          0.533180       0.269468   0.357177             0.224229        0.729602\n",
      "               18                         mlp         0.205302         0.780775                  0.579906          0.584581       0.205302   0.300446             0.219225        0.732516\n",
      "               13                         mlp         0.238123         0.766851                  0.582295          0.516497       0.238123   0.311477             0.233149        0.705151\n",
      "                2                         mlp         0.415423         0.583569                  0.524870          0.200450       0.415423   0.267944             0.416431        0.535589\n",
      "               19                         mlp         0.199991         0.660894                  0.500000          0.046386       0.199991   0.075306             0.339106        0.500000\n",
      "               15                         mlp         0.224980         0.769418                  0.579377          0.528196       0.224980   0.291061             0.230582        0.691762\n",
      "               27                         mlp         0.020825         0.767025                  0.506560          0.186760       0.020825   0.037433             0.232975        0.545560\n",
      "               14                         mlp         0.228562         0.783604                  0.589865          0.590525       0.228562   0.328700             0.216396        0.735534\n",
      "                8                         mlp         0.286172         0.728428                  0.574057          0.430854       0.286172   0.313747             0.271572        0.641370\n",
      "                3                         mlp         0.353171         0.726774                  0.596368          0.399775       0.353171   0.373706             0.273226        0.660918\n",
      "               26                         mlp         0.102247         0.748836                  0.523136          0.071099       0.102247   0.083875             0.251164        0.523509\n",
      "               19                         mlp         0.199991         0.660894                  0.500000          0.046386       0.199991   0.075306             0.339106        0.500000\n",
      "               12                         mlp         0.245641         0.775641                  0.590643          0.537601       0.245641   0.335741             0.224359        0.711214\n",
      "               28                         mlp         0.009757         0.766459                  0.502329          0.376263       0.009757   0.018918             0.233541        0.500593\n",
      "                4                         mlp         0.348096         0.728776                  0.595898          0.412954       0.348096   0.370306             0.271224        0.673038\n",
      "                1                         mlp         0.467446         0.694922                  0.615521          0.392432       0.467446   0.409898             0.305078        0.687558\n",
      "               16                         mlp         0.220112         0.784039                  0.587197          0.594400       0.220112   0.319950             0.215961        0.740794\n",
      "                9                         mlp         0.270766         0.766851                  0.593687          0.521318       0.270766   0.344205             0.233149        0.709450\n",
      "               11                         mlp         0.267180         0.702406                  0.550479          0.352832       0.267180   0.263997             0.297594        0.617617\n",
      "               25                         mlp         0.128528         0.742875                  0.528432          0.299241       0.128528   0.159326             0.257125        0.585677\n",
      "                7                         mlp         0.312073         0.658718                  0.537720          0.283400       0.312073   0.282219             0.341282        0.619423\n",
      "                6                         mlp         0.329525         0.712545                  0.578850          0.482771       0.329525   0.328713             0.287455        0.684843\n",
      "               29                         mlp         0.001314         0.768026                  0.500402          0.087496       0.001314   0.002590             0.231974        0.500038\n",
      "               21                         mlp         0.150881         0.780166                  0.560514          0.614637       0.150881   0.237796             0.219834        0.734887\n",
      "               24                         mlp         0.133788         0.770463                  0.548227          0.440461       0.133788   0.191838             0.229537        0.696989\n",
      "               22                         mlp         0.146409         0.769157                  0.551793          0.317033       0.146409   0.186168             0.230843        0.690941\n",
      "               17                         mlp         0.210720         0.781733                  0.582416          0.591333       0.210720   0.303251             0.218267        0.737919\n",
      "               30                         mlp         0.000000         0.768069                  0.499972          0.000000       0.000000   0.000000             0.231931        0.499972\n",
      "                5                         mlp         0.333254         0.725860                  0.588816          0.400293       0.333254   0.356792             0.274140        0.655644\n",
      "               23                         mlp         0.136767         0.716766                  0.514307          0.055267       0.136767   0.078722             0.283234        0.533341\n",
      "[(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'mlp', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'power_transformer', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:mlp:activation': 'relu', 'classifier:mlp:alpha': 2.393650878910808e-06, 'classifier:mlp:batch_size': 'auto', 'classifier:mlp:beta_1': 0.9, 'classifier:mlp:beta_2': 0.999, 'classifier:mlp:early_stopping': 'train', 'classifier:mlp:epsilon': 1e-08, 'classifier:mlp:hidden_layer_depth': 2, 'classifier:mlp:learning_rate_init': 0.0006058479468336154, 'classifier:mlp:n_iter_no_change': 32, 'classifier:mlp:num_nodes_per_layer': 113, 'classifier:mlp:shuffle': 'True', 'classifier:mlp:solver': 'adam', 'classifier:mlp:tol': 0.0001},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(automl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN_ryE6wpkQ2"
   },
   "source": [
    "# Build and fit classifier (mlp) with ROC AUC as target metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1627836910496,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "k3TobYyiptNH"
   },
   "outputs": [],
   "source": [
    "#set up classifier, set ROC AUC as target metric\n",
    "automl3 = autosklearn.classification.AutoSklearnClassifier(\n",
    "    time_left_for_this_task=3600,\n",
    "    #per_run_time_limit=720,\n",
    "    include_estimators =['mlp'],\n",
    "    resampling_strategy ='cv',\n",
    "    resampling_strategy_arguments={'folds': 5},\n",
    "    ensemble_size=1,\n",
    "    include_preprocessors = ['no_preprocessing'],\n",
    "    scoring_functions=[accuracy, balanced_accuracy, precision, recall, f1, error_rate, roc_auc],\n",
    "    metric=autosklearn.metrics.roc_auc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1627840507691,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "w6riwyNZp2jn",
    "outputId": "613391bd-2b67-48bd-86f7-f0e881957f11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(ensemble_size=1, include_estimators=['mlp'],\n",
       "                      include_preprocessors=['no_preprocessing'],\n",
       "                      metric=roc_auc, per_run_time_limit=360,\n",
       "                      resampling_strategy='cv',\n",
       "                      resampling_strategy_arguments={'folds': 5},\n",
       "                      scoring_functions=[accuracy, balanced_accuracy, precision,\n",
       "                                         recall, f1, custom_error, roc_auc])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl3.fit(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1627840508327,
     "user": {
      "displayName": "Abdul Rahim Ab Ghani",
      "photoUrl": "",
      "userId": "00278979136237245233"
     },
     "user_tz": -60
    },
    "id": "5Gj0eK9Bp8Bp",
    "outputId": "58494003-b8ca-4b49-8a4b-d4529ff337aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.78820048729551\n",
      "Balanced Accuracy Score:  0.5979469501218482\n",
      "Log Loss:  0.4694031419361856\n",
      "Precision Score:  0.6078799249530957\n",
      "Recall Score: :  0.24324324324324326\n",
      "F1 Score:  0.3474530831099196\n",
      "F1 (beta=2) Score:  0.2764033441392254\n",
      "ROC Auc Score:  0.7468827855948382\n",
      "Confusion Matrix: \n",
      " [[4205  209]\n",
      " [1008  324]]\n",
      "################################################################################\n",
      "Metric results\n",
      " rank_test_scores param_classifier:__choice__  mean_test_score  metric_accuracy  metric_balanced_accuracy  metric_precision  metric_recall  metric_f1  metric_custom_error  metric_roc_auc\n",
      "               12                         mlp         0.729602         0.775771                  0.599044          0.533180       0.269468   0.357177             0.224229        0.729602\n",
      "               10                         mlp         0.732516         0.780775                  0.579906          0.584581       0.205302   0.300446             0.219225        0.732516\n",
      "               19                         mlp         0.705151         0.766851                  0.582295          0.516497       0.238123   0.311477             0.233149        0.705151\n",
      "               26                         mlp         0.535589         0.583569                  0.524870          0.200450       0.415423   0.267944             0.416431        0.535589\n",
      "               28                         mlp         0.500000         0.660894                  0.500000          0.046386       0.199991   0.075306             0.339106        0.500000\n",
      "               21                         mlp         0.691762         0.769418                  0.579377          0.528196       0.224980   0.291061             0.230582        0.691762\n",
      "               24                         mlp         0.545560         0.767025                  0.506560          0.186760       0.020825   0.037433             0.232975        0.545560\n",
      "                8                         mlp         0.735534         0.783604                  0.589865          0.590525       0.228562   0.328700             0.216396        0.735534\n",
      "                7                         mlp         0.735654         0.778817                  0.591723          0.588545       0.242817   0.324039             0.221183        0.735654\n",
      "                9                         mlp         0.735048         0.781559                  0.577656          0.592437       0.197404   0.290677             0.218441        0.735048\n",
      "                4                         mlp         0.740534         0.783299                  0.593663          0.578688       0.240011   0.339104             0.216701        0.740534\n",
      "                5                         mlp         0.739741         0.785301                  0.584617          0.610534       0.210362   0.312000             0.214699        0.739741\n",
      "               25                         mlp         0.536191         0.628128                  0.518372          0.155140       0.313719   0.193651             0.371872        0.536191\n",
      "               20                         mlp         0.696329         0.764109                  0.598199          0.485372       0.288795   0.362011             0.235891        0.696329\n",
      "                6                         mlp         0.736506         0.783778                  0.585457          0.594364       0.215612   0.316108             0.216222        0.736506\n",
      "               15                         mlp         0.722527         0.767286                  0.568513          0.303391       0.197811   0.229426             0.232714        0.722527\n",
      "                2                         mlp         0.743421         0.782255                  0.590428          0.578423       0.232691   0.330948             0.217745        0.743421\n",
      "               23                         mlp         0.655264         0.731430                  0.591011          0.403271       0.329145   0.362358             0.268570        0.655264\n",
      "               28                         mlp         0.500000         0.553631                  0.500000          0.092772       0.400026   0.150615             0.446369        0.500000\n",
      "               22                         mlp         0.677485         0.776511                  0.566380          0.447407       0.174512   0.246482             0.223489        0.677485\n",
      "               28                         mlp         0.500000         0.446456                  0.500000          0.139158       0.599974   0.225917             0.553544        0.500000\n",
      "               18                         mlp         0.707652         0.775206                  0.563696          0.548192       0.169258   0.258421             0.224794        0.707652\n",
      "               13                         mlp         0.728521         0.781863                  0.582703          0.587880       0.211293   0.308569             0.218137        0.728521\n",
      "               14                         mlp         0.726175         0.777599                  0.593159          0.544928       0.249200   0.341804             0.222401        0.726175\n",
      "               11                         mlp         0.730916         0.764545                  0.582499          0.564953       0.243006   0.292116             0.235455        0.730916\n",
      "               27                         mlp         0.500113         0.768113                  0.500000          0.000000       0.000000   0.000000             0.231887        0.500113\n",
      "                1                         mlp         0.743445         0.785954                  0.595390          0.596780       0.240010   0.340976             0.214046        0.743445\n",
      "               17                         mlp         0.709572         0.767808                  0.602966          0.499086       0.295554   0.371064             0.232192        0.709572\n",
      "               16                         mlp         0.717845         0.763631                  0.598330          0.515934       0.290082   0.349103             0.236369        0.717845\n",
      "                3                         mlp         0.740845         0.784779                  0.586832          0.600670       0.217681   0.319070             0.215221        0.740845\n",
      "[(1.000000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'mlp', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:mlp:activation': 'tanh', 'classifier:mlp:alpha': 9.665261082400155e-06, 'classifier:mlp:batch_size': 'auto', 'classifier:mlp:beta_1': 0.9, 'classifier:mlp:beta_2': 0.999, 'classifier:mlp:early_stopping': 'valid', 'classifier:mlp:epsilon': 1e-08, 'classifier:mlp:hidden_layer_depth': 1, 'classifier:mlp:learning_rate_init': 0.0007970354737198188, 'classifier:mlp:n_iter_no_change': 32, 'classifier:mlp:num_nodes_per_layer': 23, 'classifier:mlp:shuffle': 'True', 'classifier:mlp:solver': 'adam', 'classifier:mlp:tol': 0.0001, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.00461760267983248, 'classifier:mlp:validation_fraction': 0.1},\n",
      "dataset_properties={\n",
      "  'task': 1,\n",
      "  'sparse': False,\n",
      "  'multilabel': False,\n",
      "  'multiclass': False,\n",
      "  'target_type': 'classification',\n",
      "  'signed': False})),\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(automl3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "model_auto-sklearn_mlp.ipynb",
   "provenance": [
    {
     "file_id": "1OBuuIGkqoaiDX_pOytlDvxvCZkmNUfG4",
     "timestamp": 1627764862484
    },
    {
     "file_id": "1ydk0fJ76WJwLdmJs0jOTCkLSRpVMiHMW",
     "timestamp": 1627758268184
    },
    {
     "file_id": "1MSBUUELKgclQakDSNY554-8O5gGz-Osk",
     "timestamp": 1627736238026
    },
    {
     "file_id": "1daGkmz-CFDKuHL7FT3inLWHXmfXVOVVI",
     "timestamp": 1627657018630
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
