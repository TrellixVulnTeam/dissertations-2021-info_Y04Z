{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa import Agent, Model\n",
    "from mesa.time import RandomActivation, BaseScheduler\n",
    "from mesa.datacollection import DataCollector\n",
    "\n",
    "from scipy.stats import powerlaw, lognorm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import powerlaw as pr\n",
    "from numpy.random import normal\n",
    "import random\n",
    "from operator import attrgetter\n",
    "from ddpg import Agent, ReplayBuffer, OUActionNoise, CriticNetwork, ActorNetwork\n",
    "\n",
    "import torch\n",
    "\n",
    "#Initialize the reinforcement learning model \n",
    "agent = Agent(alpha = 0.001, beta = 0.001, input_dims = [12], tau = 0.001, env = 1, batch_size = 64, layer1_size = 400, layer2_size = 300, n_actions=1)\n",
    "\n",
    "##VC Coefficients\n",
    "#VC Coefficients - General\n",
    "Number_of_VCs = 100 #approximate number of VCs in USA. In fact, it is 1000, but for computaional reasons we devide everything by 10\n",
    "Fund_maturity = 40 #the number of time steps until the outcome of the fund is realised, 1 step=3months\n",
    "VC_quality_alpha = 2.06 #alpha coefficient for power law distribution\n",
    "VC_quality_x_min = 0 #x_min coefficient for power law distribution\n",
    "VC_max_TVPI = 14 #we want to normalize VC_quality so that it lies between 0 and 1\n",
    "Average_portfolio_size = 32 #Based on real world data\n",
    "\n",
    "#VC Coefficients - Employees\n",
    "Number_of_employees_sd = 1.3711 #standard deviation coefficinet for lognormal distribution of number of employees\n",
    "Number_of_employees_loc = 0.8426 #loc coefficient for lognormal distribution of number of employees\n",
    "Number_of_employees_scale = 9.5626 #scale coefficient for lognormal distribution of number of employees\n",
    "VC_work_hours_per_week = 56 #Average numebr of hours worked by an analyst in VC\n",
    "Work_weeks_per_month = 4 \n",
    "Work_hours_per_month = VC_work_hours_per_week*Work_weeks_per_month #Work hours per months per employee in VC\n",
    "Work_hours_per_3months = Work_hours_per_month*3 #1 time step = 3 months, thus we are interested in hours per 3 months\n",
    "Percentage_of_time_spend_on_other_activities = 0.31 #time spend by VC employee on activitties not related to either screening or advising\n",
    "Time_for_screening_and_monitroring_3months_per_emp = Work_hours_per_3months*(1-Percentage_of_time_spend_on_other_activities)\n",
    "Number_of_funds_at_operation = 2 #at same time, VC takes care of multiple funds\n",
    "Time_for_screening_and_monitroring_3months_per_emp_per_fund = Time_for_screening_and_monitroring_3months_per_emp/Number_of_funds_at_operation\n",
    "Average_number_of_investemnt_analysts = 19 #Based on real-world data \n",
    "\n",
    "#VC Coefficients - Time needed\n",
    "Screening_time = 60 #Time in hours needed to screen a startup\n",
    "Advising_time = 27.5 #Time in hours needed per time step(i.e. 3 months) to advise to a startup in the portfolio \n",
    "\n",
    "#VC Coefficients - Returns\n",
    "Early_returns_alpha = 2.3758 #alpha coefficient for power law distribution of early stage retruns\n",
    "Early_returns_x_min = 4.5761 #X_min coefficeint for power law distribution of early stage returns\n",
    "Early_startup_exit = 32 #number of time steps it takes early startup to exit\n",
    "Late_returns_lognormal_sd = 0.98981 #standard deviation for log normal distribution of late stage returns\n",
    "Late_returns_lognormal_loc = -0.133236 #location coefficient for log normal distribution of late stage returns\n",
    "Late_returns_lognormal_scale = 1.79759 #scale coefficinet for log normal distribution of late stage returns\n",
    "Late_startup_exit = 24 #number of time steps it takes a late stage startup to exit\n",
    "\n",
    "##Startup Coefficients\n",
    "#Startup Coefficients - General\n",
    "Number_of_new_startups = 25600 #Number of business starts in USA every 3 months, In fact, it is 256000, but for computaional reasons we devide everything by 10\n",
    "Number_of_late_stage_startups = 36 #It is in fact 355, but we divide everything by 10 for computational reasons\n",
    "EPI_alpha = 0.29872 #alpha coefficient for power law distribution of EPI which is taken as a proxy for startup potential\n",
    "EPI_loc = 0 #location coefficient for power law distribution of EPI\n",
    "EPI_scale = 1 #scale coefficient for power law distribtuion of EPI\n",
    "Percentage_of_startups_getting_to_later_stage = 0.2979 #Percentage of startups which recieve funding in 1st and 2nd round \n",
    "\n",
    "#Startup Coefficients - Time progression equation\n",
    "#EPI = Alpha*EPI + Beat*VC + Industry_Shock + Macro_Shock + Idiosyncratic_shock\n",
    "Alpha = 0.99 #alpha coefficient for time progression equation. Expresses weight of EPI\n",
    "Beta = 0.01 #beta coefficient for time progression equation. Expresses the weight of VC \n",
    "Macro_shock_mean = 0 #mean for normal distribution of macro shock\n",
    "Macro_shock_sd = 0.0681 #standard deviation for normal distribution of macro shock\n",
    "Industry_shock_mean = 0 #mean for normal distribution of industry shock\n",
    "Industry_shock_sd = 0.0432 #standard deviatio for normal distribution of industry shock\n",
    "Idiosyncratic_shock_mean = 0 #mean for normal distribution for idiosyncratic shock\n",
    "Idiosyncratic_shock_sd = 0.0775 #standard deviation for normal distribtion for idiosyncratic shock\n",
    "\n",
    "#Startup Coefficeints - Industries\n",
    "List_of_Industries = [\"Business Productivity Software\", \"Drug Discovery\", \"Financial Software\", \"Media and Infromation Services\", \"Network Management Software\", \"Biotechnology\", \"Application Software\", \"Therapeutic Devices\", \"Surgical Devices\", \"Other Healthcare Tech Systems\"]\n",
    "Probability_Distribution_of_Industries = [0.3486, 0.1133, 0.10841, 0.1006, 0.0844, 0.0729, 0.0556, 0.0440, 0.0365, 0.0357]\n",
    "Correlation_matrix = pd.read_excel(\"Correlation_matrix.xlsx\")\n",
    "Correlation_matrix.index = Correlation_matrix[\"Unnamed: 0\"]\n",
    "del Correlation_matrix[\"Unnamed: 0\"]\n",
    "\n",
    "#Startup Coefficients - Screening\n",
    "Noise_mean_before_screening_ES = 0 #mean for normal distribution of noise before screening for early stage startups\n",
    "Noise_standard_deviation_before_screening_ES = 0.75 #standard deviation for normal distribution of noise before screening for early stage startups\n",
    "Noise_mean_after_screening_ES = 0 #mean for normal distribution of noise after screening for early stage startups\n",
    "Noise_standard_deviation_after_screening_ES = 0.2 #standard deviation for normal distribution of noise after screening for early stage startups\n",
    "Noise_mean_before_screnniing_LS = 0 #mean for normal distribution of noise before screening for late stage startups\n",
    "Noise_standard_deviation_before_screening_LS = 0.53 #standard deviation for normal distribution of noise before screening for late stage startups\n",
    "Noise_mean_after_screening_LS = 0 #mean for normal distribution of noise after screening for late stage startups\n",
    "Noise_mean_before_screnniing_LS = 0.14 #standard deviation for normal distribution of noise after screening for late stage startups\n",
    "\n",
    "#Startup Coefficients - Investors\n",
    "Number_of_investors_per_round = 5 #max number of investors allowed to invest in startup\n",
    "Number_of_due_diligence_investors = 10 #number of investors enagaged in due diligence\n",
    "\n",
    "##A sample of early stage returns, used for potential -> return mapping\n",
    "#powerlaw package does not have an inverse cdf function, hence we apporximate it with a sample\n",
    "sample_size = 10000\n",
    "theoretical_distribution_ER = pr.Power_Law(x_min = Early_returns_x_min, parameters = [Early_returns_alpha])\n",
    "simulated_data_ER = theoretical_distribution_ER.generate_random(sample_size)\n",
    "simulated_data_new_ER = []\n",
    "for i in simulated_data_ER: #simulated data start with 1, but rerturns start with 0, hence we translate the smaple by -1\n",
    "    i = i-1\n",
    "    simulated_data_new_ER.append(i)\n",
    "sample_data_ER = sorted(simulated_data_new_ER)\n",
    "\n",
    "##A distribution for VC_quality\n",
    "theoretical_distribution_VC = pr.Power_Law(x_min = VC_quality_x_min, parameters = [VC_quality_alpha])\n",
    "\n",
    "##General model coefficents\n",
    "Risk_free_rate = 1.521 #10 year return on us treasury bill\n",
    "Estimate_of_early_stage_screenings = int((Number_of_VCs * Average_number_of_investemnt_analysts * (Time_for_screening_and_monitroring_3months_per_emp_per_fund/Screening_time)*(1-Percentage_of_startups_getting_to_later_stage))/(Number_of_due_diligence_investors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here we define class for VC, Startup and Activation\n",
    "#VC is assigend a unique id, VC quality and the number of investment analysts\n",
    "class VC(Agent):\n",
    "    def __init__(self, unique_id, VC_quality, Investment_analysts, Fund_life_stage, model):\n",
    "        self.unique_id = unique_id\n",
    "        self.model = model\n",
    "        self.VC_quality = VC_quality\n",
    "        self.Fund_life_stage = Fund_life_stage\n",
    "        self.Investment_analysts = Investment_analysts\n",
    "        self.Endowement = 1\n",
    "        self.Screening_prospects = []\n",
    "        self.Portfolio = []\n",
    "        self.Portfolio_size = len(self.Portfolio)\n",
    "        self.Effort_left_for_fund = self.Investment_analysts*Time_for_screening_and_monitroring_3months_per_emp_per_fund\n",
    "        self.Effort_allocated_to_startups_in_portfolio = self.Portfolio_size*Advising_time\n",
    "        self.Effort_left_for_screening = self.Effort_left_for_fund - self.Effort_allocated_to_startups_in_portfolio\n",
    "        self.Number_of_available_screenings = self.Effort_left_for_screening/Screening_time \n",
    "        self.Time_till_end_of_investment_stage_E = max(0, (Fund_maturity - Early_startup_exit - self.Fund_life_stage))\n",
    "        self.Time_till_end_of_investment_stage_L = max(0, (Fund_maturity - Late_startup_exit - self.Fund_life_stage))\n",
    "        \n",
    "    #This funciton enables us to map EPI (startup potnetial) into returns\n",
    "    def EPI_to_returns(self, EPI, stage):\n",
    "        #This gives us probability of observing EPI less or equal to observed vlaue\n",
    "        probability = powerlaw.cdf(EPI, EPI_alpha, EPI_loc, EPI_scale)\n",
    "        #If VC has invested in the startup in early stage then:\n",
    "        if stage == \"Early\":\n",
    "            return float(sample_data_ER[int(sample_size*probability)])\n",
    "        #If VC has invested in the startup in later stage then:\n",
    "        if stage == \"Late\":\n",
    "            return float(lognorm.ppf(probability, Late_returns_lognormal_sd, Late_returns_lognormal_loc, Late_returns_lognormal_scale))        \n",
    "    \n",
    "    #Projects EPI fo startups into the future\n",
    "    def time_progression_projected(self, EPI):\n",
    "        EPI_ = Alpha*EPI + Beta*self.VC_quality + np.random.normal(Idiosyncratic_shock_mean, Idiosyncratic_shock_sd)\\\n",
    "        + np.random.normal(Industry_shock_mean, Industry_shock_sd) + np.random.normal(Macro_shock_mean, Macro_shock_sd)\n",
    "        return EPI_\n",
    "\n",
    "    #Calculates expecetd covariance between two startups\n",
    "    #Since EPI_final boils down to EPI_final ≈ Alpha^32*EPI_0 + (Alpha^31 + Alpha^30 + ...+ 1) *Beta*Advising\n",
    "    #+(Alpha^31 + Alpha^30 + ...+ 1) * Average_Idiosyncratic_shock + (Alpha^31 + Alpha^30 + ...+ 1) *Averga_Industry_shock +(Alpha^31 + Alpha^30 + ...+ 1) *Averga_Macro_shock\n",
    "    # the Cov(Startup_1, Startup_2) = \n",
    "    def expected_covariance(self, startup_1, startup_2):\n",
    "        time_together = Early_startup_exit - max(getattr(startup_1, \"Life_stage\"), getattr(startup_2, \"Life_stage\"))\n",
    "        alpha_sumation_1 = Alpha**(1 + Early_startup_exit - getattr(startup_1, \"Life_stage\")+time_together)*((1 - Alpha^(1+Early_startup_exit-getattr(startup_1, \"Life_stage\")))/(1-Alpha))\n",
    "        alpha_sumation_2 = Alpha**(1 + Early_startup_exit - getattr(startup_2, \"Life_stage\")+time_together)*((1 - Alpha^(1+Early_startup_exit-getattr(startup_2, \"Life_stage\")))/(1-Alpha))   \n",
    "        Industry_correlation =  Correlation_matrix.loc[getattr(startup_1, \"Industry\"), getattr(startup_1, \"Industry\")] \n",
    "        return alpha_sumation_1*alpha_sumation_2*Industry_correlation*Industry_shock_sd^2 + alpha_sumation_1*alpha_sumation_2\n",
    "    \n",
    "    #Calculate variance for one startup\n",
    "    def expected_variance(self, startup_1):\n",
    "        alpha_sumation_1 = ((1 - Alpha**(Early_startup_exit - getattr(startup_1, \"Life_stage\")))/(1-Alpha))\n",
    "        alpha_sumation_2 = ((1 - Alpha**(1 + Early_startup_exit - getattr(startup_1, \"Life_stage\")))/(1-Alpha))                   \n",
    "        if getattr(startup_1, \"Life_stage\") == 0:\n",
    "            noise = Noise_standard_deviation_after_screening_ES\n",
    "        else:\n",
    "            noise = Noise_standard_deviation_after_screening_ES/(getattr(startup_1, \"Life_stage\")**(1/2))\n",
    "        return alpha_sumation_1**2*noise + alpha_sumation_2**2*Idiosyncratic_shock_sd + alpha_sumation_2**2*Industry_shock_sd + alpha_sumation_2**2*Macro_shock_sd                                                                                         \n",
    "\n",
    "    #Calculate expected variance for the whole portfolio \n",
    "    def expected_portfolio_variance(self, Portfolio):\n",
    "        if len(Portfolio) <=1:\n",
    "            return 0\n",
    "        else:\n",
    "            Total_variance = []\n",
    "            for i in Portfolio:\n",
    "                for j in Portfolio:\n",
    "                    if i != j:\n",
    "                        Total_variance = i[2]*j[2]*self.expected_covariance(i[0], j[0]) + Total_variance\n",
    "                    if i == j:\n",
    "                        Total_variance = i[2]**2*self.expected_variance(i[0]) + Total_variance\n",
    "            return Total_variance\n",
    "                                    \n",
    "    #Gets expected return on a Portfolio\n",
    "    def expected_return(self, Portfolio):\n",
    "        Return = 0\n",
    "        if len(Portfolio) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            print(Portfolio)\n",
    "            for i in Portfolio:\n",
    "                print(getattr(i[0], \"EPI_after_screening\"))\n",
    "                Projected_EPI = getattr(i[0], \"EPI_after_screening\")\n",
    "                for j in range(0,(Early_startup_exit-getattr(i[0],\"Life_stage\"))):                    \n",
    "                    Projected_EPI = self.time_progression_projected(Projected_EPI)\n",
    "                    print(Projected_EPI)\n",
    "                    if Projected_EPI < 0:\n",
    "                        Projected_EPI = 0\n",
    "                    if Projected_EPI > 1:\n",
    "                        Projected_EPI = 0.99\n",
    "                print(\"Projected_EPI is\")\n",
    "                print(Projected_EPI)\n",
    "                print(\"EPI_to_returns\")\n",
    "                print(self.EPI_to_returns(Projected_EPI, i[1]))\n",
    "                Return = float((self.EPI_to_returns(Projected_EPI, i[1])*i[2]))+ Return\n",
    "                print(\"Return:\")\n",
    "                print(Return)\n",
    "            return Return\n",
    "    \n",
    "    #Expected Sharpe ratio\n",
    "    def expected_portfolio_coefficient(self, Portfolio):     \n",
    "        return float(self.expected_return(Portfolio) - Risk_free_rate)/float(self.expected_portfolio_variance(Portfolio))\n",
    "    \n",
    "    #Is a startup in the portfolio or not\n",
    "    def startup_in_portfolio(self, Prospect):\n",
    "        for i in self.Portfolio:\n",
    "            if Prospect[0] in i:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        \n",
    "    #Gets reward after taking a particular action a \n",
    "    def get_reward(self, action, startup):\n",
    "        #If less than 0.01 was invested, we assume that VC does not invest into a given startup\n",
    "        if action <0.01:\n",
    "            return troch.tensor([0])\n",
    "        #If action in this range then VC invests in startup\n",
    "        if 0.01<=action<=1:\n",
    "            return torch.tensor([(self.expected_portfolio_coefficient((self.Portfolio + [list(startup) + list(action)])) - self.expected_portfolio_coefficient(self.Portfolio))])\n",
    "        #\n",
    "        if action>1:\n",
    "            return torch.tensor([-100])\n",
    "        \n",
    "    #Gets state which is inputed into the RL model\n",
    "    def get_state(self, Prospect):\n",
    "        \n",
    "        #Prospect attributes\n",
    "        Startup_in_portfolio = 0\n",
    "        if self.Portfolio_size !=0:\n",
    "            Startup_in_portfolio = int(self.startup_in_portfolio(Prospect))\n",
    "        Prospect_EPI = getattr(Prospect[0], \"EPI_after_screening\")\n",
    "        Prospect_stage = 0 \n",
    "        if Prospect[1] == \"Late\":\n",
    "            Prospect_stage = 1\n",
    "        Industry_correlation = 0\n",
    "        for i in self.Portfolio:    \n",
    "            Industry_correlation =  Correlation_matrix.loc[getattr(Prospect, \"Industry\"), getattr(i[0], \"Industry\")] + Industry_correlation\n",
    "        Average_correlation_with_portfolio = 0\n",
    "        if self.Portfolio_size != 0:\n",
    "            Average_correlation_with_portfolio = Industry_correlation/self.Portfolio_size\n",
    "        \n",
    "        #Cohort attributes\n",
    "        total_cohort = 0\n",
    "        for i in self.Screening_prospects:\n",
    "            total_cohort = getattr(i[0], \"EPI_after_screening\") + total_cohort\n",
    "        Screenings_mean = total_cohort/len(self.Screening_prospects) \n",
    "        Screenings = []\n",
    "        for i in self.Screening_prospects:\n",
    "            Screenings.append(getattr(i[0], \"EPI_after_screening\"))\n",
    "        Screenings_sd = np.std(Screenings)\n",
    "            \n",
    "        #Portfolio attributes\n",
    "        total = 0\n",
    "        for i in self.Portfolio:\n",
    "            total = getattr(i[0], \"EPI_after_screening\") + total\n",
    "        Portfolio_mean = 0\n",
    "        if self.Portfolio_size != 0:\n",
    "            Portfolio_mean = total/self.Portfolio_size\n",
    "        EPIs = []\n",
    "        Portfolio_sd = 0\n",
    "        if self.Portfolio_size != 0:\n",
    "            for i in self.Portfolio:\n",
    "                EPIs.append(getattr(i[0], \"EPI_after_screening\"))\n",
    "            Portfolio_sd = np.std(EPIs)\n",
    "        \n",
    "        state_ = torch.tensor([Startup_in_portfolio, Prospect_EPI, Prospect_stage, Average_correlation_with_portfolio, Screenings_mean, Screenings_sd, Portfolio_mean, Portfolio_sd, self.VC_quality, self.Endowement, self.Time_till_end_of_investment_stage_E, self.Time_till_end_of_investment_stage_L])\n",
    "        return state_\n",
    "    \n",
    "    #Gets next state \n",
    "    def get_next_state(self, action, Prospect):\n",
    "        Startup_in_portfolio = 0\n",
    "        Prospect_EPI = 0\n",
    "        Prospect_stage = 0 \n",
    "        Average_correlation_with_portfolio = 0\n",
    "        \n",
    "        #Cohort attributes\n",
    "        total_cohort = 0\n",
    "        for i in self.Screening_prospects:\n",
    "            total_cohort = getattr(i[0], \"EPI_after_screening\") + total_cohort\n",
    "        Screenings_mean = total_cohort/len(self.Screening_prospects) \n",
    "        Screenings = []\n",
    "        for i in self.Screening_prospects:\n",
    "            Screenings.append(getattr(i[0], \"EPI_after_screening\"))\n",
    "        Screenings_sd = np.std(Screenings)\n",
    "            \n",
    "        #Portfolio attributes\n",
    "        total = 0\n",
    "        for i in self.Portfolio:\n",
    "            total = getattr(i[0], \"EPI_after_screening\") + total\n",
    "        Portfolio_mean = 0\n",
    "        if self.Portfolio_size != 0:\n",
    "            Portfolio_mean = total/self.Portfolio_size\n",
    "        EPIs = []\n",
    "        Portfolio_sd = 0\n",
    "        if self.Portfolio_size != 0:\n",
    "            for i in self.Portfolio:\n",
    "                EPIs.append(getattr(i[0], \"EPI_after_screening\"))\n",
    "            Portfolio_sd = np.std(EPIs)\n",
    "        \n",
    "        next_state_ = torch.tensor([Startup_in_portfolio, Prospect_EPI, Prospect_stage, Average_correlation_with_portfolio, Screenings_mean, Screenings_sd, Portfolio_mean, Portfolio_sd, self.VC_quality, self.Endowement, self.Time_till_end_of_investment_stage_E, self.Time_till_end_of_investment_stage_L])\n",
    "        return next_state_\n",
    "    \n",
    "    def step(self):\n",
    "        for i in self.Screening_prospects:\n",
    "            done = 0\n",
    "            obs = self.get_state(i)\n",
    "            act = agent.choose_action(obs)\n",
    "            print(obs)\n",
    "            print(act)\n",
    "            print(self.Portfolio)\n",
    "            new_state, reward = self.get_next_state(act, obs), self.get_reward(act, i)\n",
    "            agent.remember(obs, act, reward, new_state, int(done))\n",
    "            agent.learn()\n",
    "            if 0.01<=act<=1:\n",
    "                i[0].VC_potential_investments.append(self)\n",
    "                self.Portfolio.append(i+[act])\n",
    "        self.Fund_life_stage += 1\n",
    "        \n",
    "class Startup(Agent):\n",
    "    def __init__(self, unique_id, EPI, Industry, Life_stage, model):\n",
    "        self.unique_id = unique_id\n",
    "        self.model = model\n",
    "        self.Industry = Industry\n",
    "        self.EPI = EPI\n",
    "        self.Life_stage = Life_stage\n",
    "        self.EPI_with_noise = 0\n",
    "        self.EPI_after_screening = 0\n",
    "        self.VC_potential_investments = []\n",
    "        self.VC_investments = []\n",
    "    \n",
    "    def average_investor_quality(self):\n",
    "        total = 0\n",
    "        if len(self.VC_investments) != 0:\n",
    "            for i in self.VC_investments:\n",
    "                total = getattr(i[0], \"VC_quality\") + total\n",
    "            return total/len(self.VC_investments)\n",
    "        if len(self.VC_investments) == 0 :\n",
    "            return 0\n",
    "    \n",
    "    #This is a funciton which makes a startup to progress over time                                \n",
    "    #The EPI(potential) in time t+1 depends on EPI in time t, advising from VC and random shocks\n",
    "    def time_progression(self):\n",
    "        self.EPI = Alpha*self.EPI + Beta*self.average_investor_quality() + np.random.normal(Idiosyncratic_shock_mean, Idiosyncratic_shock_sd)\\\n",
    "        + np.random.normal(Industry_shock_mean, Industry_shock_sd) + np.random.normal(Macro_shock_mean, Macro_shock_sd)\n",
    "        self.Life_stage += 1\n",
    "                                    \n",
    "    def noise_before_screening(self):\n",
    "        if self.Life_stage == 0:\n",
    "            self.EPI_with_noise = self.EPI + np.random.normal(Noise_mean_before_screening_ES, Noise_standard_deviation_before_screening_ES)\n",
    "            while self.EPI_with_noise>1 or self.EPI_with_noise<0:\n",
    "                self.EPI_with_noise = self.EPI + np.random.normal(Noise_mean_before_screening_ES, Noise_standard_deviation_before_screening_ES)\n",
    "        else:\n",
    "            self.EPI_with_noise = self.EPI + np.random.normal(Noise_mean_before_screening_ES, Noise_standard_deviation_before_screening_ES/(self.Life_stage**(1/2)))\n",
    "            while self.EPI_with_noise>1 or self.EPI_with_noise<0:\n",
    "                self.EPI_with_noise = self.EPI + np.random.normal(Noise_mean_before_screening_ES, Noise_standard_deviation_before_screening_ES/(self.Life_stage**(1/2)))\n",
    "    \n",
    "    def noise_after_screening(self):\n",
    "        if self.Life_stage == 0:\n",
    "            self.EPI_after_screening = self.EPI + np.random.normal(Noise_mean_after_screening_ES, Noise_standard_deviation_after_screening_ES)\n",
    "            while self.EPI_after_screening>1 or self.EPI_after_screening<0:\n",
    "                self.EPI_after_screening = self.EPI + np.random.normal(Noise_mean_after_screening_ES, Noise_standard_deviation_after_screening_ES)\n",
    "        else:\n",
    "            self.EPI_after_screening = self.EPI + np.random.normal(Noise_mean_after_screening_ES, Noise_standard_deviation_after_screening_ES/(self.Life_stage**(1/2)))\n",
    "            while self.EPI_after_screening>1 or self.EPI_after_screening<0:\n",
    "                self.EPI_after_screening = self.EPI + np.random.normal(Noise_mean_after_screening_ES, Noise_standard_deviation_after_screening_ES)\n",
    "    \n",
    "    #Function step refers to range of updates that occur every time step \n",
    "    def step(self):\n",
    "        self.VC_potential_investments.sort(key = lambda x: x.VC_quality, reverse=True)\n",
    "        for i in self.VC_potential_investments[:5]:\n",
    "            self.VC_investments.append(i)\n",
    "        self.VC_potential_investments = []\n",
    "        #Updating EPI with noise for startups\n",
    "        self.noise_before_screening()\n",
    "        self.noise_after_screening()\n",
    "        #Collecting the prospects for this time step, \n",
    "        #0.450 and 0.570 correspond to levels of EPI that give return greater than 2\n",
    "        if self.Life_stage == 0 and self.EPI_with_noise > 0.450:\n",
    "            world.Early_stage_prospects.append(self)\n",
    "        if self.Life_stage == 8 and self.EPI_with_noise > 0.570:\n",
    "            world.Late_stage_prospects.append(self) \n",
    "        self.time_progression()  \n",
    "        #We also make all the startups progress in time    \n",
    "       \n",
    "        \n",
    "#Activation class, determines in which order agents are activated\n",
    "class Activation_1(BaseScheduler):\n",
    "    def step(self):\n",
    "        #First, starups are activated\n",
    "        for agent in self.agent_buffer(shuffled=True):\n",
    "            if agent.unique_id >= world.VC_number:\n",
    "                agent.step()\n",
    "                \n",
    "class Activation_2(BaseScheduler):\n",
    "    def step(self):\n",
    "        #Then, VCs are activated\n",
    "        for agent in self.agent_buffer(shuffled=True):\n",
    "            if agent.unique_id < world.VC_number:\n",
    "                agent.step()\n",
    "        #After agents are activated, we updated the step value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "class World(Model):\n",
    "    def __init__(self, VC_number, Startup_number):\n",
    "        self.VC_number = VC_number\n",
    "        self.Startup_number = Startup_number\n",
    "        self.schedule_1 = Activation_1(self) \n",
    "        self.schedule_2 = Activation_2(self)\n",
    "        self.Early_stage_prospects = []\n",
    "        self.Late_stage_prospects = []\n",
    "        self.VCs = []\n",
    "        \n",
    "        #Creating Agents - VC\n",
    "        for i in range (Number_of_VCs):\n",
    "            a = VC(i,float(theoretical_distribution_VC.generate_random(1)/VC_max_TVPI),int(lognorm.rvs(Number_of_employees_sd, Number_of_employees_loc, Number_of_employees_scale)),0,self)\n",
    "            while a.VC_quality>1:\n",
    "                a.VC_quality = float(theoretical_distribution_VC.generate_random(1)/VC_max_TVPI)\n",
    "            self.schedule_2.add(a)\n",
    "            self.VCs.append(a)\n",
    "            \n",
    "        self.VCs.sort(key = attrgetter('VC_quality'), reverse = True)                \n",
    "        \n",
    "        ##Collecting data\n",
    "        self.datacollector = DataCollector(\n",
    "          agent_reporters={\"EPI\": lambda a: getattr(a, \"EPI\", None)}\n",
    "        )\n",
    "\n",
    "    #Creating Agents - Startups_early stage\n",
    "    def create_startups_early_1(self):        \n",
    "        for j in range (Number_of_VCs + self.schedule_1.steps*Number_of_new_startups + self.schedule_1.steps*Number_of_late_stage_startups, Number_of_VCs +  (self.schedule_1.steps+1)*Number_of_new_startups + self.schedule_1.steps*Number_of_late_stage_startups):\n",
    "            b = Startup(j, powerlaw.rvs(EPI_alpha, EPI_loc, EPI_scale),random.choices(List_of_Industries, Probability_Distribution_of_Industries),0, self)\n",
    "            self.schedule_1.add(b)         \n",
    "                \n",
    "    def create_startups_early_2(self):        \n",
    "        for j in range (Number_of_VCs + self.schedule_1.steps*Number_of_new_startups + 8*Number_of_late_stage_startups, Number_of_VCs +  (self.schedule_1.steps+1)*Number_of_new_startups + 8*Number_of_late_stage_startups):\n",
    "            b = Startup(j, powerlaw.rvs(EPI_alpha, EPI_loc, EPI_scale),random.choices(List_of_Industries, Probability_Distribution_of_Industries),0, self)       \n",
    "            self.schedule_1.add(b) \n",
    "       \n",
    "    #Creating Agents - Startups_late stage\n",
    "    def create_startups_late(self):\n",
    "        #Creating list of late_stage EPIs \n",
    "        Data = []\n",
    "        for i in range(Number_of_new_startups):\n",
    "            epi = powerlaw.rvs(EPI_alpha, EPI_loc, EPI_scale)\n",
    "            epi_with_noise = epi + np.random.normal(Noise_mean_before_screening_ES, Noise_standard_deviation_before_screening_ES)\n",
    "            while epi_with_noise >1 or epi_with_noise<0:\n",
    "                epi_with_noise = epi + np.random.normal(Noise_mean_before_screening_ES, Noise_standard_deviation_before_screening_ES)\n",
    "            epi_after_screening = epi + np.random.normal(Noise_mean_after_screening_ES, Noise_standard_deviation_after_screening_ES)\n",
    "            while epi_after_screening >1 or epi_after_screening<0:\n",
    "                epi_after_screening = epi + np.random.normal(Noise_mean_after_screening_ES, Noise_standard_deviation_after_screening_ES)\n",
    "            data_point = [epi, epi_with_noise, epi_after_screening]\n",
    "            if data_point[1] > 0.450:\n",
    "                Data.append(data_point)\n",
    "        Data.sort(key = lambda x: x[1], reverse = True)\n",
    "        Data_selection = Data[:Estimate_of_early_stage_screenings]\n",
    "        Data_selection.sort(key = lambda x: x[2], reverse = True)\n",
    "        Data_selection_final = Data_selection[:Number_of_late_stage_startups]\n",
    "        EPI_list = []\n",
    "        for i in Data_selection_final:\n",
    "            EPI_list.append(i[0])    \n",
    "        for (j, i) in zip(range (Number_of_VCs + (self.schedule_1.steps+1)*Number_of_new_startups + self.schedule_1.steps*Number_of_late_stage_startups, Number_of_VCs + (self.schedule_1.steps+1)*Number_of_new_startups + (self.schedule_1.steps+1)*Number_of_late_stage_startups), range(Number_of_late_stage_startups)):\n",
    "            c = Startup(j, EPI_list[i],random.choices(List_of_Industries, Probability_Distribution_of_Industries),8, self)\n",
    "            self.schedule_1.add(c)\n",
    "                \n",
    "    def startups_generation(self):\n",
    "        if self.schedule_1.steps<8:\n",
    "            self.create_startups_early_1()\n",
    "            self.create_startups_late()\n",
    "        else:\n",
    "            self.create_startups_early_2()\n",
    "            \n",
    "    def matching_prospects_to_VCs(self):\n",
    "        index = 0\n",
    "        for i in world.Early_stage_prospects:\n",
    "            for j in world.VCs:\n",
    "                if getattr(j, \"Number_of_available_screenings\")*(1-Percentage_of_startups_getting_to_later_stage) > 1+ len(getattr(j, \"Screening_prospects\")):\n",
    "                    j.Screening_prospects.append([i, \"Early\"])\n",
    "                    i.VC_investments.append([j])\n",
    "                    index +=1\n",
    "                if index == 10:\n",
    "                    break\n",
    "            index = 0\n",
    "        index = 0 \n",
    "        for i in world.Late_stage_prospects:\n",
    "            for j in world.VCs:\n",
    "                if getattr(j, \"Number_of_available_screenings\")*Percentage_of_startups_getting_to_later_stage > len(getattr(j, \"Screening_prospects\")):\n",
    "                    j.Screening_prospects.append([i, \"Late\"])\n",
    "                    i.VC_investments.append([j])\n",
    "                    index +=1\n",
    "                if index == 10:\n",
    "                    break\n",
    "            index = 0\n",
    "        \n",
    "    def step(self):\n",
    "        self.Early_stage_prospects = []\n",
    "        self.Late_stage_prospects = []\n",
    "        self.startups_generation()\n",
    "        self.schedule_1.step()\n",
    "        self.Early_stage_prospects.sort(key = attrgetter('EPI_with_noise'), reverse = True)\n",
    "        self.Late_stage_prospects.sort(key = attrgetter('EPI_with_noise'), reverse = True)\n",
    "        self.matching_prospects_to_VCs()\n",
    "        self.schedule_2.step()\n",
    "        self.schedule_1.steps += 1\n",
    "        self.schedule_1.time += 1\n",
    "        #self.datacollector.collect(self)\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.2706,  0.0000,  0.0000,  0.3626,  0.2587,  0.0000,  0.0000,\n",
      "         0.4162,  1.0000,  8.0000, 16.0000], dtype=torch.float64)\n",
      "[0.50101143]\n",
      "[]\n",
      "[[<__main__.Startup object at 0x7fea76885880>, 'Early', 0.50101143]]\n",
      "0.2706384409645302\n",
      "0.24110232028655454\n",
      "0.20116399771814114\n",
      "0.236735706274221\n",
      "0.268915265777841\n",
      "0.04569361247791695\n",
      "0.07980630955643991\n",
      "0.035726539084599496\n",
      "0.2786438071094748\n",
      "0.1874350762371586\n",
      "0.23349197483530265\n",
      "0.3475284021531786\n",
      "0.2986677661941524\n",
      "0.08296533669732348\n",
      "0.20587763824724628\n",
      "0.17698593467534895\n",
      "0.20001319787479993\n",
      "0.24906968988941028\n",
      "0.09210091819007853\n",
      "0.06541125753435728\n",
      "0.09623354558369246\n",
      "0.11911428957835635\n",
      "0.06490581513078365\n",
      "0.0790331553316706\n",
      "-0.05223945320240002\n",
      "0.04641680191194631\n",
      "0.07183260077227728\n",
      "0.1052436126831563\n",
      "0.31264543919969723\n",
      "0.5318969754578955\n",
      "0.4494594989614988\n",
      "0.5205943572678097\n",
      "Projected_EPI is\n",
      "0.5205943572678097\n",
      "EPI_to_returns\n",
      "2.5766608221732867\n",
      "Return:\n",
      "1.2909365262783092\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-329-317e9f891835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mworld\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNumber_of_VCs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber_of_new_startups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-328-48629224d8c2>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLate_stage_prospects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EPI_with_noise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatching_prospects_to_VCs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-327-64e772e8a816>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_id\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVC_number\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m#After agents are activated, we updated the step value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-327-64e772e8a816>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPortfolio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-327-64e772e8a816>\u001b[0m in \u001b[0;36mget_reward\u001b[0;34m(self, action, startup)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m#If action in this range then VC invests in startup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_portfolio_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPortfolio\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_portfolio_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPortfolio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-327-64e772e8a816>\u001b[0m in \u001b[0;36mexpected_portfolio_coefficient\u001b[0;34m(self, Portfolio)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m#Expected Sharpe ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpected_portfolio_coefficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPortfolio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPortfolio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mRisk_free_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_portfolio_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPortfolio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m#Is a startup in the portfolio or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "world = World(Number_of_VCs, Number_of_new_startups)\n",
    "for i in range(1):\n",
    "    world.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for i in world.VCs:\n",
    "    print(i.Screening_prospects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def startup_in_portfolio(self, Prospect):\n",
    "        for i in Portfolio:\n",
    "            if Prospect[0] in i:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0 \n",
    "    \n",
    "    def get_state(self, Prospect):\n",
    "        \n",
    "        #Prospect attributes\n",
    "        Startup_in_portfolio = self.startup_in_portfolio(Prospect)\n",
    "        Prospect_EPI = getattr(Prospect[0], \"EPI_after_screening\")\n",
    "        Prospect_stage = 0 \n",
    "        if Prospect[1] == \"Late\":\n",
    "            Prospect_stage = 1\n",
    "        Industry_correlation = 0\n",
    "        for i in self.Portfolio:    \n",
    "            Industry_correlation =  Correlation_matrix.loc[getattr(Prospect, \"Industry\"), getattr(i[0], \"Industry\")] + Industry_correlation\n",
    "        Average_correlation_with_portfolio = 0\n",
    "        if self.Portfolio_size != 0:\n",
    "            Average_correlation_with_portfolio = Industry_correlation/self.Portfolio_size\n",
    "        \n",
    "        #Cohort attributes\n",
    "        total_cohort = 0\n",
    "        for i in self.Screening_prospects:\n",
    "            total_cohort = getattr(i[0], \"EPI_after_screening\") + total_cohort\n",
    "        Screenings_mean = total_cohort/len(self.Screening_prospects) \n",
    "        Screenings = []\n",
    "        for i in self.Screening_prospects:\n",
    "            Screenings.append(getattr(i[0], \"EPI_after_screening\"))\n",
    "        Screenings_sd = np.std(Screenings)\n",
    "            \n",
    "        #Portfolio attributes\n",
    "        total = 0\n",
    "        for i in self.Portfolio:\n",
    "            total = getattr(i[0], \"EPI_after_screening\") + total\n",
    "        Portfolio_mean = 0\n",
    "        if self.Portfolio_size != 0:\n",
    "            Portfolio_mean = total/self.Portfolio_size\n",
    "        EPIs = []\n",
    "        for i in self.Portfolio:\n",
    "            EPIs.append(getattr(i[0], \"EPI_after_screening\"))\n",
    "        Portfolio_sd = np.std(EPIs)\n",
    "        \n",
    "        state_ = torch.tensor([Startup_in_portfolio, Prospect_EPI, Prospect_stage, Average_correlation_with_portfolio, Screenings_mean, Screenings_sd, Portfolio_mean, Portfolio_sd, self.VC_quality, self.Endowement, self.Time_till_end_of_investment_stage_E, self.Time_till_end_of_investment_stage_L])\n",
    "        return state_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car:\n",
    "    def __init__(self, number):\n",
    "        self.number = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cars = []\n",
    "for i in range(10):\n",
    "    s = Car(np.random.uniform(0,10))\n",
    "    Cars.append(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3666887275630986\n",
      "7.435953875404775\n",
      "2.05151240438901\n",
      "2.362214039784009\n",
      "3.924088859831926\n",
      "0.08103013361251077\n",
      "4.961311873982178\n",
      "3.091929139485692\n",
      "5.2001717169607895\n",
      "5.513971306273037\n"
     ]
    }
   ],
   "source": [
    "for i in Cars:\n",
    "    print(getattr(i,\"number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cars.sort(key = lambda x: x.number, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.435953875404775\n",
      "5.513971306273037\n",
      "5.2001717169607895\n",
      "4.961311873982178\n",
      "3.924088859831926\n",
      "3.3666887275630986\n",
      "3.091929139485692\n",
      "2.362214039784009\n",
      "2.05151240438901\n",
      "0.08103013361251077\n"
     ]
    }
   ],
   "source": [
    "for i in Cars:\n",
    "    print(getattr(i,\"number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cars_selection = Cars[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Car at 0x7fea90a7f310>,\n",
       " <__main__.Car at 0x7fea90ac4640>,\n",
       " <__main__.Car at 0x7fea90ac45b0>,\n",
       " <__main__.Car at 0x7fea90ac4490>,\n",
       " <__main__.Car at 0x7fea90ac4370>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cars_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cars_selection.append(i in Cars[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Car at 0x7fea90a7f310>,\n",
       " <__main__.Car at 0x7fea90ac4640>,\n",
       " <__main__.Car at 0x7fea90ac45b0>,\n",
       " <__main__.Car at 0x7fea90ac4490>,\n",
       " <__main__.Car at 0x7fea90ac4370>,\n",
       " [<__main__.Car at 0x7fea90a7f310>,\n",
       "  <__main__.Car at 0x7fea90ac4640>,\n",
       "  <__main__.Car at 0x7fea90ac45b0>,\n",
       "  <__main__.Car at 0x7fea90ac4490>,\n",
       "  <__main__.Car at 0x7fea90ac4370>],\n",
       " False]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in CaCars_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = [0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i+[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Startup_in_portfolio = 0\n",
    "Prospect_EPI = 0.4\n",
    "Prospect_stage = 1\n",
    "Average_correlation_with_portfolio = 0.5\n",
    "Screenings_mean = 0.2\n",
    "Screenings_sd = 0.3\n",
    "Portfolio_mean = 0\n",
    "Portfolio_sd = 0\n",
    "VC_quality = 0.8\n",
    "Endowement = 1\n",
    "Time_till_end_of_investment_stage_E = 4\n",
    "Time_till_end_of_investment_stage_L = 6\n",
    "\n",
    "state_ = torch.tensor([Startup_in_portfolio, Prospect_EPI, Prospect_stage, Average_correlation_with_portfolio, Screenings_mean, Screenings_sd, Portfolio_mean, Portfolio_sd, VC_quality, Endowement, Time_till_end_of_investment_stage_E, Time_till_end_of_investment_stage_L])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelgramata/Documents/00_Dissertation/Model/Model/Model/ddpg.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  observation = T.tensor(observation, dtype=T.float).to(self.actor.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.519666], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.choose_action(state_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.tensor([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def startup_in_portfolio(self, Prospect):\n",
    "        for i in self.Portfolio:\n",
    "            if Prospect[0] in i:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = [()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor([ 0.0000,  0.2807,  0.0000,  0.0000,  0.3781,  0.2599,  0.0000,  0.0000,\n",
    "         0.2353,  1.0000,  8.0000, 16.0000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.choose_action(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def time_progression_projected(EPI):\n",
    "        EPI_ = Alpha*EPI + Beta*0.8 + np.random.normal(Idiosyncratic_shock_mean, Idiosyncratic_shock_sd)\\\n",
    "        + np.random.normal(Industry_shock_mean, Industry_shock_sd) + np.random.normal(Macro_shock_mean, Macro_shock_sd)\n",
    "        return EPI_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792028641755653"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_progression_projected(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def expected_return(self, Portfolio):\n",
    "        Return = []\n",
    "        for i in Portfolio:\n",
    "            Projected_EPI = getattr(i[0], \"EPI_with_noise\")\n",
    "            for j in range(0,(Early_startup_exit-getattr(i[0],\"Life_stage\"))):                    \n",
    "                Projected_EPI = self.time_progression_projected(Projected_EPI)\n",
    "            Return = (EPI_to_returns(Projected_EPI, i[1])*i[2])+ Return\n",
    "        return Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-52be69ed55b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample_data_ER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "probability = 1.6\n",
    "sample_data_ER[int(sample_size*probability)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(a+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
